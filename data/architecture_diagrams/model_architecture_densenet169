digraph {
	graph [size="687.3,687.3"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	2417191304432 [label="
 (1, 5, 256, 256)" fillcolor=darkolivegreen1]
	2417187390128 [label=ConvolutionBackward0]
	2416982621488 -> 2417187390128
	2416982621488 [label=ReluBackward0]
	2416914199648 -> 2416982621488
	2416914199648 [label=CudnnBatchNormBackward0]
	2416773402864 -> 2416914199648
	2416773402864 [label=ConvolutionBackward0]
	2416913854240 -> 2416773402864
	2416913854240 [label=ReluBackward0]
	2416913551456 -> 2416913854240
	2416913551456 [label=CudnnBatchNormBackward0]
	2416913422160 -> 2416913551456
	2416913422160 [label=ConvolutionBackward0]
	2416982793696 -> 2416913422160
	2416982793696 [label=UpsampleNearest2DBackward0]
	2416913643648 -> 2416982793696
	2416913643648 [label=ReluBackward0]
	2416913640240 -> 2416913643648
	2416913640240 [label=CudnnBatchNormBackward0]
	2416913634144 -> 2416913640240
	2416913634144 [label=ConvolutionBackward0]
	2416913637792 -> 2416913634144
	2416913637792 [label=ReluBackward0]
	2416913633520 -> 2416913637792
	2416913633520 [label=CudnnBatchNormBackward0]
	2416913641968 -> 2416913633520
	2416913641968 [label=ConvolutionBackward0]
	2416913645424 -> 2416913641968
	2416913645424 [label=CatBackward0]
	2416913641392 -> 2416913645424
	2416913641392 [label=UpsampleNearest2DBackward0]
	2416913645376 -> 2416913641392
	2416913645376 [label=ReluBackward0]
	2416913637648 -> 2416913645376
	2416913637648 [label=CudnnBatchNormBackward0]
	2416913632272 -> 2416913637648
	2416913632272 [label=ConvolutionBackward0]
	2416913631456 -> 2416913632272
	2416913631456 [label=ReluBackward0]
	2416913633712 -> 2416913631456
	2416913633712 [label=CudnnBatchNormBackward0]
	2416913642736 -> 2416913633712
	2416913642736 [label=ConvolutionBackward0]
	2416913638560 -> 2416913642736
	2416913638560 [label=CatBackward0]
	2416913632704 -> 2416913638560
	2416913632704 [label=UpsampleNearest2DBackward0]
	2416913635200 -> 2416913632704
	2416913635200 [label=ReluBackward0]
	2416913635824 -> 2416913635200
	2416913635824 [label=CudnnBatchNormBackward0]
	2416913638704 -> 2416913635824
	2416913638704 [label=ConvolutionBackward0]
	2416913635488 -> 2416913638704
	2416913635488 [label=ReluBackward0]
	2416913645040 -> 2416913635488
	2416913645040 [label=CudnnBatchNormBackward0]
	2416913629584 -> 2416913645040
	2416913629584 [label=ConvolutionBackward0]
	2416913644896 -> 2416913629584
	2416913644896 [label=CatBackward0]
	2416913639808 -> 2416913644896
	2416913639808 [label=UpsampleNearest2DBackward0]
	2416913643552 -> 2416913639808
	2416913643552 [label=ReluBackward0]
	2416913641488 -> 2416913643552
	2416913641488 [label=CudnnBatchNormBackward0]
	2416913632368 -> 2416913641488
	2416913632368 [label=ConvolutionBackward0]
	2416913641344 -> 2416913632368
	2416913641344 [label=ReluBackward0]
	2416913633808 -> 2416913641344
	2416913633808 [label=CudnnBatchNormBackward0]
	2416913643168 -> 2416913633808
	2416913643168 [label=ConvolutionBackward0]
	2416913635680 -> 2416913643168
	2416913635680 [label=CatBackward0]
	2416913636976 -> 2416913635680
	2416913636976 [label=UpsampleNearest2DBackward0]
	2416913631504 -> 2416913636976
	2416913631504 [label=CudnnBatchNormBackward0]
	2416913641008 -> 2416913631504
	2416913641008 [label=CatBackward0]
	2416913644080 -> 2416913641008
	2416913644080 [label=AvgPool2DBackward0]
	2417190373504 -> 2416913644080
	2417190373504 [label=ConvolutionBackward0]
	2416913642640 -> 2417190373504
	2416913642640 [label=ReluBackward0]
	2417190371728 -> 2416913642640
	2417190371728 [label=CudnnBatchNormBackward0]
	2417190386704 -> 2417190371728
	2417190386704 [label=CatBackward0]
	2417190382288 -> 2417190386704
	2417190382288 [label=AvgPool2DBackward0]
	2417190381856 -> 2417190382288
	2417190381856 [label=ConvolutionBackward0]
	2416913636784 -> 2417190381856
	2416913636784 [label=ReluBackward0]
	2417190380272 -> 2416913636784
	2417190380272 [label=CudnnBatchNormBackward0]
	2417190373792 -> 2417190380272
	2417190373792 [label=CatBackward0]
	2417190371392 -> 2417190373792
	2417190371392 [label=AvgPool2DBackward0]
	2417190379792 -> 2417190371392
	2417190379792 [label=ConvolutionBackward0]
	2416913638080 -> 2417190379792
	2416913638080 [label=ReluBackward0]
	2417190382192 -> 2416913638080
	2417190382192 [label=CudnnBatchNormBackward0]
	2417190382480 -> 2417190382192
	2417190382480 [label=CatBackward0]
	2417190384880 -> 2417190382480
	2417190384880 [label=MaxPool2DWithIndicesBackward0]
	2416913641248 -> 2417190384880
	2416913641248 [label=ReluBackward0]
	2417190386848 -> 2416913641248
	2417190386848 [label=CudnnBatchNormBackward0]
	2417190374704 -> 2417190386848
	2417190374704 [label=ConvolutionBackward0]
	2417190374080 -> 2417190374704
	2417186333440 [label="encoder.features.conv0.weight
 (64, 3, 7, 7)" fillcolor=lightblue]
	2417186333440 -> 2417190374080
	2417190374080 [label=AccumulateGrad]
	2417190372496 -> 2417190386848
	2417186332080 [label="encoder.features.norm0.weight
 (64)" fillcolor=lightblue]
	2417186332080 -> 2417190372496
	2417190372496 [label=AccumulateGrad]
	2417190377008 -> 2417190386848
	2417186330400 [label="encoder.features.norm0.bias
 (64)" fillcolor=lightblue]
	2417186330400 -> 2417190377008
	2417190377008 [label=AccumulateGrad]
	2417190385072 -> 2417190382480
	2417190385072 [label=ConvolutionBackward0]
	2417190371440 -> 2417190385072
	2417190371440 [label=ReluBackward0]
	2417190374896 -> 2417190371440
	2417190374896 [label=CudnnBatchNormBackward0]
	2417190374032 -> 2417190374896
	2417190374032 [label=ConvolutionBackward0]
	2417190377584 -> 2417190374032
	2417190377584 [label=ReluBackward0]
	2417190378544 -> 2417190377584
	2417190378544 [label=CudnnBatchNormBackward0]
	2417190381184 -> 2417190378544
	2417190381184 [label=CatBackward0]
	2417190384880 -> 2417190381184
	2417190379552 -> 2417190378544
	2417186330000 [label="encoder.features.denseblock1.denselayer1.norm1.weight
 (64)" fillcolor=lightblue]
	2417186330000 -> 2417190379552
	2417190379552 [label=AccumulateGrad]
	2417190377824 -> 2417190378544
	2417186329840 [label="encoder.features.denseblock1.denselayer1.norm1.bias
 (64)" fillcolor=lightblue]
	2417186329840 -> 2417190377824
	2417190377824 [label=AccumulateGrad]
	2417190385504 -> 2417190374032
	2417186329200 [label="encoder.features.denseblock1.denselayer1.conv1.weight
 (128, 64, 1, 1)" fillcolor=lightblue]
	2417186329200 -> 2417190385504
	2417190385504 [label=AccumulateGrad]
	2417190376672 -> 2417190374896
	2417186329280 [label="encoder.features.denseblock1.denselayer1.norm2.weight
 (128)" fillcolor=lightblue]
	2417186329280 -> 2417190376672
	2417190376672 [label=AccumulateGrad]
	2417190376576 -> 2417190374896
	2417186329040 [label="encoder.features.denseblock1.denselayer1.norm2.bias
 (128)" fillcolor=lightblue]
	2417186329040 -> 2417190376576
	2417190376576 [label=AccumulateGrad]
	2417190373360 -> 2417190385072
	2417186328320 [label="encoder.features.denseblock1.denselayer1.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2417186328320 -> 2417190373360
	2417190373360 [label=AccumulateGrad]
	2417190384160 -> 2417190382480
	2417190384160 [label=ConvolutionBackward0]
	2417190377152 -> 2417190384160
	2417190377152 [label=ReluBackward0]
	2417190377344 -> 2417190377152
	2417190377344 [label=CudnnBatchNormBackward0]
	2417190373264 -> 2417190377344
	2417190373264 [label=ConvolutionBackward0]
	2417190372784 -> 2417190373264
	2417190372784 [label=ReluBackward0]
	2417190384256 -> 2417190372784
	2417190384256 [label=CudnnBatchNormBackward0]
	2417190387232 -> 2417190384256
	2417190387232 [label=CatBackward0]
	2417190384880 -> 2417190387232
	2417190385072 -> 2417190387232
	2417190387472 -> 2417190384256
	2417186328400 [label="encoder.features.denseblock1.denselayer2.norm1.weight
 (96)" fillcolor=lightblue]
	2417186328400 -> 2417190387472
	2417190387472 [label=AccumulateGrad]
	2417190383344 -> 2417190384256
	2417186328480 [label="encoder.features.denseblock1.denselayer2.norm1.bias
 (96)" fillcolor=lightblue]
	2417186328480 -> 2417190383344
	2417190383344 [label=AccumulateGrad]
	2417190383296 -> 2417190373264
	2417186328080 [label="encoder.features.denseblock1.denselayer2.conv1.weight
 (128, 96, 1, 1)" fillcolor=lightblue]
	2417186328080 -> 2417190383296
	2417190383296 [label=AccumulateGrad]
	2417190380464 -> 2417190377344
	2417186327520 [label="encoder.features.denseblock1.denselayer2.norm2.weight
 (128)" fillcolor=lightblue]
	2417186327520 -> 2417190380464
	2417190380464 [label=AccumulateGrad]
	2417190378688 -> 2417190377344
	2417184290880 [label="encoder.features.denseblock1.denselayer2.norm2.bias
 (128)" fillcolor=lightblue]
	2417184290880 -> 2417190378688
	2417190378688 [label=AccumulateGrad]
	2417190376432 -> 2417190384160
	2417184287680 [label="encoder.features.denseblock1.denselayer2.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2417184287680 -> 2417190376432
	2417190376432 [label=AccumulateGrad]
	2417190385264 -> 2417190382480
	2417190385264 [label=ConvolutionBackward0]
	2417190381664 -> 2417190385264
	2417190381664 [label=ReluBackward0]
	2417190378448 -> 2417190381664
	2417190378448 [label=CudnnBatchNormBackward0]
	2417190372208 -> 2417190378448
	2417190372208 [label=ConvolutionBackward0]
	2417190371680 -> 2417190372208
	2417190371680 [label=ReluBackward0]
	2417190385312 -> 2417190371680
	2417190385312 [label=CudnnBatchNormBackward0]
	2417190380848 -> 2417190385312
	2417190380848 [label=CatBackward0]
	2417190384880 -> 2417190380848
	2417190385072 -> 2417190380848
	2417190384160 -> 2417190380848
	2417190377056 -> 2417190385312
	2417184289600 [label="encoder.features.denseblock1.denselayer3.norm1.weight
 (128)" fillcolor=lightblue]
	2417184289600 -> 2417190377056
	2417190377056 [label=AccumulateGrad]
	2417190387280 -> 2417190385312
	2417184279520 [label="encoder.features.denseblock1.denselayer3.norm1.bias
 (128)" fillcolor=lightblue]
	2417184279520 -> 2417190387280
	2417190387280 [label=AccumulateGrad]
	2417190371824 -> 2417190372208
	2417184277920 [label="encoder.features.denseblock1.denselayer3.conv1.weight
 (128, 128, 1, 1)" fillcolor=lightblue]
	2417184277920 -> 2417190371824
	2417190371824 [label=AccumulateGrad]
	2417190383728 -> 2417190378448
	2417184277680 [label="encoder.features.denseblock1.denselayer3.norm2.weight
 (128)" fillcolor=lightblue]
	2417184277680 -> 2417190383728
	2417190383728 [label=AccumulateGrad]
	2417190384736 -> 2417190378448
	2417184277120 [label="encoder.features.denseblock1.denselayer3.norm2.bias
 (128)" fillcolor=lightblue]
	2417184277120 -> 2417190384736
	2417190384736 [label=AccumulateGrad]
	2417190379696 -> 2417190385264
	2417184278240 [label="encoder.features.denseblock1.denselayer3.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2417184278240 -> 2417190379696
	2417190379696 [label=AccumulateGrad]
	2417190385456 -> 2417190382480
	2417190385456 [label=ConvolutionBackward0]
	2417190387328 -> 2417190385456
	2417190387328 [label=ReluBackward0]
	2417190377872 -> 2417190387328
	2417190377872 [label=CudnnBatchNormBackward0]
	2417190379312 -> 2417190377872
	2417190379312 [label=ConvolutionBackward0]
	2417190374320 -> 2417190379312
	2417190374320 [label=ReluBackward0]
	2417190374128 -> 2417190374320
	2417190374128 [label=CudnnBatchNormBackward0]
	2417190377728 -> 2417190374128
	2417190377728 [label=CatBackward0]
	2417190384880 -> 2417190377728
	2417190385072 -> 2417190377728
	2417190384160 -> 2417190377728
	2417190385264 -> 2417190377728
	2417190384928 -> 2417190374128
	2417184278800 [label="encoder.features.denseblock1.denselayer4.norm1.weight
 (160)" fillcolor=lightblue]
	2417184278800 -> 2417190384928
	2417190384928 [label=AccumulateGrad]
	2417190375616 -> 2417190374128
	2417184280240 [label="encoder.features.denseblock1.denselayer4.norm1.bias
 (160)" fillcolor=lightblue]
	2417184280240 -> 2417190375616
	2417190375616 [label=AccumulateGrad]
	2417190372448 -> 2417190379312
	2417184281280 [label="encoder.features.denseblock1.denselayer4.conv1.weight
 (128, 160, 1, 1)" fillcolor=lightblue]
	2417184281280 -> 2417190372448
	2417190372448 [label=AccumulateGrad]
	2417190375472 -> 2417190377872
	2417184280720 [label="encoder.features.denseblock1.denselayer4.norm2.weight
 (128)" fillcolor=lightblue]
	2417184280720 -> 2417190375472
	2417190375472 [label=AccumulateGrad]
	2417190374368 -> 2417190377872
	2417184280560 [label="encoder.features.denseblock1.denselayer4.norm2.bias
 (128)" fillcolor=lightblue]
	2417184280560 -> 2417190374368
	2417190374368 [label=AccumulateGrad]
	2417190387616 -> 2417190385456
	2417184282080 [label="encoder.features.denseblock1.denselayer4.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2417184282080 -> 2417190387616
	2417190387616 [label=AccumulateGrad]
	2417190385840 -> 2417190382480
	2417190385840 [label=ConvolutionBackward0]
	2417190380368 -> 2417190385840
	2417190380368 [label=ReluBackward0]
	2417190374848 -> 2417190380368
	2417190374848 [label=CudnnBatchNormBackward0]
	2417190382960 -> 2417190374848
	2417190382960 [label=ConvolutionBackward0]
	2417190373696 -> 2417190382960
	2417190373696 [label=ReluBackward0]
	2417190386992 -> 2417190373696
	2417190386992 [label=CudnnBatchNormBackward0]
	2417190373024 -> 2417190386992
	2417190373024 [label=CatBackward0]
	2417190384880 -> 2417190373024
	2417190385072 -> 2417190373024
	2417190384160 -> 2417190373024
	2417190385264 -> 2417190373024
	2417190385456 -> 2417190373024
	2417190374992 -> 2417190386992
	2417184283760 [label="encoder.features.denseblock1.denselayer5.norm1.weight
 (192)" fillcolor=lightblue]
	2417184283760 -> 2417190374992
	2417190374992 [label=AccumulateGrad]
	2417190376864 -> 2417190386992
	2417184283440 [label="encoder.features.denseblock1.denselayer5.norm1.bias
 (192)" fillcolor=lightblue]
	2417184283440 -> 2417190376864
	2417190376864 [label=AccumulateGrad]
	2417190385936 -> 2417190382960
	2417184284080 [label="encoder.features.denseblock1.denselayer5.conv1.weight
 (128, 192, 1, 1)" fillcolor=lightblue]
	2417184284080 -> 2417190385936
	2417190385936 [label=AccumulateGrad]
	2417190383392 -> 2417190374848
	2417184283920 [label="encoder.features.denseblock1.denselayer5.norm2.weight
 (128)" fillcolor=lightblue]
	2417184283920 -> 2417190383392
	2417190383392 [label=AccumulateGrad]
	2417190376720 -> 2417190374848
	2417184284400 [label="encoder.features.denseblock1.denselayer5.norm2.bias
 (128)" fillcolor=lightblue]
	2417184284400 -> 2417190376720
	2417190376720 [label=AccumulateGrad]
	2417190381376 -> 2417190385840
	2417184286960 [label="encoder.features.denseblock1.denselayer5.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2417184286960 -> 2417190381376
	2417190381376 [label=AccumulateGrad]
	2417190385984 -> 2417190382480
	2417190385984 [label=ConvolutionBackward0]
	2417190376624 -> 2417190385984
	2417190376624 [label=ReluBackward0]
	2417190372016 -> 2417190376624
	2417190372016 [label=CudnnBatchNormBackward0]
	2417190379264 -> 2417190372016
	2417190379264 [label=ConvolutionBackward0]
	2417190384064 -> 2417190379264
	2417190384064 [label=ReluBackward0]
	2417190371920 -> 2417190384064
	2417190371920 [label=CudnnBatchNormBackward0]
	2417190373456 -> 2417190371920
	2417190373456 [label=CatBackward0]
	2417190384880 -> 2417190373456
	2417190385072 -> 2417190373456
	2417190384160 -> 2417190373456
	2417190385264 -> 2417190373456
	2417190385456 -> 2417190373456
	2417190385840 -> 2417190373456
	2417190374464 -> 2417190371920
	2417184286640 [label="encoder.features.denseblock1.denselayer6.norm1.weight
 (224)" fillcolor=lightblue]
	2417184286640 -> 2417190374464
	2417190374464 [label=AccumulateGrad]
	2417190386944 -> 2417190371920
	2417184286320 [label="encoder.features.denseblock1.denselayer6.norm1.bias
 (224)" fillcolor=lightblue]
	2417184286320 -> 2417190386944
	2417190386944 [label=AccumulateGrad]
	2417190385648 -> 2417190379264
	2417184287760 [label="encoder.features.denseblock1.denselayer6.conv1.weight
 (128, 224, 1, 1)" fillcolor=lightblue]
	2417184287760 -> 2417190385648
	2417190385648 [label=AccumulateGrad]
	2417190386656 -> 2417190372016
	2417184288880 [label="encoder.features.denseblock1.denselayer6.norm2.weight
 (128)" fillcolor=lightblue]
	2417184288880 -> 2417190386656
	2417190386656 [label=AccumulateGrad]
	2417190371536 -> 2417190372016
	2417184288560 [label="encoder.features.denseblock1.denselayer6.norm2.bias
 (128)" fillcolor=lightblue]
	2417184288560 -> 2417190371536
	2417190371536 [label=AccumulateGrad]
	2417190383008 -> 2417190385984
	2417184289680 [label="encoder.features.denseblock1.denselayer6.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2417184289680 -> 2417190383008
	2417190383008 [label=AccumulateGrad]
	2417190371872 -> 2417190382192
	2417184289200 [label="encoder.features.transition1.norm.weight
 (256)" fillcolor=lightblue]
	2417184289200 -> 2417190371872
	2417190371872 [label=AccumulateGrad]
	2417190379744 -> 2417190382192
	2417184289040 [label="encoder.features.transition1.norm.bias
 (256)" fillcolor=lightblue]
	2417184289040 -> 2417190379744
	2417190379744 [label=AccumulateGrad]
	2417190382432 -> 2417190379792
	2417184290480 [label="encoder.features.transition1.conv.weight
 (128, 256, 1, 1)" fillcolor=lightblue]
	2417184290480 -> 2417190382432
	2417190382432 [label=AccumulateGrad]
	2417190376000 -> 2417190373792
	2417190376000 [label=ConvolutionBackward0]
	2417190372688 -> 2417190376000
	2417190372688 [label=ReluBackward0]
	2417190382720 -> 2417190372688
	2417190382720 [label=CudnnBatchNormBackward0]
	2417190386896 -> 2417190382720
	2417190386896 [label=ConvolutionBackward0]
	2417190375808 -> 2417190386896
	2417190375808 [label=ReluBackward0]
	2417190379840 -> 2417190375808
	2417190379840 [label=CudnnBatchNormBackward0]
	2417190382240 -> 2417190379840
	2417190382240 [label=CatBackward0]
	2417190371392 -> 2417190382240
	2417190386368 -> 2417190379840
	2417184292080 [label="encoder.features.denseblock2.denselayer1.norm1.weight
 (128)" fillcolor=lightblue]
	2417184292080 -> 2417190386368
	2417190386368 [label=AccumulateGrad]
	2417190378208 -> 2417190379840
	2417184291760 [label="encoder.features.denseblock2.denselayer1.norm1.bias
 (128)" fillcolor=lightblue]
	2417184291760 -> 2417190378208
	2417190378208 [label=AccumulateGrad]
	2417190385600 -> 2417190386896
	2417184292400 [label="encoder.features.denseblock2.denselayer1.conv1.weight
 (128, 128, 1, 1)" fillcolor=lightblue]
	2417184292400 -> 2417190385600
	2417190385600 [label=AccumulateGrad]
	2417190382096 -> 2417190382720
	2417184292240 [label="encoder.features.denseblock2.denselayer1.norm2.weight
 (128)" fillcolor=lightblue]
	2417184292240 -> 2417190382096
	2417190382096 [label=AccumulateGrad]
	2417190377488 -> 2417190382720
	2417184292720 [label="encoder.features.denseblock2.denselayer1.norm2.bias
 (128)" fillcolor=lightblue]
	2417184292720 -> 2417190377488
	2417190377488 [label=AccumulateGrad]
	2417190384016 -> 2417190376000
	2417184285760 [label="encoder.features.denseblock2.denselayer1.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2417184285760 -> 2417190384016
	2417190384016 [label=AccumulateGrad]
	2417190384592 -> 2417190373792
	2417190384592 [label=ConvolutionBackward0]
	2417190372352 -> 2417190384592
	2417190372352 [label=ReluBackward0]
	2417190383920 -> 2417190372352
	2417190383920 [label=CudnnBatchNormBackward0]
	2417190378784 -> 2417190383920
	2417190378784 [label=ConvolutionBackward0]
	2417190375136 -> 2417190378784
	2417190375136 [label=ReluBackward0]
	2417190376144 -> 2417190375136
	2417190376144 [label=CudnnBatchNormBackward0]
	2417190385744 -> 2417190376144
	2417190385744 [label=CatBackward0]
	2417190371392 -> 2417190385744
	2417190376000 -> 2417190385744
	2417190373072 -> 2417190376144
	2417184283200 [label="encoder.features.denseblock2.denselayer2.norm1.weight
 (160)" fillcolor=lightblue]
	2417184283200 -> 2417190373072
	2417190373072 [label=AccumulateGrad]
	2417190383536 -> 2417190376144
	2417184288960 [label="encoder.features.denseblock2.denselayer2.norm1.bias
 (160)" fillcolor=lightblue]
	2417184288960 -> 2417190383536
	2417190383536 [label=AccumulateGrad]
	2417190383200 -> 2417190378784
	2417191794192 [label="encoder.features.denseblock2.denselayer2.conv1.weight
 (128, 160, 1, 1)" fillcolor=lightblue]
	2417191794192 -> 2417190383200
	2417190383200 [label=AccumulateGrad]
	2417190386800 -> 2417190383920
	2417191783472 [label="encoder.features.denseblock2.denselayer2.norm2.weight
 (128)" fillcolor=lightblue]
	2417191783472 -> 2417190386800
	2417190386800 [label=AccumulateGrad]
	2417190381472 -> 2417190383920
	2417191780592 [label="encoder.features.denseblock2.denselayer2.norm2.bias
 (128)" fillcolor=lightblue]
	2417191780592 -> 2417190381472
	2417190381472 [label=AccumulateGrad]
	2417190386320 -> 2417190384592
	2417191781552 [label="encoder.features.denseblock2.denselayer2.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2417191781552 -> 2417190386320
	2417190386320 [label=AccumulateGrad]
	2417190379888 -> 2417190373792
	2417190379888 [label=ConvolutionBackward0]
	2417190386224 -> 2417190379888
	2417190386224 [label=ReluBackward0]
	2417190377920 -> 2417190386224
	2417190377920 [label=CudnnBatchNormBackward0]
	2417190380704 -> 2417190377920
	2417190380704 [label=ConvolutionBackward0]
	2417190385024 -> 2417190380704
	2417190385024 [label=ReluBackward0]
	2417190386512 -> 2417190385024
	2417190386512 [label=CudnnBatchNormBackward0]
	2417190376912 -> 2417190386512
	2417190376912 [label=CatBackward0]
	2417190371392 -> 2417190376912
	2417190376000 -> 2417190376912
	2417190384592 -> 2417190376912
	2417190375760 -> 2417190386512
	2417191780992 [label="encoder.features.denseblock2.denselayer3.norm1.weight
 (192)" fillcolor=lightblue]
	2417191780992 -> 2417190375760
	2417190375760 [label=AccumulateGrad]
	2417190376768 -> 2417190386512
	2417191780672 [label="encoder.features.denseblock2.denselayer3.norm1.bias
 (192)" fillcolor=lightblue]
	2417191780672 -> 2417190376768
	2417190376768 [label=AccumulateGrad]
	2417190373936 -> 2417190380704
	2417191782432 [label="encoder.features.denseblock2.denselayer3.conv1.weight
 (128, 192, 1, 1)" fillcolor=lightblue]
	2417191782432 -> 2417190373936
	2417190373936 [label=AccumulateGrad]
	2417190381280 -> 2417190377920
	2417191784032 [label="encoder.features.denseblock2.denselayer3.norm2.weight
 (128)" fillcolor=lightblue]
	2417191784032 -> 2417190381280
	2417190381280 [label=AccumulateGrad]
	2417190381712 -> 2417190377920
	2417191783712 [label="encoder.features.denseblock2.denselayer3.norm2.bias
 (128)" fillcolor=lightblue]
	2417191783712 -> 2417190381712
	2417190381712 [label=AccumulateGrad]
	2417190372736 -> 2417190379888
	2417191784112 [label="encoder.features.denseblock2.denselayer3.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2417191784112 -> 2417190372736
	2417190372736 [label=AccumulateGrad]
	2417190372832 -> 2417190373792
	2417190372832 [label=ConvolutionBackward0]
	2417190381040 -> 2417190372832
	2417190381040 [label=ReluBackward0]
	2417190381952 -> 2417190381040
	2417190381952 [label=CudnnBatchNormBackward0]
	2417190378016 -> 2417190381952
	2417190378016 [label=ConvolutionBackward0]
	2417190379648 -> 2417190378016
	2417190379648 [label=ReluBackward0]
	2416913184032 -> 2417190379648
	2416913184032 [label=CudnnBatchNormBackward0]
	2416913175920 -> 2416913184032
	2416913175920 [label=CatBackward0]
	2417190371392 -> 2416913175920
	2417190376000 -> 2416913175920
	2417190384592 -> 2416913175920
	2417190379888 -> 2416913175920
	2416913183552 -> 2416913184032
	2417191784192 [label="encoder.features.denseblock2.denselayer4.norm1.weight
 (224)" fillcolor=lightblue]
	2417191784192 -> 2416913183552
	2416913183552 [label=AccumulateGrad]
	2416913171312 -> 2416913184032
	2417191784592 [label="encoder.features.denseblock2.denselayer4.norm1.bias
 (224)" fillcolor=lightblue]
	2417191784592 -> 2416913171312
	2416913171312 [label=AccumulateGrad]
	2416913176736 -> 2417190378016
	2417191787152 [label="encoder.features.denseblock2.denselayer4.conv1.weight
 (128, 224, 1, 1)" fillcolor=lightblue]
	2417191787152 -> 2416913176736
	2416913176736 [label=AccumulateGrad]
	2417190383632 -> 2417190381952
	2417191786832 [label="encoder.features.denseblock2.denselayer4.norm2.weight
 (128)" fillcolor=lightblue]
	2417191786832 -> 2417190383632
	2417190383632 [label=AccumulateGrad]
	2417190383776 -> 2417190381952
	2417191786512 [label="encoder.features.denseblock2.denselayer4.norm2.bias
 (128)" fillcolor=lightblue]
	2417191786512 -> 2417190383776
	2417190383776 [label=AccumulateGrad]
	2417190378496 -> 2417190372832
	2417191787472 [label="encoder.features.denseblock2.denselayer4.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2417191787472 -> 2417190378496
	2417190378496 [label=AccumulateGrad]
	2417190375952 -> 2417190373792
	2417190375952 [label=ConvolutionBackward0]
	2417190374752 -> 2417190375952
	2417190374752 [label=ReluBackward0]
	2416913182880 -> 2417190374752
	2416913182880 [label=CudnnBatchNormBackward0]
	2416913173616 -> 2416913182880
	2416913173616 [label=ConvolutionBackward0]
	2416913183456 -> 2416913173616
	2416913183456 [label=ReluBackward0]
	2416913177168 -> 2416913183456
	2416913177168 [label=CudnnBatchNormBackward0]
	2416913183408 -> 2416913177168
	2416913183408 [label=CatBackward0]
	2417190371392 -> 2416913183408
	2417190376000 -> 2416913183408
	2417190384592 -> 2416913183408
	2417190379888 -> 2416913183408
	2417190372832 -> 2416913183408
	2416913186288 -> 2416913177168
	2417191787312 [label="encoder.features.denseblock2.denselayer5.norm1.weight
 (256)" fillcolor=lightblue]
	2417191787312 -> 2416913186288
	2416913186288 [label=AccumulateGrad]
	2416913186240 -> 2416913177168
	2417191787792 [label="encoder.features.denseblock2.denselayer5.norm1.bias
 (256)" fillcolor=lightblue]
	2417191787792 -> 2416913186240
	2416913186240 [label=AccumulateGrad]
	2416913183744 -> 2416913173616
	2417191789872 [label="encoder.features.denseblock2.denselayer5.conv1.weight
 (128, 256, 1, 1)" fillcolor=lightblue]
	2417191789872 -> 2416913183744
	2416913183744 [label=AccumulateGrad]
	2416913177936 -> 2416913182880
	2417191789712 [label="encoder.features.denseblock2.denselayer5.norm2.weight
 (128)" fillcolor=lightblue]
	2417191789712 -> 2416913177936
	2416913177936 [label=AccumulateGrad]
	2416913184992 -> 2416913182880
	2417191789392 [label="encoder.features.denseblock2.denselayer5.norm2.bias
 (128)" fillcolor=lightblue]
	2417191789392 -> 2416913184992
	2416913184992 [label=AccumulateGrad]
	2417190387136 -> 2417190375952
	2417191790912 [label="encoder.features.denseblock2.denselayer5.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2417191790912 -> 2417190387136
	2417190387136 [label=AccumulateGrad]
	2417190376288 -> 2417190373792
	2417190376288 [label=ConvolutionBackward0]
	2417190381232 -> 2417190376288
	2417190381232 [label=ReluBackward0]
	2416913182496 -> 2417190381232
	2416913182496 [label=CudnnBatchNormBackward0]
	2416913184272 -> 2416913182496
	2416913184272 [label=ConvolutionBackward0]
	2416913179424 -> 2416913184272
	2416913179424 [label=ReluBackward0]
	2416913183600 -> 2416913179424
	2416913183600 [label=CudnnBatchNormBackward0]
	2416913186432 -> 2416913183600
	2416913186432 [label=CatBackward0]
	2417190371392 -> 2416913186432
	2417190376000 -> 2416913186432
	2417190384592 -> 2416913186432
	2417190379888 -> 2416913186432
	2417190372832 -> 2416913186432
	2417190375952 -> 2416913186432
	2416913186576 -> 2416913183600
	2417191792352 [label="encoder.features.denseblock2.denselayer6.norm1.weight
 (288)" fillcolor=lightblue]
	2417191792352 -> 2416913186576
	2416913186576 [label=AccumulateGrad]
	2416913184320 -> 2416913183600
	2417191792192 [label="encoder.features.denseblock2.denselayer6.norm1.bias
 (288)" fillcolor=lightblue]
	2417191792192 -> 2416913184320
	2416913184320 [label=AccumulateGrad]
	2416913178992 -> 2416913184272
	2417191792832 [label="encoder.features.denseblock2.denselayer6.conv1.weight
 (128, 288, 1, 1)" fillcolor=lightblue]
	2417191792832 -> 2416913178992
	2416913178992 [label=AccumulateGrad]
	2416913178800 -> 2416913182496
	2417191792512 [label="encoder.features.denseblock2.denselayer6.norm2.weight
 (128)" fillcolor=lightblue]
	2417191792512 -> 2416913178800
	2416913178800 [label=AccumulateGrad]
	2416913183168 -> 2416913182496
	2417191792992 [label="encoder.features.denseblock2.denselayer6.norm2.bias
 (128)" fillcolor=lightblue]
	2417191792992 -> 2416913183168
	2416913183168 [label=AccumulateGrad]
	2416913186528 -> 2417190376288
	2417191795392 [label="encoder.features.denseblock2.denselayer6.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2417191795392 -> 2416913186528
	2416913186528 [label=AccumulateGrad]
	2417190376384 -> 2417190373792
	2417190376384 [label=ConvolutionBackward0]
	2416913185856 -> 2417190376384
	2416913185856 [label=ReluBackward0]
	2416913182304 -> 2416913185856
	2416913182304 [label=CudnnBatchNormBackward0]
	2416913185040 -> 2416913182304
	2416913185040 [label=ConvolutionBackward0]
	2416913183984 -> 2416913185040
	2416913183984 [label=ReluBackward0]
	2416913182544 -> 2416913183984
	2416913182544 [label=CudnnBatchNormBackward0]
	2416913172656 -> 2416913182544
	2416913172656 [label=CatBackward0]
	2417190371392 -> 2416913172656
	2417190376000 -> 2416913172656
	2417190384592 -> 2416913172656
	2417190379888 -> 2416913172656
	2417190372832 -> 2416913172656
	2417190375952 -> 2416913172656
	2417190376288 -> 2416913172656
	2416913179040 -> 2416913182544
	2417191795072 [label="encoder.features.denseblock2.denselayer7.norm1.weight
 (320)" fillcolor=lightblue]
	2417191795072 -> 2416913179040
	2416913179040 [label=AccumulateGrad]
	2416913181344 -> 2416913182544
	2417191794752 [label="encoder.features.denseblock2.denselayer7.norm1.bias
 (320)" fillcolor=lightblue]
	2417191794752 -> 2416913181344
	2416913181344 [label=AccumulateGrad]
	2416913184896 -> 2416913185040
	2417191796192 [label="encoder.features.denseblock2.denselayer7.conv1.weight
 (128, 320, 1, 1)" fillcolor=lightblue]
	2417191796192 -> 2416913184896
	2416913184896 [label=AccumulateGrad]
	2416913184128 -> 2416913182304
	2417191796672 [label="encoder.features.denseblock2.denselayer7.norm2.weight
 (128)" fillcolor=lightblue]
	2417191796672 -> 2416913184128
	2416913184128 [label=AccumulateGrad]
	2416913186144 -> 2416913182304
	2417191796352 [label="encoder.features.denseblock2.denselayer7.norm2.bias
 (128)" fillcolor=lightblue]
	2417191796352 -> 2416913186144
	2416913186144 [label=AccumulateGrad]
	2416913170928 -> 2417190376384
	2417191787872 [label="encoder.features.denseblock2.denselayer7.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2417191787872 -> 2416913170928
	2416913170928 [label=AccumulateGrad]
	2417190377200 -> 2417190373792
	2417190377200 [label=ConvolutionBackward0]
	2416913183888 -> 2417190377200
	2416913183888 [label=ReluBackward0]
	2416913183792 -> 2416913183888
	2416913183792 [label=CudnnBatchNormBackward0]
	2416913182832 -> 2416913183792
	2416913182832 [label=ConvolutionBackward0]
	2416913174192 -> 2416913182832
	2416913174192 [label=ReluBackward0]
	2416913185328 -> 2416913174192
	2416913185328 [label=CudnnBatchNormBackward0]
	2416913177120 -> 2416913185328
	2416913177120 [label=CatBackward0]
	2417190371392 -> 2416913177120
	2417190376000 -> 2416913177120
	2417190384592 -> 2416913177120
	2417190379888 -> 2416913177120
	2417190372832 -> 2416913177120
	2417190375952 -> 2416913177120
	2417190376288 -> 2416913177120
	2417190376384 -> 2416913177120
	2416913181200 -> 2416913185328
	2417191794832 [label="encoder.features.denseblock2.denselayer8.norm1.weight
 (352)" fillcolor=lightblue]
	2417191794832 -> 2416913181200
	2416913181200 [label=AccumulateGrad]
	2416913171504 -> 2416913185328
	2417191796112 [label="encoder.features.denseblock2.denselayer8.norm1.bias
 (352)" fillcolor=lightblue]
	2417191796112 -> 2416913171504
	2416913171504 [label=AccumulateGrad]
	2416913171936 -> 2416913182832
	2417184516336 [label="encoder.features.denseblock2.denselayer8.conv1.weight
 (128, 352, 1, 1)" fillcolor=lightblue]
	2417184516336 -> 2416913171936
	2416913171936 [label=AccumulateGrad]
	2416913183696 -> 2416913183792
	2417184517616 [label="encoder.features.denseblock2.denselayer8.norm2.weight
 (128)" fillcolor=lightblue]
	2417184517616 -> 2416913183696
	2416913183696 [label=AccumulateGrad]
	2416913173184 -> 2416913183792
	2417184516976 [label="encoder.features.denseblock2.denselayer8.norm2.bias
 (128)" fillcolor=lightblue]
	2417184516976 -> 2416913173184
	2416913173184 [label=AccumulateGrad]
	2416913170880 -> 2417190377200
	2417184511296 [label="encoder.features.denseblock2.denselayer8.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2417184511296 -> 2416913170880
	2416913170880 [label=AccumulateGrad]
	2417190376528 -> 2417190373792
	2417190376528 [label=ConvolutionBackward0]
	2416913173232 -> 2417190376528
	2416913173232 [label=ReluBackward0]
	2416913180192 -> 2416913173232
	2416913180192 [label=CudnnBatchNormBackward0]
	2416913184560 -> 2416913180192
	2416913184560 [label=ConvolutionBackward0]
	2416913175872 -> 2416913184560
	2416913175872 [label=ReluBackward0]
	2416913176544 -> 2416913175872
	2416913176544 [label=CudnnBatchNormBackward0]
	2416913170688 -> 2416913176544
	2416913170688 [label=CatBackward0]
	2417190371392 -> 2416913170688
	2417190376000 -> 2416913170688
	2417190384592 -> 2416913170688
	2417190379888 -> 2416913170688
	2417190372832 -> 2416913170688
	2417190375952 -> 2416913170688
	2417190376288 -> 2416913170688
	2417190376384 -> 2416913170688
	2417190377200 -> 2416913170688
	2416913172128 -> 2416913176544
	2417184506576 [label="encoder.features.denseblock2.denselayer9.norm1.weight
 (384)" fillcolor=lightblue]
	2417184506576 -> 2416913172128
	2416913172128 [label=AccumulateGrad]
	2416913177888 -> 2416913176544
	2417184506416 [label="encoder.features.denseblock2.denselayer9.norm1.bias
 (384)" fillcolor=lightblue]
	2417184506416 -> 2416913177888
	2416913177888 [label=AccumulateGrad]
	2416913183312 -> 2416913184560
	2417184507056 [label="encoder.features.denseblock2.denselayer9.conv1.weight
 (128, 384, 1, 1)" fillcolor=lightblue]
	2417184507056 -> 2416913183312
	2416913183312 [label=AccumulateGrad]
	2416913185712 -> 2416913180192
	2417184506896 [label="encoder.features.denseblock2.denselayer9.norm2.weight
 (128)" fillcolor=lightblue]
	2417184506896 -> 2416913185712
	2416913185712 [label=AccumulateGrad]
	2416913180864 -> 2416913180192
	2417184507296 [label="encoder.features.denseblock2.denselayer9.norm2.bias
 (128)" fillcolor=lightblue]
	2417184507296 -> 2416913180864
	2416913180864 [label=AccumulateGrad]
	2416913183024 -> 2417190376528
	2417184509056 [label="encoder.features.denseblock2.denselayer9.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2417184509056 -> 2416913183024
	2416913183024 [label=AccumulateGrad]
	2417190380176 -> 2417190373792
	2417190380176 [label=ConvolutionBackward0]
	2416913173088 -> 2417190380176
	2416913173088 [label=ReluBackward0]
	2416913184656 -> 2416913173088
	2416913184656 [label=CudnnBatchNormBackward0]
	2416913184608 -> 2416913184656
	2416913184608 [label=ConvolutionBackward0]
	2416913182976 -> 2416913184608
	2416913182976 [label=ReluBackward0]
	2416913172176 -> 2416913182976
	2416913172176 [label=CudnnBatchNormBackward0]
	2416913172608 -> 2416913172176
	2416913172608 [label=CatBackward0]
	2417190371392 -> 2416913172608
	2417190376000 -> 2416913172608
	2417190384592 -> 2416913172608
	2417190379888 -> 2416913172608
	2417190372832 -> 2416913172608
	2417190375952 -> 2416913172608
	2417190376288 -> 2416913172608
	2417190376384 -> 2416913172608
	2417190377200 -> 2416913172608
	2417190376528 -> 2416913172608
	2416913185904 -> 2416913172176
	2417184508896 [label="encoder.features.denseblock2.denselayer10.norm1.weight
 (416)" fillcolor=lightblue]
	2417184508896 -> 2416913185904
	2416913185904 [label=AccumulateGrad]
	2416913184368 -> 2416913172176
	2417184509376 [label="encoder.features.denseblock2.denselayer10.norm1.bias
 (416)" fillcolor=lightblue]
	2417184509376 -> 2416913184368
	2416913184368 [label=AccumulateGrad]
	2416913180240 -> 2416913184608
	2417184512096 [label="encoder.features.denseblock2.denselayer10.conv1.weight
 (128, 416, 1, 1)" fillcolor=lightblue]
	2417184512096 -> 2416913180240
	2416913180240 [label=AccumulateGrad]
	2416913174336 -> 2416913184656
	2417184511856 [label="encoder.features.denseblock2.denselayer10.norm2.weight
 (128)" fillcolor=lightblue]
	2417184511856 -> 2416913174336
	2416913174336 [label=AccumulateGrad]
	2416913181296 -> 2416913184656
	2417184511376 [label="encoder.features.denseblock2.denselayer10.norm2.bias
 (128)" fillcolor=lightblue]
	2417184511376 -> 2416913181296
	2416913181296 [label=AccumulateGrad]
	2416913186384 -> 2417190380176
	2417184512416 [label="encoder.features.denseblock2.denselayer10.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2417184512416 -> 2416913186384
	2416913186384 [label=AccumulateGrad]
	2417190378160 -> 2417190373792
	2417190378160 [label=ConvolutionBackward0]
	2416913186192 -> 2417190378160
	2416913186192 [label=ReluBackward0]
	2416913185808 -> 2416913186192
	2416913185808 [label=CudnnBatchNormBackward0]
	2416913184224 -> 2416913185808
	2416913184224 [label=ConvolutionBackward0]
	2416913172512 -> 2416913184224
	2416913172512 [label=ReluBackward0]
	2416913174384 -> 2416913172512
	2416913174384 [label=CudnnBatchNormBackward0]
	2416913181920 -> 2416913174384
	2416913181920 [label=CatBackward0]
	2417190371392 -> 2416913181920
	2417190376000 -> 2416913181920
	2417190384592 -> 2416913181920
	2417190379888 -> 2416913181920
	2417190372832 -> 2416913181920
	2417190375952 -> 2416913181920
	2417190376288 -> 2416913181920
	2417190376384 -> 2416913181920
	2417190377200 -> 2416913181920
	2417190376528 -> 2416913181920
	2417190380176 -> 2416913181920
	2416913180624 -> 2416913174384
	2417184512736 [label="encoder.features.denseblock2.denselayer11.norm1.weight
 (448)" fillcolor=lightblue]
	2417184512736 -> 2416913180624
	2416913180624 [label=AccumulateGrad]
	2416913170736 -> 2416913174384
	2417184514336 [label="encoder.features.denseblock2.denselayer11.norm1.bias
 (448)" fillcolor=lightblue]
	2417184514336 -> 2416913170736
	2416913170736 [label=AccumulateGrad]
	2416913183504 -> 2416913184224
	2417184514656 [label="encoder.features.denseblock2.denselayer11.conv1.weight
 (128, 448, 1, 1)" fillcolor=lightblue]
	2417184514656 -> 2416913183504
	2416913183504 [label=AccumulateGrad]
	2416913184080 -> 2416913185808
	2417184514496 [label="encoder.features.denseblock2.denselayer11.norm2.weight
 (128)" fillcolor=lightblue]
	2417184514496 -> 2416913184080
	2416913184080 [label=AccumulateGrad]
	2416913186048 -> 2416913185808
	2417184514976 [label="encoder.features.denseblock2.denselayer11.norm2.bias
 (128)" fillcolor=lightblue]
	2417184514976 -> 2416913186048
	2416913186048 [label=AccumulateGrad]
	2416913183936 -> 2417190378160
	2417184516896 [label="encoder.features.denseblock2.denselayer11.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2417184516896 -> 2416913183936
	2416913183936 [label=AccumulateGrad]
	2417190379216 -> 2417190373792
	2417190379216 [label=ConvolutionBackward0]
	2416913185088 -> 2417190379216
	2416913185088 [label=ReluBackward0]
	2416913179616 -> 2416913185088
	2416913179616 [label=CudnnBatchNormBackward0]
	2416913177360 -> 2416913179616
	2416913177360 [label=ConvolutionBackward0]
	2416913173856 -> 2416913177360
	2416913173856 [label=ReluBackward0]
	2416913173808 -> 2416913173856
	2416913173808 [label=CudnnBatchNormBackward0]
	2416913175344 -> 2416913173808
	2416913175344 [label=CatBackward0]
	2417190371392 -> 2416913175344
	2417190376000 -> 2416913175344
	2417190384592 -> 2416913175344
	2417190379888 -> 2416913175344
	2417190372832 -> 2416913175344
	2417190375952 -> 2416913175344
	2417190376288 -> 2416913175344
	2417190376384 -> 2416913175344
	2417190377200 -> 2416913175344
	2417190376528 -> 2416913175344
	2417190380176 -> 2416913175344
	2417190378160 -> 2416913175344
	2416913184944 -> 2416913173808
	2417184516416 [label="encoder.features.denseblock2.denselayer12.norm1.weight
 (480)" fillcolor=lightblue]
	2417184516416 -> 2416913184944
	2416913184944 [label=AccumulateGrad]
	2416913176496 -> 2416913173808
	2417184516256 [label="encoder.features.denseblock2.denselayer12.norm1.bias
 (480)" fillcolor=lightblue]
	2417184516256 -> 2416913176496
	2416913176496 [label=AccumulateGrad]
	2416913178416 -> 2416913177360
	2417184517696 [label="encoder.features.denseblock2.denselayer12.conv1.weight
 (128, 480, 1, 1)" fillcolor=lightblue]
	2417184517696 -> 2416913178416
	2416913178416 [label=AccumulateGrad]
	2416913176064 -> 2416913179616
	2417184519136 [label="encoder.features.denseblock2.denselayer12.norm2.weight
 (128)" fillcolor=lightblue]
	2417184519136 -> 2416913176064
	2416913176064 [label=AccumulateGrad]
	2416913180816 -> 2416913179616
	2417184518976 [label="encoder.features.denseblock2.denselayer12.norm2.bias
 (128)" fillcolor=lightblue]
	2417184518976 -> 2416913180816
	2416913180816 [label=AccumulateGrad]
	2416913184800 -> 2417190379216
	2417184519616 [label="encoder.features.denseblock2.denselayer12.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2417184519616 -> 2416913184800
	2416913184800 [label=AccumulateGrad]
	2417190373312 -> 2417190380272
	2417184519456 [label="encoder.features.transition2.norm.weight
 (512)" fillcolor=lightblue]
	2417184519456 -> 2417190373312
	2417190373312 [label=AccumulateGrad]
	2417190384400 -> 2417190380272
	2417184519776 [label="encoder.features.transition2.norm.bias
 (512)" fillcolor=lightblue]
	2417184519776 -> 2417190384400
	2417190384400 [label=AccumulateGrad]
	2417190373648 -> 2417190381856
	2417184522176 [label="encoder.features.transition2.conv.weight
 (256, 512, 1, 1)" fillcolor=lightblue]
	2417184522176 -> 2417190373648
	2417190373648 [label=AccumulateGrad]
	2417190375184 -> 2417190386704
	2417190375184 [label=ConvolutionBackward0]
	2417190371632 -> 2417190375184
	2417190371632 [label=ReluBackward0]
	2417190372160 -> 2417190371632
	2417190372160 [label=CudnnBatchNormBackward0]
	2416913175536 -> 2417190372160
	2416913175536 [label=ConvolutionBackward0]
	2416913186720 -> 2416913175536
	2416913186720 [label=ReluBackward0]
	2416913181728 -> 2416913186720
	2416913181728 [label=CudnnBatchNormBackward0]
	2416913186336 -> 2416913181728
	2416913186336 [label=CatBackward0]
	2417190382288 -> 2416913186336
	2416913178848 -> 2416913181728
	2417184520896 [label="encoder.features.denseblock3.denselayer1.norm1.weight
 (256)" fillcolor=lightblue]
	2417184520896 -> 2416913178848
	2416913178848 [label=AccumulateGrad]
	2416913176112 -> 2416913181728
	2417184521536 [label="encoder.features.denseblock3.denselayer1.norm1.bias
 (256)" fillcolor=lightblue]
	2417184521536 -> 2416913176112
	2416913176112 [label=AccumulateGrad]
	2416913175296 -> 2416913175536
	2417184507136 [label="encoder.features.denseblock3.denselayer1.conv1.weight
 (128, 256, 1, 1)" fillcolor=lightblue]
	2417184507136 -> 2416913175296
	2416913175296 [label=AccumulateGrad]
	2416913180672 -> 2417190372160
	2417184518896 [label="encoder.features.denseblock3.denselayer1.norm2.weight
 (128)" fillcolor=lightblue]
	2417184518896 -> 2416913180672
	2416913180672 [label=AccumulateGrad]
	2416913176688 -> 2417190372160
	2417184509456 [label="encoder.features.denseblock3.denselayer1.norm2.bias
 (128)" fillcolor=lightblue]
	2417184509456 -> 2416913176688
	2416913176688 [label=AccumulateGrad]
	2417190375712 -> 2417190375184
	2417185203024 [label="encoder.features.denseblock3.denselayer1.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2417185203024 -> 2417190375712
	2417190375712 [label=AccumulateGrad]
	2417190383584 -> 2417190386704
	2417190383584 [label=ConvolutionBackward0]
	2417190378400 -> 2417190383584
	2417190378400 [label=ReluBackward0]
	2416913173040 -> 2417190378400
	2416913173040 [label=CudnnBatchNormBackward0]
	2416913184704 -> 2416913173040
	2416913184704 [label=ConvolutionBackward0]
	2416913183648 -> 2416913184704
	2416913183648 [label=ReluBackward0]
	2416913183120 -> 2416913183648
	2416913183120 [label=CudnnBatchNormBackward0]
	2416913182736 -> 2416913183120
	2416913182736 [label=CatBackward0]
	2417190382288 -> 2416913182736
	2417190375184 -> 2416913182736
	2416913182640 -> 2416913183120
	2417185208704 [label="encoder.features.denseblock3.denselayer2.norm1.weight
 (288)" fillcolor=lightblue]
	2417185208704 -> 2416913182640
	2416913182640 [label=AccumulateGrad]
	2416913183216 -> 2416913183120
	2417185207424 [label="encoder.features.denseblock3.denselayer2.norm1.bias
 (288)" fillcolor=lightblue]
	2417185207424 -> 2416913183216
	2416913183216 [label=AccumulateGrad]
	2416913183264 -> 2416913184704
	2417191762784 [label="encoder.features.denseblock3.denselayer2.conv1.weight
 (128, 288, 1, 1)" fillcolor=lightblue]
	2417191762784 -> 2416913183264
	2416913183264 [label=AccumulateGrad]
	2416913186768 -> 2416913173040
	2417191760224 [label="encoder.features.denseblock3.denselayer2.norm2.weight
 (128)" fillcolor=lightblue]
	2417191760224 -> 2416913186768
	2416913186768 [label=AccumulateGrad]
	2416913186672 -> 2416913173040
	2417191761504 [label="encoder.features.denseblock3.denselayer2.norm2.bias
 (128)" fillcolor=lightblue]
	2417191761504 -> 2416913186672
	2416913186672 [label=AccumulateGrad]
	2417190381328 -> 2417190383584
	2417184948464 [label="encoder.features.denseblock3.denselayer2.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2417184948464 -> 2417190381328
	2417190381328 [label=AccumulateGrad]
	2417190380656 -> 2417190386704
	2417190380656 [label=ConvolutionBackward0]
	2416913184416 -> 2417190380656
	2416913184416 [label=ReluBackward0]
	2416913184464 -> 2416913184416
	2416913184464 [label=CudnnBatchNormBackward0]
	2416913182592 -> 2416913184464
	2416913182592 [label=ConvolutionBackward0]
	2416913182208 -> 2416913182592
	2416913182208 [label=ReluBackward0]
	2416913182256 -> 2416913182208
	2416913182256 [label=CudnnBatchNormBackward0]
	2416913182160 -> 2416913182256
	2416913182160 [label=CatBackward0]
	2417190382288 -> 2416913182160
	2417190375184 -> 2416913182160
	2417190383584 -> 2416913182160
	2416913181824 -> 2416913182256
	2417184957984 [label="encoder.features.denseblock3.denselayer3.norm1.weight
 (320)" fillcolor=lightblue]
	2417184957984 -> 2416913181824
	2416913181824 [label=AccumulateGrad]
	2416913182112 -> 2416913182256
	2417184952224 [label="encoder.features.denseblock3.denselayer3.norm1.bias
 (320)" fillcolor=lightblue]
	2417184952224 -> 2416913182112
	2416913182112 [label=AccumulateGrad]
	2416913182016 -> 2416913182592
	2417184951584 [label="encoder.features.denseblock3.denselayer3.conv1.weight
 (128, 320, 1, 1)" fillcolor=lightblue]
	2417184951584 -> 2416913182016
	2416913182016 [label=AccumulateGrad]
	2416913182688 -> 2416913184464
	2417184948384 [label="encoder.features.denseblock3.denselayer3.norm2.weight
 (128)" fillcolor=lightblue]
	2417184948384 -> 2416913182688
	2416913182688 [label=AccumulateGrad]
	2416913182928 -> 2416913184464
	2417184949824 [label="encoder.features.denseblock3.denselayer3.norm2.bias
 (128)" fillcolor=lightblue]
	2417184949824 -> 2416913182928
	2416913182928 [label=AccumulateGrad]
	2416913174960 -> 2417190380656
	2417184950624 [label="encoder.features.denseblock3.denselayer3.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2417184950624 -> 2416913174960
	2416913174960 [label=AccumulateGrad]
	2417190378880 -> 2417190386704
	2417190378880 [label=ConvolutionBackward0]
	2416913182448 -> 2417190378880
	2416913182448 [label=ReluBackward0]
	2416913182400 -> 2416913182448
	2416913182400 [label=CudnnBatchNormBackward0]
	2416913181440 -> 2416913182400
	2416913181440 [label=ConvolutionBackward0]
	2416913181584 -> 2416913181440
	2416913181584 [label=ReluBackward0]
	2416913181008 -> 2416913181584
	2416913181008 [label=CudnnBatchNormBackward0]
	2416913180960 -> 2416913181008
	2416913180960 [label=CatBackward0]
	2417190382288 -> 2416913180960
	2417190375184 -> 2416913180960
	2417190383584 -> 2416913180960
	2417190380656 -> 2416913180960
	2416913181056 -> 2416913181008
	2417184950304 [label="encoder.features.denseblock3.denselayer4.norm1.weight
 (352)" fillcolor=lightblue]
	2417184950304 -> 2416913181056
	2416913181056 [label=AccumulateGrad]
	2416913180912 -> 2416913181008
	2417184949984 [label="encoder.features.denseblock3.denselayer4.norm1.bias
 (352)" fillcolor=lightblue]
	2417184949984 -> 2416913180912
	2416913180912 [label=AccumulateGrad]
	2416913181104 -> 2416913181440
	2417184951664 [label="encoder.features.denseblock3.denselayer4.conv1.weight
 (128, 352, 1, 1)" fillcolor=lightblue]
	2417184951664 -> 2416913181104
	2416913181104 [label=AccumulateGrad]
	2416913181536 -> 2416913182400
	2417184953104 [label="encoder.features.denseblock3.denselayer4.norm2.weight
 (128)" fillcolor=lightblue]
	2417184953104 -> 2416913181536
	2416913181536 [label=AccumulateGrad]
	2416913182064 -> 2416913182400
	2417184952944 [label="encoder.features.denseblock3.denselayer4.norm2.bias
 (128)" fillcolor=lightblue]
	2417184952944 -> 2416913182064
	2416913182064 [label=AccumulateGrad]
	2416913182784 -> 2417190378880
	2417184953584 [label="encoder.features.denseblock3.denselayer4.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2417184953584 -> 2416913182784
	2416913182784 [label=AccumulateGrad]
	2417190377968 -> 2417190386704
	2417190377968 [label=ConvolutionBackward0]
	2416913181680 -> 2417190377968
	2416913181680 [label=ReluBackward0]
	2416913181488 -> 2416913181680
	2416913181488 [label=CudnnBatchNormBackward0]
	2416913180720 -> 2416913181488
	2416913180720 [label=ConvolutionBackward0]
	2416913180576 -> 2416913180720
	2416913180576 [label=ReluBackward0]
	2416913180144 -> 2416913180576
	2416913180144 [label=CudnnBatchNormBackward0]
	2416913179904 -> 2416913180144
	2416913179904 [label=CatBackward0]
	2417190382288 -> 2416913179904
	2417190375184 -> 2416913179904
	2417190383584 -> 2416913179904
	2417190380656 -> 2416913179904
	2417190378880 -> 2416913179904
	2416913179712 -> 2416913180144
	2417184953424 [label="encoder.features.denseblock3.denselayer5.norm1.weight
 (384)" fillcolor=lightblue]
	2417184953424 -> 2416913179712
	2416913179712 [label=AccumulateGrad]
	2416913180480 -> 2416913180144
	2417184953744 [label="encoder.features.denseblock3.denselayer5.norm1.bias
 (384)" fillcolor=lightblue]
	2417184953744 -> 2416913180480
	2416913180480 [label=AccumulateGrad]
	2416913180384 -> 2416913180720
	2417184956304 [label="encoder.features.denseblock3.denselayer5.conv1.weight
 (128, 384, 1, 1)" fillcolor=lightblue]
	2417184956304 -> 2416913180384
	2416913180384 [label=AccumulateGrad]
	2416913180528 -> 2416913181488
	2417184956144 [label="encoder.features.denseblock3.denselayer5.norm2.weight
 (128)" fillcolor=lightblue]
	2417184956144 -> 2416913180528
	2416913180528 [label=AccumulateGrad]
	2416913181152 -> 2416913181488
	2417184955664 [label="encoder.features.denseblock3.denselayer5.norm2.bias
 (128)" fillcolor=lightblue]
	2417184955664 -> 2416913181152
	2416913181152 [label=AccumulateGrad]
	2416913181632 -> 2417190377968
	2417184957264 [label="encoder.features.denseblock3.denselayer5.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2417184957264 -> 2416913181632
	2416913181632 [label=AccumulateGrad]
	2417190383440 -> 2417190386704
	2417190383440 [label=ConvolutionBackward0]
	2416913180336 -> 2417190383440
	2416913180336 [label=ReluBackward0]
	2416913180432 -> 2416913180336
	2416913180432 [label=CudnnBatchNormBackward0]
	2416913179952 -> 2416913180432
	2416913179952 [label=ConvolutionBackward0]
	2416913179520 -> 2416913179952
	2416913179520 [label=ReluBackward0]
	2416913179232 -> 2416913179520
	2416913179232 [label=CudnnBatchNormBackward0]
	2416913179184 -> 2416913179232
	2416913179184 [label=CatBackward0]
	2417190382288 -> 2416913179184
	2417190375184 -> 2416913179184
	2417190383584 -> 2416913179184
	2417190380656 -> 2416913179184
	2417190378880 -> 2416913179184
	2417190377968 -> 2416913179184
	2416913179280 -> 2416913179232
	2417184958224 [label="encoder.features.denseblock3.denselayer6.norm1.weight
 (416)" fillcolor=lightblue]
	2417184958224 -> 2416913179280
	2416913179280 [label=AccumulateGrad]
	2416913179136 -> 2416913179232
	2417184958064 [label="encoder.features.denseblock3.denselayer6.norm1.bias
 (416)" fillcolor=lightblue]
	2417184958064 -> 2416913179136
	2416913179136 [label=AccumulateGrad]
	2416913179328 -> 2416913179952
	2417184958704 [label="encoder.features.denseblock3.denselayer6.conv1.weight
 (128, 416, 1, 1)" fillcolor=lightblue]
	2417184958704 -> 2416913179328
	2416913179328 [label=AccumulateGrad]
	2416913179760 -> 2416913180432
	2417184958544 [label="encoder.features.denseblock3.denselayer6.norm2.weight
 (128)" fillcolor=lightblue]
	2417184958544 -> 2416913179760
	2416913179760 [label=AccumulateGrad]
	2416913180096 -> 2416913180432
	2417184958864 [label="encoder.features.denseblock3.denselayer6.norm2.bias
 (128)" fillcolor=lightblue]
	2417184958864 -> 2416913180096
	2416913180096 [label=AccumulateGrad]
	2416913180768 -> 2417190383440
	2417184961344 [label="encoder.features.denseblock3.denselayer6.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2417184961344 -> 2416913180768
	2416913180768 [label=AccumulateGrad]
	2417190375232 -> 2417190386704
	2417190375232 [label=ConvolutionBackward0]
	2416913179856 -> 2417190375232
	2416913179856 [label=ReluBackward0]
	2416913179568 -> 2416913179856
	2416913179568 [label=CudnnBatchNormBackward0]
	2416913178896 -> 2416913179568
	2416913178896 [label=ConvolutionBackward0]
	2416913178752 -> 2416913178896
	2416913178752 [label=ReluBackward0]
	2416913178368 -> 2416913178752
	2416913178368 [label=CudnnBatchNormBackward0]
	2416913177984 -> 2416913178368
	2416913177984 [label=CatBackward0]
	2417190382288 -> 2416913177984
	2417190375184 -> 2416913177984
	2417190383584 -> 2416913177984
	2417190380656 -> 2416913177984
	2417190378880 -> 2416913177984
	2417190377968 -> 2416913177984
	2417190383440 -> 2416913177984
	2416913178080 -> 2416913178368
	2417184961264 [label="encoder.features.denseblock3.denselayer7.norm1.weight
 (448)" fillcolor=lightblue]
	2417184961264 -> 2416913178080
	2416913178080 [label=AccumulateGrad]
	2416913178656 -> 2416913178368
	2417184960784 [label="encoder.features.denseblock3.denselayer7.norm1.bias
 (448)" fillcolor=lightblue]
	2417184960784 -> 2416913178656
	2416913178656 [label=AccumulateGrad]
	2416913178560 -> 2416913178896
	2417184961744 [label="encoder.features.denseblock3.denselayer7.conv1.weight
 (128, 448, 1, 1)" fillcolor=lightblue]
	2417184961744 -> 2416913178560
	2416913178560 [label=AccumulateGrad]
	2416913178704 -> 2416913179568
	2417184962064 [label="encoder.features.denseblock3.denselayer7.norm2.weight
 (128)" fillcolor=lightblue]
	2417184962064 -> 2416913178704
	2416913178704 [label=AccumulateGrad]
	2416913179376 -> 2416913179568
	2417184963664 [label="encoder.features.denseblock3.denselayer7.norm2.bias
 (128)" fillcolor=lightblue]
	2417184963664 -> 2416913179376
	2416913179376 [label=AccumulateGrad]
	2416913179808 -> 2417190375232
	2417184964464 [label="encoder.features.denseblock3.denselayer7.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2417184964464 -> 2416913179808
	2416913179808 [label=AccumulateGrad]
	2417190384688 -> 2417190386704
	2417190384688 [label=ConvolutionBackward0]
	2416913178512 -> 2417190384688
	2416913178512 [label=ReluBackward0]
	2416913178608 -> 2416913178512
	2416913178608 [label=CudnnBatchNormBackward0]
	2416913178032 -> 2416913178608
	2416913178032 [label=ConvolutionBackward0]
	2416913177456 -> 2416913178032
	2416913177456 [label=ReluBackward0]
	2416913177504 -> 2416913177456
	2416913177504 [label=CudnnBatchNormBackward0]
	2416913177264 -> 2416913177504
	2416913177264 [label=CatBackward0]
	2417190382288 -> 2416913177264
	2417190375184 -> 2416913177264
	2417190383584 -> 2416913177264
	2417190380656 -> 2416913177264
	2417190378880 -> 2416913177264
	2417190377968 -> 2416913177264
	2417190383440 -> 2416913177264
	2417190375232 -> 2416913177264
	2416913177216 -> 2416913177504
	2417184963984 [label="encoder.features.denseblock3.denselayer8.norm1.weight
 (480)" fillcolor=lightblue]
	2417184963984 -> 2416913177216
	2416913177216 [label=AccumulateGrad]
	2416913177696 -> 2416913177504
	2417184963824 [label="encoder.features.denseblock3.denselayer8.norm1.bias
 (480)" fillcolor=lightblue]
	2417184963824 -> 2416913177696
	2416913177696 [label=AccumulateGrad]
	2416913177552 -> 2416913178032
	2417184962464 [label="encoder.features.denseblock3.denselayer8.conv1.weight
 (128, 480, 1, 1)" fillcolor=lightblue]
	2417184962464 -> 2416913177552
	2416913177552 [label=AccumulateGrad]
	2416913178128 -> 2416913178608
	2417184954784 [label="encoder.features.denseblock3.denselayer8.norm2.weight
 (128)" fillcolor=lightblue]
	2417184954784 -> 2416913178128
	2416913178128 [label=AccumulateGrad]
	2416913178176 -> 2416913178608
	2417184964384 [label="encoder.features.denseblock3.denselayer8.norm2.bias
 (128)" fillcolor=lightblue]
	2417184964384 -> 2416913178176
	2416913178176 [label=AccumulateGrad]
	2416913178944 -> 2417190384688
	2417184950384 [label="encoder.features.denseblock3.denselayer8.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2417184950384 -> 2416913178944
	2416913178944 [label=AccumulateGrad]
	2417190373984 -> 2417190386704
	2417190373984 [label=ConvolutionBackward0]
	2416913177840 -> 2417190373984
	2416913177840 [label=ReluBackward0]
	2416913177648 -> 2416913177840
	2416913177648 [label=CudnnBatchNormBackward0]
	2416913176832 -> 2416913177648
	2416913176832 [label=ConvolutionBackward0]
	2416913176976 -> 2416913176832
	2416913176976 [label=ReluBackward0]
	2416913176400 -> 2416913176976
	2416913176400 [label=CudnnBatchNormBackward0]
	2416913176304 -> 2416913176400
	2416913176304 [label=CatBackward0]
	2417190382288 -> 2416913176304
	2417190375184 -> 2416913176304
	2417190383584 -> 2416913176304
	2417190380656 -> 2416913176304
	2417190378880 -> 2416913176304
	2417190377968 -> 2416913176304
	2417190383440 -> 2416913176304
	2417190375232 -> 2416913176304
	2417190384688 -> 2416913176304
	2416913176448 -> 2416913176400
	2416991663232 [label="encoder.features.denseblock3.denselayer9.norm1.weight
 (512)" fillcolor=lightblue]
	2416991663232 -> 2416913176448
	2416913176448 [label=AccumulateGrad]
	2416913176592 -> 2416913176400
	2416991663472 [label="encoder.features.denseblock3.denselayer9.norm1.bias
 (512)" fillcolor=lightblue]
	2416991663472 -> 2416913176592
	2416913176592 [label=AccumulateGrad]
	2416913176640 -> 2416913176832
	2416991663872 [label="encoder.features.denseblock3.denselayer9.conv1.weight
 (128, 512, 1, 1)" fillcolor=lightblue]
	2416991663872 -> 2416913176640
	2416913176640 [label=AccumulateGrad]
	2416913176928 -> 2416913177648
	2416991664672 [label="encoder.features.denseblock3.denselayer9.norm2.weight
 (128)" fillcolor=lightblue]
	2416991664672 -> 2416913176928
	2416913176928 [label=AccumulateGrad]
	2416913177600 -> 2416913177648
	2416991664592 [label="encoder.features.denseblock3.denselayer9.norm2.bias
 (128)" fillcolor=lightblue]
	2416991664592 -> 2416913177600
	2416913177600 [label=AccumulateGrad]
	2416913178224 -> 2417190373984
	2417184732848 [label="encoder.features.denseblock3.denselayer9.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2417184732848 -> 2416913178224
	2416913178224 [label=AccumulateGrad]
	2417190384208 -> 2417190386704
	2417190384208 [label=ConvolutionBackward0]
	2416913177072 -> 2417190384208
	2416913177072 [label=ReluBackward0]
	2416913176880 -> 2416913177072
	2416913176880 [label=CudnnBatchNormBackward0]
	2416913176352 -> 2416913176880
	2416913176352 [label=ConvolutionBackward0]
	2416913175584 -> 2416913176352
	2416913175584 [label=ReluBackward0]
	2416913175632 -> 2416913175584
	2416913175632 [label=CudnnBatchNormBackward0]
	2416913175440 -> 2416913175632
	2416913175440 [label=CatBackward0]
	2417190382288 -> 2416913175440
	2417190375184 -> 2416913175440
	2417190383584 -> 2416913175440
	2417190380656 -> 2416913175440
	2417190378880 -> 2416913175440
	2417190377968 -> 2416913175440
	2417190383440 -> 2416913175440
	2417190375232 -> 2416913175440
	2417190384688 -> 2416913175440
	2417190373984 -> 2416913175440
	2416913175392 -> 2416913175632
	2417184733488 [label="encoder.features.denseblock3.denselayer10.norm1.weight
 (544)" fillcolor=lightblue]
	2417184733488 -> 2416913175392
	2416913175392 [label=AccumulateGrad]
	2416913175824 -> 2416913175632
	2417184719008 [label="encoder.features.denseblock3.denselayer10.norm1.bias
 (544)" fillcolor=lightblue]
	2417184719008 -> 2416913175824
	2416913175824 [label=AccumulateGrad]
	2416913175680 -> 2416913176352
	2417184719968 [label="encoder.features.denseblock3.denselayer10.conv1.weight
 (128, 544, 1, 1)" fillcolor=lightblue]
	2417184719968 -> 2416913175680
	2416913175680 [label=AccumulateGrad]
	2416913176016 -> 2416913176880
	2417184719488 [label="encoder.features.denseblock3.denselayer10.norm2.weight
 (128)" fillcolor=lightblue]
	2417184719488 -> 2416913176016
	2416913176016 [label=AccumulateGrad]
	2416913176208 -> 2416913176880
	2417184719328 [label="encoder.features.denseblock3.denselayer10.norm2.bias
 (128)" fillcolor=lightblue]
	2417184719328 -> 2416913176208
	2416913176208 [label=AccumulateGrad]
	2416913177024 -> 2417190384208
	2417184720768 [label="encoder.features.denseblock3.denselayer10.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2417184720768 -> 2416913177024
	2416913177024 [label=AccumulateGrad]
	2417190384784 -> 2417190386704
	2417190384784 [label=ConvolutionBackward0]
	2416913175968 -> 2417190384784
	2416913175968 [label=ReluBackward0]
	2416913175776 -> 2416913175968
	2416913175776 [label=CudnnBatchNormBackward0]
	2416913175008 -> 2416913175776
	2416913175008 [label=ConvolutionBackward0]
	2416913175152 -> 2416913175008
	2416913175152 [label=ReluBackward0]
	2416913174480 -> 2416913175152
	2416913174480 [label=CudnnBatchNormBackward0]
	2416913174720 -> 2416913174480
	2416913174720 [label=CatBackward0]
	2417190382288 -> 2416913174720
	2417190375184 -> 2416913174720
	2417190383584 -> 2416913174720
	2417190380656 -> 2416913174720
	2417190378880 -> 2416913174720
	2417190377968 -> 2416913174720
	2417190383440 -> 2416913174720
	2417190375232 -> 2416913174720
	2417190384688 -> 2416913174720
	2417190373984 -> 2416913174720
	2417190384208 -> 2416913174720
	2416913174528 -> 2416913174480
	2417184722208 [label="encoder.features.denseblock3.denselayer11.norm1.weight
 (576)" fillcolor=lightblue]
	2417184722208 -> 2416913174528
	2416913174528 [label=AccumulateGrad]
	2416913174672 -> 2416913174480
	2417184722048 [label="encoder.features.denseblock3.denselayer11.norm1.bias
 (576)" fillcolor=lightblue]
	2417184722048 -> 2416913174672
	2416913174672 [label=AccumulateGrad]
	2416913174864 -> 2416913175008
	2417184722688 [label="encoder.features.denseblock3.denselayer11.conv1.weight
 (128, 576, 1, 1)" fillcolor=lightblue]
	2417184722688 -> 2416913174864
	2416913174864 [label=AccumulateGrad]
	2416913175104 -> 2416913175776
	2417184723168 [label="encoder.features.denseblock3.denselayer11.norm2.weight
 (128)" fillcolor=lightblue]
	2417184723168 -> 2416913175104
	2416913175104 [label=AccumulateGrad]
	2416913175728 -> 2416913175776
	2417184722848 [label="encoder.features.denseblock3.denselayer11.norm2.bias
 (128)" fillcolor=lightblue]
	2417184722848 -> 2416913175728
	2416913175728 [label=AccumulateGrad]
	2416913176256 -> 2417190384784
	2417184725408 [label="encoder.features.denseblock3.denselayer11.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2417184725408 -> 2416913176256
	2416913176256 [label=AccumulateGrad]
	2417190377104 -> 2417190386704
	2417190377104 [label=ConvolutionBackward0]
	2416913175248 -> 2417190377104
	2416913175248 [label=ReluBackward0]
	2416913175056 -> 2416913175248
	2416913175056 [label=CudnnBatchNormBackward0]
	2416913174288 -> 2416913175056
	2416913174288 [label=ConvolutionBackward0]
	2416913174144 -> 2416913174288
	2416913174144 [label=ReluBackward0]
	2416913173760 -> 2416913174144
	2416913173760 [label=CudnnBatchNormBackward0]
	2416913173520 -> 2416913173760
	2416913173520 [label=CatBackward0]
	2417190382288 -> 2416913173520
	2417190375184 -> 2416913173520
	2417190383584 -> 2416913173520
	2417190380656 -> 2416913173520
	2417190378880 -> 2416913173520
	2417190377968 -> 2416913173520
	2417190383440 -> 2416913173520
	2417190375232 -> 2416913173520
	2417190384688 -> 2416913173520
	2417190373984 -> 2416913173520
	2417190384208 -> 2416913173520
	2417190384784 -> 2416913173520
	2416913173328 -> 2416913173760
	2417184725248 [label="encoder.features.denseblock3.denselayer12.norm1.weight
 (608)" fillcolor=lightblue]
	2417184725248 -> 2416913173328
	2416913173328 [label=AccumulateGrad]
	2416913174048 -> 2416913173760
	2417184724768 [label="encoder.features.denseblock3.denselayer12.norm1.bias
 (608)" fillcolor=lightblue]
	2417184724768 -> 2416913174048
	2416913174048 [label=AccumulateGrad]
	2416913173952 -> 2416913174288
	2417184725728 [label="encoder.features.denseblock3.denselayer12.conv1.weight
 (128, 608, 1, 1)" fillcolor=lightblue]
	2417184725728 -> 2416913173952
	2416913173952 [label=AccumulateGrad]
	2416913174096 -> 2416913175056
	2417184726048 [label="encoder.features.denseblock3.denselayer12.norm2.weight
 (128)" fillcolor=lightblue]
	2417184726048 -> 2416913174096
	2416913174096 [label=AccumulateGrad]
	2416913174576 -> 2416913175056
	2417184727648 [label="encoder.features.denseblock3.denselayer12.norm2.bias
 (128)" fillcolor=lightblue]
	2417184727648 -> 2416913174576
	2416913174576 [label=AccumulateGrad]
	2416913175200 -> 2417190377104
	2417184728448 [label="encoder.features.denseblock3.denselayer12.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2417184728448 -> 2416913175200
	2416913175200 [label=AccumulateGrad]
	2417190379936 -> 2417190386704
	2417190379936 [label=ConvolutionBackward0]
	2416913173904 -> 2417190379936
	2416913173904 [label=ReluBackward0]
	2416913174000 -> 2416913173904
	2416913174000 [label=CudnnBatchNormBackward0]
	2416913173568 -> 2416913174000
	2416913173568 [label=ConvolutionBackward0]
	2416913172944 -> 2416913173568
	2416913172944 [label=ReluBackward0]
	2416913172992 -> 2416913172944
	2416913172992 [label=CudnnBatchNormBackward0]
	2416913172896 -> 2416913172992
	2416913172896 [label=CatBackward0]
	2417190382288 -> 2416913172896
	2417190375184 -> 2416913172896
	2417190383584 -> 2416913172896
	2417190380656 -> 2416913172896
	2417190378880 -> 2416913172896
	2417190377968 -> 2416913172896
	2417190383440 -> 2416913172896
	2417190375232 -> 2416913172896
	2417190384688 -> 2416913172896
	2417190373984 -> 2416913172896
	2417190384208 -> 2416913172896
	2417190384784 -> 2416913172896
	2417190377104 -> 2416913172896
	2416913172416 -> 2416913172992
	2417184727968 [label="encoder.features.denseblock3.denselayer13.norm1.weight
 (640)" fillcolor=lightblue]
	2417184727968 -> 2416913172416
	2416913172416 [label=AccumulateGrad]
	2416913172848 -> 2416913172992
	2417184727808 [label="encoder.features.denseblock3.denselayer13.norm1.bias
 (640)" fillcolor=lightblue]
	2417184727808 -> 2416913172848
	2416913172848 [label=AccumulateGrad]
	2416913172752 -> 2416913173568
	2417184730528 [label="encoder.features.denseblock3.denselayer13.conv1.weight
 (128, 640, 1, 1)" fillcolor=lightblue]
	2417184730528 -> 2416913172752
	2416913172752 [label=AccumulateGrad]
	2416913173376 -> 2416913174000
	2417184730368 [label="encoder.features.denseblock3.denselayer13.norm2.weight
 (128)" fillcolor=lightblue]
	2417184730368 -> 2416913173376
	2416913173376 [label=AccumulateGrad]
	2416913173712 -> 2416913174000
	2417184729888 [label="encoder.features.denseblock3.denselayer13.norm2.bias
 (128)" fillcolor=lightblue]
	2417184729888 -> 2416913173712
	2416913173712 [label=AccumulateGrad]
	2416913174624 -> 2417190379936
	2417184730848 [label="encoder.features.denseblock3.denselayer13.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2417184730848 -> 2416913174624
	2416913174624 [label=AccumulateGrad]
	2417190387664 -> 2417190386704
	2417190387664 [label=ConvolutionBackward0]
	2416913173472 -> 2417190387664
	2416913173472 [label=ReluBackward0]
	2416913173136 -> 2416913173472
	2416913173136 [label=CudnnBatchNormBackward0]
	2416913172320 -> 2416913173136
	2416913172320 [label=ConvolutionBackward0]
	2416913172080 -> 2416913172320
	2416913172080 [label=ReluBackward0]
	2416913171648 -> 2416913172080
	2416913171648 [label=CudnnBatchNormBackward0]
	2416913171888 -> 2416913171648
	2416913171888 [label=CatBackward0]
	2417190382288 -> 2416913171888
	2417190375184 -> 2416913171888
	2417190383584 -> 2416913171888
	2417190380656 -> 2416913171888
	2417190378880 -> 2416913171888
	2417190377968 -> 2416913171888
	2417190383440 -> 2416913171888
	2417190375232 -> 2416913171888
	2417190384688 -> 2416913171888
	2417190373984 -> 2416913171888
	2417190384208 -> 2416913171888
	2417190384784 -> 2416913171888
	2417190377104 -> 2416913171888
	2417190379936 -> 2416913171888
	2416913171696 -> 2416913171648
	2417184731168 [label="encoder.features.denseblock3.denselayer14.norm1.weight
 (672)" fillcolor=lightblue]
	2417184731168 -> 2416913171696
	2416913171696 [label=AccumulateGrad]
	2416913171840 -> 2416913171648
	2417184732768 [label="encoder.features.denseblock3.denselayer14.norm1.bias
 (672)" fillcolor=lightblue]
	2417184732768 -> 2416913171840
	2416913171840 [label=AccumulateGrad]
	2416913172032 -> 2416913172320
	2417184733568 [label="encoder.features.denseblock3.denselayer14.conv1.weight
 (128, 672, 1, 1)" fillcolor=lightblue]
	2417184733568 -> 2416913172032
	2416913172032 [label=AccumulateGrad]
	2416913172464 -> 2416913173136
	2417184733088 [label="encoder.features.denseblock3.denselayer14.norm2.weight
 (128)" fillcolor=lightblue]
	2417184733088 -> 2416913172464
	2416913172464 [label=AccumulateGrad]
	2416913172800 -> 2416913173136
	2417184732928 [label="encoder.features.denseblock3.denselayer14.norm2.bias
 (128)" fillcolor=lightblue]
	2417184732928 -> 2416913172800
	2416913172800 [label=AccumulateGrad]
	2416913173424 -> 2417190387664
	2417184734368 [label="encoder.features.denseblock3.denselayer14.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2417184734368 -> 2416913173424
	2416913173424 [label=AccumulateGrad]
	2417190380896 -> 2417190386704
	2417190380896 [label=ConvolutionBackward0]
	2416913172272 -> 2417190380896
	2416913172272 [label=ReluBackward0]
	2416913172368 -> 2416913172272
	2416913172368 [label=CudnnBatchNormBackward0]
	2416913171456 -> 2416913172368
	2416913171456 [label=ConvolutionBackward0]
	2416913171120 -> 2416913171456
	2416913171120 [label=ReluBackward0]
	2416913171168 -> 2416913171120
	2416913171168 [label=CudnnBatchNormBackward0]
	2416913170784 -> 2416913171168
	2416913170784 [label=CatBackward0]
	2417190382288 -> 2416913170784
	2417190375184 -> 2416913170784
	2417190383584 -> 2416913170784
	2417190380656 -> 2416913170784
	2417190378880 -> 2416913170784
	2417190377968 -> 2416913170784
	2417190383440 -> 2416913170784
	2417190375232 -> 2416913170784
	2417190384688 -> 2416913170784
	2417190373984 -> 2416913170784
	2417190384208 -> 2416913170784
	2417190384784 -> 2416913170784
	2417190377104 -> 2416913170784
	2417190379936 -> 2416913170784
	2417190387664 -> 2416913170784
	2416913170592 -> 2416913171168
	2417184734768 [label="encoder.features.denseblock3.denselayer15.norm1.weight
 (704)" fillcolor=lightblue]
	2417184734768 -> 2416913170592
	2416913170592 [label=AccumulateGrad]
	2416913171072 -> 2416913171168
	2417184721968 [label="encoder.features.denseblock3.denselayer15.norm1.bias
 (704)" fillcolor=lightblue]
	2417184721968 -> 2416913171072
	2416913171072 [label=AccumulateGrad]
	2416913171264 -> 2416913171456
	2417184720688 [label="encoder.features.denseblock3.denselayer15.conv1.weight
 (128, 704, 1, 1)" fillcolor=lightblue]
	2417184720688 -> 2416913171264
	2416913171264 [label=AccumulateGrad]
	2416913171408 -> 2416913172368
	2417184723888 [label="encoder.features.denseblock3.denselayer15.norm2.weight
 (128)" fillcolor=lightblue]
	2417184723888 -> 2416913171408
	2416913171408 [label=AccumulateGrad]
	2416913171744 -> 2416913172368
	2417191641936 [label="encoder.features.denseblock3.denselayer15.norm2.bias
 (128)" fillcolor=lightblue]
	2417191641936 -> 2416913171744
	2416913171744 [label=AccumulateGrad]
	2416913172224 -> 2417190380896
	2417191639056 [label="encoder.features.denseblock3.denselayer15.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2417191639056 -> 2416913172224
	2416913172224 [label=AccumulateGrad]
	2417190374944 -> 2417190386704
	2417190374944 [label=ConvolutionBackward0]
	2416770593744 -> 2417190374944
	2416770593744 [label=ReluBackward0]
	2416913171024 -> 2416770593744
	2416913171024 [label=CudnnBatchNormBackward0]
	2416913170832 -> 2416913171024
	2416913170832 [label=ConvolutionBackward0]
	2416982705728 -> 2416913170832
	2416982705728 [label=ReluBackward0]
	2416982718976 -> 2416982705728
	2416982718976 [label=CudnnBatchNormBackward0]
	2416982718160 -> 2416982718976
	2416982718160 [label=CatBackward0]
	2417190382288 -> 2416982718160
	2417190375184 -> 2416982718160
	2417190383584 -> 2416982718160
	2417190380656 -> 2416982718160
	2417190378880 -> 2416982718160
	2417190377968 -> 2416982718160
	2417190383440 -> 2416982718160
	2417190375232 -> 2416982718160
	2417190384688 -> 2416982718160
	2417190373984 -> 2416982718160
	2417190384208 -> 2416982718160
	2417190384784 -> 2416982718160
	2417190377104 -> 2416982718160
	2417190379936 -> 2416982718160
	2417190387664 -> 2416982718160
	2417190380896 -> 2416982718160
	2416982711728 -> 2416982718976
	2417191636176 [label="encoder.features.denseblock3.denselayer16.norm1.weight
 (736)" fillcolor=lightblue]
	2417191636176 -> 2416982711728
	2416982711728 [label=AccumulateGrad]
	2416982717152 -> 2416982718976
	2417191641136 [label="encoder.features.denseblock3.denselayer16.norm1.bias
 (736)" fillcolor=lightblue]
	2417191641136 -> 2416982717152
	2416982717152 [label=AccumulateGrad]
	2416982708032 -> 2416913170832
	2417191638736 [label="encoder.features.denseblock3.denselayer16.conv1.weight
 (128, 736, 1, 1)" fillcolor=lightblue]
	2417191638736 -> 2416982708032
	2416982708032 [label=AccumulateGrad]
	2416913170640 -> 2416913171024
	2417191639536 [label="encoder.features.denseblock3.denselayer16.norm2.weight
 (128)" fillcolor=lightblue]
	2417191639536 -> 2416913170640
	2416913170640 [label=AccumulateGrad]
	2416913171792 -> 2416913171024
	2417191643616 [label="encoder.features.denseblock3.denselayer16.norm2.bias
 (128)" fillcolor=lightblue]
	2417191643616 -> 2416913171792
	2416913171792 [label=AccumulateGrad]
	2416913171216 -> 2417190374944
	2417191641696 [label="encoder.features.denseblock3.denselayer16.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2417191641696 -> 2416913171216
	2416913171216 [label=AccumulateGrad]
	2417190379504 -> 2417190386704
	2417190379504 [label=ConvolutionBackward0]
	2416913170496 -> 2417190379504
	2416913170496 [label=ReluBackward0]
	2416982705056 -> 2416913170496
	2416982705056 [label=CudnnBatchNormBackward0]
	2416982708752 -> 2416982705056
	2416982708752 [label=ConvolutionBackward0]
	2416982708608 -> 2416982708752
	2416982708608 [label=ReluBackward0]
	2416982718784 -> 2416982708608
	2416982718784 [label=CudnnBatchNormBackward0]
	2416982710720 -> 2416982718784
	2416982710720 [label=CatBackward0]
	2417190382288 -> 2416982710720
	2417190375184 -> 2416982710720
	2417190383584 -> 2416982710720
	2417190380656 -> 2416982710720
	2417190378880 -> 2416982710720
	2417190377968 -> 2416982710720
	2417190383440 -> 2416982710720
	2417190375232 -> 2416982710720
	2417190384688 -> 2416982710720
	2417190373984 -> 2416982710720
	2417190384208 -> 2416982710720
	2417190384784 -> 2416982710720
	2417190377104 -> 2416982710720
	2417190379936 -> 2416982710720
	2417190387664 -> 2416982710720
	2417190380896 -> 2416982710720
	2417190374944 -> 2416982710720
	2416982710864 -> 2416982718784
	2417191640016 [label="encoder.features.denseblock3.denselayer17.norm1.weight
 (768)" fillcolor=lightblue]
	2417191640016 -> 2416982710864
	2416982710864 [label=AccumulateGrad]
	2416982718592 -> 2416982718784
	2417191643856 [label="encoder.features.denseblock3.denselayer17.norm1.bias
 (768)" fillcolor=lightblue]
	2417191643856 -> 2416982718592
	2416982718592 [label=AccumulateGrad]
	2416982711008 -> 2416982708752
	2417191640656 [label="encoder.features.denseblock3.denselayer17.conv1.weight
 (128, 768, 1, 1)" fillcolor=lightblue]
	2417191640656 -> 2416982711008
	2416982711008 [label=AccumulateGrad]
	2416982717008 -> 2416982705056
	2417191637936 [label="encoder.features.denseblock3.denselayer17.norm2.weight
 (128)" fillcolor=lightblue]
	2417191637936 -> 2416982717008
	2416982717008 [label=AccumulateGrad]
	2416982705536 -> 2416982705056
	2417191640896 [label="encoder.features.denseblock3.denselayer17.norm2.bias
 (128)" fillcolor=lightblue]
	2417191640896 -> 2416982705536
	2416982705536 [label=AccumulateGrad]
	2416913170544 -> 2417190379504
	2417191638096 [label="encoder.features.denseblock3.denselayer17.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2417191638096 -> 2416913170544
	2416913170544 [label=AccumulateGrad]
	2417190373888 -> 2417190386704
	2417190373888 [label=ConvolutionBackward0]
	2416913184512 -> 2417190373888
	2416913184512 [label=ReluBackward0]
	2416982708368 -> 2416913184512
	2416982708368 [label=CudnnBatchNormBackward0]
	2416982710624 -> 2416982708368
	2416982710624 [label=ConvolutionBackward0]
	2416982704864 -> 2416982710624
	2416982704864 [label=ReluBackward0]
	2416982711920 -> 2416982704864
	2416982711920 [label=CudnnBatchNormBackward0]
	2416982716672 -> 2416982711920
	2416982716672 [label=CatBackward0]
	2417190382288 -> 2416982716672
	2417190375184 -> 2416982716672
	2417190383584 -> 2416982716672
	2417190380656 -> 2416982716672
	2417190378880 -> 2416982716672
	2417190377968 -> 2416982716672
	2417190383440 -> 2416982716672
	2417190375232 -> 2416982716672
	2417190384688 -> 2416982716672
	2417190373984 -> 2416982716672
	2417190384208 -> 2416982716672
	2417190384784 -> 2416982716672
	2417190377104 -> 2416982716672
	2417190379936 -> 2416982716672
	2417190387664 -> 2416982716672
	2417190380896 -> 2416982716672
	2417190374944 -> 2416982716672
	2417190379504 -> 2416982716672
	2416982709280 -> 2416982711920
	2417191639776 [label="encoder.features.denseblock3.denselayer18.norm1.weight
 (800)" fillcolor=lightblue]
	2417191639776 -> 2416982709280
	2416982709280 [label=AccumulateGrad]
	2416982705440 -> 2416982711920
	2417191643216 [label="encoder.features.denseblock3.denselayer18.norm1.bias
 (800)" fillcolor=lightblue]
	2417191643216 -> 2416982705440
	2416982705440 [label=AccumulateGrad]
	2416982715232 -> 2416982710624
	2417191641856 [label="encoder.features.denseblock3.denselayer18.conv1.weight
 (128, 800, 1, 1)" fillcolor=lightblue]
	2417191641856 -> 2416982715232
	2416982715232 [label=AccumulateGrad]
	2416982707360 -> 2416982708368
	2417191633776 [label="encoder.features.denseblock3.denselayer18.norm2.weight
 (128)" fillcolor=lightblue]
	2417191633776 -> 2416982707360
	2416982707360 [label=AccumulateGrad]
	2416982710912 -> 2416982708368
	2417191641376 [label="encoder.features.denseblock3.denselayer18.norm2.bias
 (128)" fillcolor=lightblue]
	2417191641376 -> 2416982710912
	2416982710912 [label=AccumulateGrad]
	2416982717728 -> 2417190373888
	2417191640816 [label="encoder.features.denseblock3.denselayer18.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2417191640816 -> 2416982717728
	2416982717728 [label=AccumulateGrad]
	2417190373168 -> 2417190386704
	2417190373168 [label=ConvolutionBackward0]
	2416982713792 -> 2417190373168
	2416982713792 [label=ReluBackward0]
	2416982715616 -> 2416982713792
	2416982715616 [label=CudnnBatchNormBackward0]
	2416982719312 -> 2416982715616
	2416982719312 [label=ConvolutionBackward0]
	2416982719456 -> 2416982719312
	2416982719456 [label=ReluBackward0]
	2416982705104 -> 2416982719456
	2416982705104 [label=CudnnBatchNormBackward0]
	2416982717824 -> 2416982705104
	2416982717824 [label=CatBackward0]
	2417190382288 -> 2416982717824
	2417190375184 -> 2416982717824
	2417190383584 -> 2416982717824
	2417190380656 -> 2416982717824
	2417190378880 -> 2416982717824
	2417190377968 -> 2416982717824
	2417190383440 -> 2416982717824
	2417190375232 -> 2416982717824
	2417190384688 -> 2416982717824
	2417190373984 -> 2416982717824
	2417190384208 -> 2416982717824
	2417190384784 -> 2416982717824
	2417190377104 -> 2416982717824
	2417190379936 -> 2416982717824
	2417190387664 -> 2416982717824
	2417190380896 -> 2416982717824
	2417190374944 -> 2416982717824
	2417190379504 -> 2416982717824
	2417190373888 -> 2416982717824
	2416982707648 -> 2416982705104
	2417185423296 [label="encoder.features.denseblock3.denselayer19.norm1.weight
 (832)" fillcolor=lightblue]
	2417185423296 -> 2416982707648
	2416982707648 [label=AccumulateGrad]
	2416982706640 -> 2416982705104
	2417185423216 [label="encoder.features.denseblock3.denselayer19.norm1.bias
 (832)" fillcolor=lightblue]
	2417185423216 -> 2416982706640
	2416982706640 [label=AccumulateGrad]
	2416982719648 -> 2416982719312
	2417185408496 [label="encoder.features.denseblock3.denselayer19.conv1.weight
 (128, 832, 1, 1)" fillcolor=lightblue]
	2417185408496 -> 2416982719648
	2416982719648 [label=AccumulateGrad]
	2416982707600 -> 2416982715616
	2417185409056 [label="encoder.features.denseblock3.denselayer19.norm2.weight
 (128)" fillcolor=lightblue]
	2417185409056 -> 2416982707600
	2416982707600 [label=AccumulateGrad]
	2416982716576 -> 2416982715616
	2417185408976 [label="encoder.features.denseblock3.denselayer19.norm2.bias
 (128)" fillcolor=lightblue]
	2417185408976 -> 2416982716576
	2416982716576 [label=AccumulateGrad]
	2416982716240 -> 2417190373168
	2417185409456 [label="encoder.features.denseblock3.denselayer19.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2417185409456 -> 2416982716240
	2416982716240 [label=AccumulateGrad]
	2417190382816 -> 2417190386704
	2417190382816 [label=ConvolutionBackward0]
	2416982707216 -> 2417190382816
	2416982707216 [label=ReluBackward0]
	2416982706304 -> 2416982707216
	2416982706304 [label=CudnnBatchNormBackward0]
	2416982707120 -> 2416982706304
	2416982707120 [label=ConvolutionBackward0]
	2416982713360 -> 2416982707120
	2416982713360 [label=ReluBackward0]
	2416982707888 -> 2416982713360
	2416982707888 [label=CudnnBatchNormBackward0]
	2416982704624 -> 2416982707888
	2416982704624 [label=CatBackward0]
	2417190382288 -> 2416982704624
	2417190375184 -> 2416982704624
	2417190383584 -> 2416982704624
	2417190380656 -> 2416982704624
	2417190378880 -> 2416982704624
	2417190377968 -> 2416982704624
	2417190383440 -> 2416982704624
	2417190375232 -> 2416982704624
	2417190384688 -> 2416982704624
	2417190373984 -> 2416982704624
	2417190384208 -> 2416982704624
	2417190384784 -> 2416982704624
	2417190377104 -> 2416982704624
	2417190379936 -> 2416982704624
	2417190387664 -> 2416982704624
	2417190380896 -> 2416982704624
	2417190374944 -> 2416982704624
	2417190379504 -> 2416982704624
	2417190373888 -> 2416982704624
	2417190373168 -> 2416982704624
	2416982707456 -> 2416982707888
	2417185409216 [label="encoder.features.denseblock3.denselayer20.norm1.weight
 (864)" fillcolor=lightblue]
	2417185409216 -> 2416982707456
	2416982707456 [label=AccumulateGrad]
	2416982713312 -> 2416982707888
	2417185409616 [label="encoder.features.denseblock3.denselayer20.norm1.bias
 (864)" fillcolor=lightblue]
	2417185409616 -> 2416982713312
	2416982713312 [label=AccumulateGrad]
	2416982711344 -> 2416982707120
	2417185411216 [label="encoder.features.denseblock3.denselayer20.conv1.weight
 (128, 864, 1, 1)" fillcolor=lightblue]
	2417185411216 -> 2416982711344
	2416982711344 [label=AccumulateGrad]
	2416982714944 -> 2416982706304
	2417185411056 [label="encoder.features.denseblock3.denselayer20.norm2.weight
 (128)" fillcolor=lightblue]
	2417185411056 -> 2416982714944
	2416982714944 [label=AccumulateGrad]
	2416982705296 -> 2416982706304
	2417185410816 [label="encoder.features.denseblock3.denselayer20.norm2.bias
 (128)" fillcolor=lightblue]
	2417185410816 -> 2416982705296
	2416982705296 [label=AccumulateGrad]
	2416982706592 -> 2417190382816
	2417185411376 [label="encoder.features.denseblock3.denselayer20.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2417185411376 -> 2416982706592
	2416982706592 [label=AccumulateGrad]
	2417190380320 -> 2417190386704
	2417190380320 [label=ConvolutionBackward0]
	2416982718304 -> 2417190380320
	2416982718304 [label=ReluBackward0]
	2416982718928 -> 2416982718304
	2416982718928 [label=CudnnBatchNormBackward0]
	2416982713552 -> 2416982718928
	2416982713552 [label=ConvolutionBackward0]
	2416982704336 -> 2416982713552
	2416982704336 [label=ReluBackward0]
	2416982711488 -> 2416982704336
	2416982711488 [label=CudnnBatchNormBackward0]
	2416982707072 -> 2416982711488
	2416982707072 [label=CatBackward0]
	2417190382288 -> 2416982707072
	2417190375184 -> 2416982707072
	2417190383584 -> 2416982707072
	2417190380656 -> 2416982707072
	2417190378880 -> 2416982707072
	2417190377968 -> 2416982707072
	2417190383440 -> 2416982707072
	2417190375232 -> 2416982707072
	2417190384688 -> 2416982707072
	2417190373984 -> 2416982707072
	2417190384208 -> 2416982707072
	2417190384784 -> 2416982707072
	2417190377104 -> 2416982707072
	2417190379936 -> 2416982707072
	2417190387664 -> 2416982707072
	2417190380896 -> 2416982707072
	2417190374944 -> 2416982707072
	2417190379504 -> 2416982707072
	2417190373888 -> 2416982707072
	2417190373168 -> 2416982707072
	2417190382816 -> 2416982707072
	2416982712928 -> 2416982711488
	2417185411696 [label="encoder.features.denseblock3.denselayer21.norm1.weight
 (896)" fillcolor=lightblue]
	2417185411696 -> 2416982712928
	2416982712928 [label=AccumulateGrad]
	2416982709136 -> 2416982711488
	2417185412736 [label="encoder.features.denseblock3.denselayer21.norm1.bias
 (896)" fillcolor=lightblue]
	2417185412736 -> 2416982709136
	2416982709136 [label=AccumulateGrad]
	2416982718496 -> 2416982713552
	2417185413216 [label="encoder.features.denseblock3.denselayer21.conv1.weight
 (128, 896, 1, 1)" fillcolor=lightblue]
	2417185413216 -> 2416982718496
	2416982718496 [label=AccumulateGrad]
	2416982715040 -> 2416982718928
	2417185412976 [label="encoder.features.denseblock3.denselayer21.norm2.weight
 (128)" fillcolor=lightblue]
	2417185412976 -> 2416982715040
	2416982715040 [label=AccumulateGrad]
	2416982711536 -> 2416982718928
	2417185412816 [label="encoder.features.denseblock3.denselayer21.norm2.bias
 (128)" fillcolor=lightblue]
	2417185412816 -> 2416982711536
	2416982711536 [label=AccumulateGrad]
	2416982708848 -> 2417190380320
	2417185413456 [label="encoder.features.denseblock3.denselayer21.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2417185413456 -> 2416982708848
	2416982708848 [label=AccumulateGrad]
	2417190386464 -> 2417190386704
	2417190386464 [label=ConvolutionBackward0]
	2416982704192 -> 2417190386464
	2416982704192 [label=ReluBackward0]
	2416982709472 -> 2416982704192
	2416982709472 [label=CudnnBatchNormBackward0]
	2416982716480 -> 2416982709472
	2416982716480 [label=ConvolutionBackward0]
	2416982716288 -> 2416982716480
	2416982716288 [label=ReluBackward0]
	2416982720368 -> 2416982716288
	2416982720368 [label=CudnnBatchNormBackward0]
	2416982720320 -> 2416982720368
	2416982720320 [label=CatBackward0]
	2417190382288 -> 2416982720320
	2417190375184 -> 2416982720320
	2417190383584 -> 2416982720320
	2417190380656 -> 2416982720320
	2417190378880 -> 2416982720320
	2417190377968 -> 2416982720320
	2417190383440 -> 2416982720320
	2417190375232 -> 2416982720320
	2417190384688 -> 2416982720320
	2417190373984 -> 2416982720320
	2417190384208 -> 2416982720320
	2417190384784 -> 2416982720320
	2417190377104 -> 2416982720320
	2417190379936 -> 2416982720320
	2417190387664 -> 2416982720320
	2417190380896 -> 2416982720320
	2417190374944 -> 2416982720320
	2417190379504 -> 2416982720320
	2417190373888 -> 2416982720320
	2417190373168 -> 2416982720320
	2417190382816 -> 2416982720320
	2417190380320 -> 2416982720320
	2416982706112 -> 2416982720368
	2417185413696 [label="encoder.features.denseblock3.denselayer22.norm1.weight
 (928)" fillcolor=lightblue]
	2417185413696 -> 2416982706112
	2416982706112 [label=AccumulateGrad]
	2416982709184 -> 2416982720368
	2417185414656 [label="encoder.features.denseblock3.denselayer22.norm1.bias
 (928)" fillcolor=lightblue]
	2417185414656 -> 2416982709184
	2416982709184 [label=AccumulateGrad]
	2416982714128 -> 2416982716480
	2417185415296 [label="encoder.features.denseblock3.denselayer22.conv1.weight
 (128, 928, 1, 1)" fillcolor=lightblue]
	2417185415296 -> 2416982714128
	2416982714128 [label=AccumulateGrad]
	2416982704960 -> 2416982709472
	2417185415056 [label="encoder.features.denseblock3.denselayer22.norm2.weight
 (128)" fillcolor=lightblue]
	2417185415056 -> 2416982704960
	2416982704960 [label=AccumulateGrad]
	2416982712256 -> 2416982709472
	2417185414816 [label="encoder.features.denseblock3.denselayer22.norm2.bias
 (128)" fillcolor=lightblue]
	2417185414816 -> 2416982712256
	2416982712256 [label=AccumulateGrad]
	2416982713600 -> 2417190386464
	2417185415776 [label="encoder.features.denseblock3.denselayer22.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2417185415776 -> 2416982713600
	2416982713600 [label=AccumulateGrad]
	2417190379456 -> 2417190386704
	2417190379456 [label=ConvolutionBackward0]
	2416982709520 -> 2417190379456
	2416982709520 [label=ReluBackward0]
	2416982712832 -> 2416982709520
	2416982712832 [label=CudnnBatchNormBackward0]
	2416982704288 -> 2416982712832
	2416982704288 [label=ConvolutionBackward0]
	2416982706544 -> 2416982704288
	2416982706544 [label=ReluBackward0]
	2416982718064 -> 2416982706544
	2416982718064 [label=CudnnBatchNormBackward0]
	2416982719792 -> 2416982718064
	2416982719792 [label=CatBackward0]
	2417190382288 -> 2416982719792
	2417190375184 -> 2416982719792
	2417190383584 -> 2416982719792
	2417190380656 -> 2416982719792
	2417190378880 -> 2416982719792
	2417190377968 -> 2416982719792
	2417190383440 -> 2416982719792
	2417190375232 -> 2416982719792
	2417190384688 -> 2416982719792
	2417190373984 -> 2416982719792
	2417190384208 -> 2416982719792
	2417190384784 -> 2416982719792
	2417190377104 -> 2416982719792
	2417190379936 -> 2416982719792
	2417190387664 -> 2416982719792
	2417190380896 -> 2416982719792
	2417190374944 -> 2416982719792
	2417190379504 -> 2416982719792
	2417190373888 -> 2416982719792
	2417190373168 -> 2416982719792
	2417190382816 -> 2416982719792
	2417190380320 -> 2416982719792
	2417190386464 -> 2416982719792
	2416982719936 -> 2416982718064
	2417185416816 [label="encoder.features.denseblock3.denselayer23.norm1.weight
 (960)" fillcolor=lightblue]
	2417185416816 -> 2416982719936
	2416982719936 [label=AccumulateGrad]
	2416982706496 -> 2416982718064
	2417185416656 [label="encoder.features.denseblock3.denselayer23.norm1.bias
 (960)" fillcolor=lightblue]
	2417185416656 -> 2416982706496
	2416982706496 [label=AccumulateGrad]
	2416982705920 -> 2416982704288
	2417185417296 [label="encoder.features.denseblock3.denselayer23.conv1.weight
 (128, 960, 1, 1)" fillcolor=lightblue]
	2417185417296 -> 2416982705920
	2416982705920 [label=AccumulateGrad]
	2416982719408 -> 2416982712832
	2417185417056 [label="encoder.features.denseblock3.denselayer23.norm2.weight
 (128)" fillcolor=lightblue]
	2417185417056 -> 2416982719408
	2416982719408 [label=AccumulateGrad]
	2416982719024 -> 2416982712832
	2417185416896 [label="encoder.features.denseblock3.denselayer23.norm2.bias
 (128)" fillcolor=lightblue]
	2417185416896 -> 2416982719024
	2416982719024 [label=AccumulateGrad]
	2416982717488 -> 2417190379456
	2417185417936 [label="encoder.features.denseblock3.denselayer23.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2417185417936 -> 2416982717488
	2416982717488 [label=AccumulateGrad]
	2417190375904 -> 2417190386704
	2417190375904 [label=ConvolutionBackward0]
	2416982714800 -> 2417190375904
	2416982714800 [label=ReluBackward0]
	2416982718832 -> 2416982714800
	2416982718832 [label=CudnnBatchNormBackward0]
	2416982714992 -> 2416982718832
	2416982714992 [label=ConvolutionBackward0]
	2416982715568 -> 2416982714992
	2416982715568 [label=ReluBackward0]
	2416982720176 -> 2416982715568
	2416982720176 [label=CudnnBatchNormBackward0]
	2416982716384 -> 2416982720176
	2416982716384 [label=CatBackward0]
	2417190382288 -> 2416982716384
	2417190375184 -> 2416982716384
	2417190383584 -> 2416982716384
	2417190380656 -> 2416982716384
	2417190378880 -> 2416982716384
	2417190377968 -> 2416982716384
	2417190383440 -> 2416982716384
	2417190375232 -> 2416982716384
	2417190384688 -> 2416982716384
	2417190373984 -> 2416982716384
	2417190384208 -> 2416982716384
	2417190384784 -> 2416982716384
	2417190377104 -> 2416982716384
	2417190379936 -> 2416982716384
	2417190387664 -> 2416982716384
	2417190380896 -> 2416982716384
	2417190374944 -> 2416982716384
	2417190379504 -> 2416982716384
	2417190373888 -> 2416982716384
	2417190373168 -> 2416982716384
	2417190382816 -> 2416982716384
	2417190380320 -> 2416982716384
	2417190386464 -> 2416982716384
	2417190379456 -> 2416982716384
	2416982720128 -> 2416982720176
	2417185418896 [label="encoder.features.denseblock3.denselayer24.norm1.weight
 (992)" fillcolor=lightblue]
	2417185418896 -> 2416982720128
	2416982720128 [label=AccumulateGrad]
	2416982704672 -> 2416982720176
	2417185418656 [label="encoder.features.denseblock3.denselayer24.norm1.bias
 (992)" fillcolor=lightblue]
	2417185418656 -> 2416982704672
	2416982704672 [label=AccumulateGrad]
	2416982715520 -> 2416982714992
	2417185419136 [label="encoder.features.denseblock3.denselayer24.conv1.weight
 (128, 992, 1, 1)" fillcolor=lightblue]
	2417185419136 -> 2416982715520
	2416982715520 [label=AccumulateGrad]
	2416982718256 -> 2416982718832
	2417185419056 [label="encoder.features.denseblock3.denselayer24.norm2.weight
 (128)" fillcolor=lightblue]
	2417185419056 -> 2416982718256
	2416982718256 [label=AccumulateGrad]
	2416982718688 -> 2416982718832
	2417185419296 [label="encoder.features.denseblock3.denselayer24.norm2.bias
 (128)" fillcolor=lightblue]
	2417185419296 -> 2416982718688
	2416982718688 [label=AccumulateGrad]
	2416982704240 -> 2417190375904
	2417185420896 [label="encoder.features.denseblock3.denselayer24.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2417185420896 -> 2416982704240
	2416982704240 [label=AccumulateGrad]
	2417190378832 -> 2417190386704
	2417190378832 [label=ConvolutionBackward0]
	2416982715184 -> 2417190378832
	2416982715184 [label=ReluBackward0]
	2416982715472 -> 2416982715184
	2416982715472 [label=CudnnBatchNormBackward0]
	2416982719888 -> 2416982715472
	2416982719888 [label=ConvolutionBackward0]
	2416982717920 -> 2416982719888
	2416982717920 [label=ReluBackward0]
	2416982707984 -> 2416982717920
	2416982707984 [label=CudnnBatchNormBackward0]
	2416982720272 -> 2416982707984
	2416982720272 [label=CatBackward0]
	2417190382288 -> 2416982720272
	2417190375184 -> 2416982720272
	2417190383584 -> 2416982720272
	2417190380656 -> 2416982720272
	2417190378880 -> 2416982720272
	2417190377968 -> 2416982720272
	2417190383440 -> 2416982720272
	2417190375232 -> 2416982720272
	2417190384688 -> 2416982720272
	2417190373984 -> 2416982720272
	2417190384208 -> 2416982720272
	2417190384784 -> 2416982720272
	2417190377104 -> 2416982720272
	2417190379936 -> 2416982720272
	2417190387664 -> 2416982720272
	2417190380896 -> 2416982720272
	2417190374944 -> 2416982720272
	2417190379504 -> 2416982720272
	2417190373888 -> 2416982720272
	2417190373168 -> 2416982720272
	2417190382816 -> 2416982720272
	2417190380320 -> 2416982720272
	2417190386464 -> 2416982720272
	2417190379456 -> 2416982720272
	2417190375904 -> 2416982720272
	2416982718448 -> 2416982707984
	2417185420736 [label="encoder.features.denseblock3.denselayer25.norm1.weight
 (1024)" fillcolor=lightblue]
	2417185420736 -> 2416982718448
	2416982718448 [label=AccumulateGrad]
	2416982708656 -> 2416982707984
	2417185420496 [label="encoder.features.denseblock3.denselayer25.norm1.bias
 (1024)" fillcolor=lightblue]
	2417185420496 -> 2416982708656
	2416982708656 [label=AccumulateGrad]
	2416982720416 -> 2416982719888
	2417185420976 [label="encoder.features.denseblock3.denselayer25.conv1.weight
 (128, 1024, 1, 1)" fillcolor=lightblue]
	2417185420976 -> 2416982720416
	2416982720416 [label=AccumulateGrad]
	2416982711776 -> 2416982715472
	2417185421216 [label="encoder.features.denseblock3.denselayer25.norm2.weight
 (128)" fillcolor=lightblue]
	2417185421216 -> 2416982711776
	2416982711776 [label=AccumulateGrad]
	2416982720080 -> 2416982715472
	2417185422256 [label="encoder.features.denseblock3.denselayer25.norm2.bias
 (128)" fillcolor=lightblue]
	2417185422256 -> 2416982720080
	2416982720080 [label=AccumulateGrad]
	2416982720464 -> 2417190378832
	2417185422976 [label="encoder.features.denseblock3.denselayer25.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2417185422976 -> 2416982720464
	2416982720464 [label=AccumulateGrad]
	2417190380800 -> 2417190386704
	2417190380800 [label=ConvolutionBackward0]
	2416982711392 -> 2417190380800
	2416982711392 [label=ReluBackward0]
	2416982714656 -> 2416982711392
	2416982714656 [label=CudnnBatchNormBackward0]
	2416982709808 -> 2416982714656
	2416982709808 [label=ConvolutionBackward0]
	2416982720032 -> 2416982709808
	2416982720032 [label=ReluBackward0]
	2416982715328 -> 2416982720032
	2416982715328 [label=CudnnBatchNormBackward0]
	2416982709712 -> 2416982715328
	2416982709712 [label=CatBackward0]
	2417190382288 -> 2416982709712
	2417190375184 -> 2416982709712
	2417190383584 -> 2416982709712
	2417190380656 -> 2416982709712
	2417190378880 -> 2416982709712
	2417190377968 -> 2416982709712
	2417190383440 -> 2416982709712
	2417190375232 -> 2416982709712
	2417190384688 -> 2416982709712
	2417190373984 -> 2416982709712
	2417190384208 -> 2416982709712
	2417190384784 -> 2416982709712
	2417190377104 -> 2416982709712
	2417190379936 -> 2416982709712
	2417190387664 -> 2416982709712
	2417190380896 -> 2416982709712
	2417190374944 -> 2416982709712
	2417190379504 -> 2416982709712
	2417190373888 -> 2416982709712
	2417190373168 -> 2416982709712
	2417190382816 -> 2416982709712
	2417190380320 -> 2416982709712
	2417190386464 -> 2416982709712
	2417190379456 -> 2416982709712
	2417190375904 -> 2416982709712
	2417190378832 -> 2416982709712
	2416982715376 -> 2416982715328
	2417185422736 [label="encoder.features.denseblock3.denselayer26.norm1.weight
 (1056)" fillcolor=lightblue]
	2417185422736 -> 2416982715376
	2416982715376 [label=AccumulateGrad]
	2416982708416 -> 2416982715328
	2417185422496 [label="encoder.features.denseblock3.denselayer26.norm1.bias
 (1056)" fillcolor=lightblue]
	2417185422496 -> 2416982708416
	2416982708416 [label=AccumulateGrad]
	2416982718208 -> 2416982709808
	2417185407376 [label="encoder.features.denseblock3.denselayer26.conv1.weight
 (128, 1056, 1, 1)" fillcolor=lightblue]
	2417185407376 -> 2416982718208
	2416982718208 [label=AccumulateGrad]
	2416982712640 -> 2416982714656
	2417185505440 [label="encoder.features.denseblock3.denselayer26.norm2.weight
 (128)" fillcolor=lightblue]
	2417185505440 -> 2416982712640
	2416982712640 [label=AccumulateGrad]
	2416982710432 -> 2416982714656
	2417185505920 [label="encoder.features.denseblock3.denselayer26.norm2.bias
 (128)" fillcolor=lightblue]
	2417185505920 -> 2416982710432
	2416982710432 [label=AccumulateGrad]
	2416982710480 -> 2417190380800
	2417185506400 [label="encoder.features.denseblock3.denselayer26.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2417185506400 -> 2416982710480
	2416982710480 [label=AccumulateGrad]
	2417190385792 -> 2417190386704
	2417190385792 [label=ConvolutionBackward0]
	2416982716096 -> 2417190385792
	2416982716096 [label=ReluBackward0]
	2416982708800 -> 2416982716096
	2416982708800 [label=CudnnBatchNormBackward0]
	2416982715136 -> 2416982708800
	2416982715136 [label=ConvolutionBackward0]
	2416982717392 -> 2416982715136
	2416982717392 [label=ReluBackward0]
	2416982710144 -> 2416982717392
	2416982710144 [label=CudnnBatchNormBackward0]
	2416982716432 -> 2416982710144
	2416982716432 [label=CatBackward0]
	2417190382288 -> 2416982716432
	2417190375184 -> 2416982716432
	2417190383584 -> 2416982716432
	2417190380656 -> 2416982716432
	2417190378880 -> 2416982716432
	2417190377968 -> 2416982716432
	2417190383440 -> 2416982716432
	2417190375232 -> 2416982716432
	2417190384688 -> 2416982716432
	2417190373984 -> 2416982716432
	2417190384208 -> 2416982716432
	2417190384784 -> 2416982716432
	2417190377104 -> 2416982716432
	2417190379936 -> 2416982716432
	2417190387664 -> 2416982716432
	2417190380896 -> 2416982716432
	2417190374944 -> 2416982716432
	2417190379504 -> 2416982716432
	2417190373888 -> 2416982716432
	2417190373168 -> 2416982716432
	2417190382816 -> 2416982716432
	2417190380320 -> 2416982716432
	2417190386464 -> 2416982716432
	2417190379456 -> 2416982716432
	2417190375904 -> 2416982716432
	2417190378832 -> 2416982716432
	2417190380800 -> 2416982716432
	2416982704528 -> 2416982710144
	2417185506160 [label="encoder.features.denseblock3.denselayer27.norm1.weight
 (1088)" fillcolor=lightblue]
	2417185506160 -> 2416982704528
	2416982704528 [label=AccumulateGrad]
	2416982710528 -> 2416982710144
	2417185506080 [label="encoder.features.denseblock3.denselayer27.norm1.bias
 (1088)" fillcolor=lightblue]
	2417185506080 -> 2416982710528
	2416982710528 [label=AccumulateGrad]
	2416982709904 -> 2416982715136
	2417185506960 [label="encoder.features.denseblock3.denselayer27.conv1.weight
 (128, 1088, 1, 1)" fillcolor=lightblue]
	2417185506960 -> 2416982709904
	2416982709904 [label=AccumulateGrad]
	2416982716048 -> 2416982708800
	2417185507840 [label="encoder.features.denseblock3.denselayer27.norm2.weight
 (128)" fillcolor=lightblue]
	2417185507840 -> 2416982716048
	2416982716048 [label=AccumulateGrad]
	2416982715424 -> 2416982708800
	2417185507680 [label="encoder.features.denseblock3.denselayer27.norm2.bias
 (128)" fillcolor=lightblue]
	2417185507680 -> 2416982715424
	2416982715424 [label=AccumulateGrad]
	2416982706736 -> 2417190385792
	2417185508240 [label="encoder.features.denseblock3.denselayer27.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2417185508240 -> 2416982706736
	2416982706736 [label=AccumulateGrad]
	2417190386176 -> 2417190386704
	2417190386176 [label=ConvolutionBackward0]
	2416982714704 -> 2417190386176
	2416982714704 [label=ReluBackward0]
	2416982715712 -> 2416982714704
	2416982715712 [label=CudnnBatchNormBackward0]
	2416982707312 -> 2416982715712
	2416982707312 [label=ConvolutionBackward0]
	2416982715808 -> 2416982707312
	2416982715808 [label=ReluBackward0]
	2416982717440 -> 2416982715808
	2416982717440 [label=CudnnBatchNormBackward0]
	2416982712016 -> 2416982717440
	2416982712016 [label=CatBackward0]
	2417190382288 -> 2416982712016
	2417190375184 -> 2416982712016
	2417190383584 -> 2416982712016
	2417190380656 -> 2416982712016
	2417190378880 -> 2416982712016
	2417190377968 -> 2416982712016
	2417190383440 -> 2416982712016
	2417190375232 -> 2416982712016
	2417190384688 -> 2416982712016
	2417190373984 -> 2416982712016
	2417190384208 -> 2416982712016
	2417190384784 -> 2416982712016
	2417190377104 -> 2416982712016
	2417190379936 -> 2416982712016
	2417190387664 -> 2416982712016
	2417190380896 -> 2416982712016
	2417190374944 -> 2416982712016
	2417190379504 -> 2416982712016
	2417190373888 -> 2416982712016
	2417190373168 -> 2416982712016
	2417190382816 -> 2416982712016
	2417190380320 -> 2416982712016
	2417190386464 -> 2416982712016
	2417190379456 -> 2416982712016
	2417190375904 -> 2416982712016
	2417190378832 -> 2416982712016
	2417190380800 -> 2416982712016
	2417190385792 -> 2416982712016
	2416982719168 -> 2416982717440
	2417185508080 [label="encoder.features.denseblock3.denselayer28.norm1.weight
 (1120)" fillcolor=lightblue]
	2417185508080 -> 2416982719168
	2416982719168 [label=AccumulateGrad]
	2416982717680 -> 2416982717440
	2417185508320 [label="encoder.features.denseblock3.denselayer28.norm1.bias
 (1120)" fillcolor=lightblue]
	2417185508320 -> 2416982717680
	2416982717680 [label=AccumulateGrad]
	2416982719216 -> 2416982707312
	2417185509920 [label="encoder.features.denseblock3.denselayer28.conv1.weight
 (128, 1120, 1, 1)" fillcolor=lightblue]
	2417185509920 -> 2416982719216
	2416982719216 [label=AccumulateGrad]
	2416982717200 -> 2416982715712
	2417185509840 [label="encoder.features.denseblock3.denselayer28.norm2.weight
 (128)" fillcolor=lightblue]
	2417185509840 -> 2416982717200
	2416982717200 [label=AccumulateGrad]
	2416982715856 -> 2416982715712
	2417185509600 [label="encoder.features.denseblock3.denselayer28.norm2.bias
 (128)" fillcolor=lightblue]
	2417185509600 -> 2416982715856
	2416982715856 [label=AccumulateGrad]
	2416982715760 -> 2417190386176
	2417185510080 [label="encoder.features.denseblock3.denselayer28.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2417185510080 -> 2416982715760
	2416982715760 [label=AccumulateGrad]
	2417190373744 -> 2417190386704
	2417190373744 [label=ConvolutionBackward0]
	2416982717296 -> 2417190373744
	2416982717296 [label=ReluBackward0]
	2416982714608 -> 2416982717296
	2416982714608 [label=CudnnBatchNormBackward0]
	2416982711968 -> 2416982714608
	2416982711968 [label=ConvolutionBackward0]
	2416982708944 -> 2416982711968
	2416982708944 [label=ReluBackward0]
	2416982709376 -> 2416982708944
	2416982709376 [label=CudnnBatchNormBackward0]
	2416982708992 -> 2416982709376
	2416982708992 [label=CatBackward0]
	2417190382288 -> 2416982708992
	2417190375184 -> 2416982708992
	2417190383584 -> 2416982708992
	2417190380656 -> 2416982708992
	2417190378880 -> 2416982708992
	2417190377968 -> 2416982708992
	2417190383440 -> 2416982708992
	2417190375232 -> 2416982708992
	2417190384688 -> 2416982708992
	2417190373984 -> 2416982708992
	2417190384208 -> 2416982708992
	2417190384784 -> 2416982708992
	2417190377104 -> 2416982708992
	2417190379936 -> 2416982708992
	2417190387664 -> 2416982708992
	2417190380896 -> 2416982708992
	2417190374944 -> 2416982708992
	2417190379504 -> 2416982708992
	2417190373888 -> 2416982708992
	2417190373168 -> 2416982708992
	2417190382816 -> 2416982708992
	2417190380320 -> 2416982708992
	2417190386464 -> 2416982708992
	2417190379456 -> 2416982708992
	2417190375904 -> 2416982708992
	2417190378832 -> 2416982708992
	2417190380800 -> 2416982708992
	2417190385792 -> 2416982708992
	2417190386176 -> 2416982708992
	2416982709040 -> 2416982709376
	2417185510320 [label="encoder.features.denseblock3.denselayer29.norm1.weight
 (1152)" fillcolor=lightblue]
	2417185510320 -> 2416982709040
	2416982709040 [label=AccumulateGrad]
	2416982714848 -> 2416982709376
	2417185511280 [label="encoder.features.denseblock3.denselayer29.norm1.bias
 (1152)" fillcolor=lightblue]
	2417185511280 -> 2416982714848
	2416982714848 [label=AccumulateGrad]
	2416982708896 -> 2416982711968
	2417185511760 [label="encoder.features.denseblock3.denselayer29.conv1.weight
 (128, 1152, 1, 1)" fillcolor=lightblue]
	2417185511760 -> 2416982708896
	2416982708896 [label=AccumulateGrad]
	2416982719264 -> 2416982714608
	2417185511520 [label="encoder.features.denseblock3.denselayer29.norm2.weight
 (128)" fillcolor=lightblue]
	2417185511520 -> 2416982719264
	2416982719264 [label=AccumulateGrad]
	2416982712784 -> 2416982714608
	2417185511440 [label="encoder.features.denseblock3.denselayer29.norm2.bias
 (128)" fillcolor=lightblue]
	2417185511440 -> 2416982712784
	2416982712784 [label=AccumulateGrad]
	2416982715088 -> 2417190373744
	2417185512160 [label="encoder.features.denseblock3.denselayer29.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2417185512160 -> 2416982715088
	2416982715088 [label=AccumulateGrad]
	2417190375424 -> 2417190386704
	2417190375424 [label=ConvolutionBackward0]
	2416982710048 -> 2417190375424
	2416982710048 [label=ReluBackward0]
	2416982709088 -> 2416982710048
	2416982709088 [label=CudnnBatchNormBackward0]
	2416982705248 -> 2416982709088
	2416982705248 [label=ConvolutionBackward0]
	2416982716912 -> 2416982705248
	2416982716912 [label=ReluBackward0]
	2416982719552 -> 2416982716912
	2416982719552 [label=CudnnBatchNormBackward0]
	2416982706688 -> 2416982719552
	2416982706688 [label=CatBackward0]
	2417190382288 -> 2416982706688
	2417190375184 -> 2416982706688
	2417190383584 -> 2416982706688
	2417190380656 -> 2416982706688
	2417190378880 -> 2416982706688
	2417190377968 -> 2416982706688
	2417190383440 -> 2416982706688
	2417190375232 -> 2416982706688
	2417190384688 -> 2416982706688
	2417190373984 -> 2416982706688
	2417190384208 -> 2416982706688
	2417190384784 -> 2416982706688
	2417190377104 -> 2416982706688
	2417190379936 -> 2416982706688
	2417190387664 -> 2416982706688
	2417190380896 -> 2416982706688
	2417190374944 -> 2416982706688
	2417190379504 -> 2416982706688
	2417190373888 -> 2416982706688
	2417190373168 -> 2416982706688
	2417190382816 -> 2416982706688
	2417190380320 -> 2416982706688
	2417190386464 -> 2416982706688
	2417190379456 -> 2416982706688
	2417190375904 -> 2416982706688
	2417190378832 -> 2416982706688
	2417190380800 -> 2416982706688
	2417190385792 -> 2416982706688
	2417190386176 -> 2416982706688
	2417190373744 -> 2416982706688
	2416982705776 -> 2416982719552
	2417185512400 [label="encoder.features.denseblock3.denselayer30.norm1.weight
 (1184)" fillcolor=lightblue]
	2417185512400 -> 2416982705776
	2416982705776 [label=AccumulateGrad]
	2416982709616 -> 2416982719552
	2417185513280 [label="encoder.features.denseblock3.denselayer30.norm1.bias
 (1184)" fillcolor=lightblue]
	2417185513280 -> 2416982709616
	2416982709616 [label=AccumulateGrad]
	2416982718640 -> 2416982705248
	2417185514000 [label="encoder.features.denseblock3.denselayer30.conv1.weight
 (128, 1184, 1, 1)" fillcolor=lightblue]
	2417185514000 -> 2416982718640
	2416982718640 [label=AccumulateGrad]
	2416982707264 -> 2416982709088
	2417185513920 [label="encoder.features.denseblock3.denselayer30.norm2.weight
 (128)" fillcolor=lightblue]
	2417185513920 -> 2416982707264
	2416982707264 [label=AccumulateGrad]
	2416982718016 -> 2416982709088
	2417185513680 [label="encoder.features.denseblock3.denselayer30.norm2.bias
 (128)" fillcolor=lightblue]
	2417185513680 -> 2416982718016
	2416982718016 [label=AccumulateGrad]
	2416982719120 -> 2417190375424
	2417185514160 [label="encoder.features.denseblock3.denselayer30.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2417185514160 -> 2416982719120
	2416982719120 [label=AccumulateGrad]
	2417190386608 -> 2417190386704
	2417190386608 [label=ConvolutionBackward0]
	2416982704912 -> 2417190386608
	2416982704912 [label=ReluBackward0]
	2416982706976 -> 2416982704912
	2416982706976 [label=CudnnBatchNormBackward0]
	2416982717104 -> 2416982706976
	2416982717104 [label=ConvolutionBackward0]
	2416982705392 -> 2416982717104
	2416982705392 [label=ReluBackward0]
	2416982710336 -> 2416982705392
	2416982710336 [label=CudnnBatchNormBackward0]
	2416982710192 -> 2416982710336
	2416982710192 [label=CatBackward0]
	2417190382288 -> 2416982710192
	2417190375184 -> 2416982710192
	2417190383584 -> 2416982710192
	2417190380656 -> 2416982710192
	2417190378880 -> 2416982710192
	2417190377968 -> 2416982710192
	2417190383440 -> 2416982710192
	2417190375232 -> 2416982710192
	2417190384688 -> 2416982710192
	2417190373984 -> 2416982710192
	2417190384208 -> 2416982710192
	2417190384784 -> 2416982710192
	2417190377104 -> 2416982710192
	2417190379936 -> 2416982710192
	2417190387664 -> 2416982710192
	2417190380896 -> 2416982710192
	2417190374944 -> 2416982710192
	2417190379504 -> 2416982710192
	2417190373888 -> 2416982710192
	2417190373168 -> 2416982710192
	2417190382816 -> 2416982710192
	2417190380320 -> 2416982710192
	2417190386464 -> 2416982710192
	2417190379456 -> 2416982710192
	2417190375904 -> 2416982710192
	2417190378832 -> 2416982710192
	2417190380800 -> 2416982710192
	2417190385792 -> 2416982710192
	2417190386176 -> 2416982710192
	2417190373744 -> 2416982710192
	2417190375424 -> 2416982710192
	2416982705824 -> 2416982710336
	2417185514400 [label="encoder.features.denseblock3.denselayer31.norm1.weight
 (1216)" fillcolor=lightblue]
	2417185514400 -> 2416982705824
	2416982705824 [label=AccumulateGrad]
	2416982710000 -> 2416982710336
	2417185515360 [label="encoder.features.denseblock3.denselayer31.norm1.bias
 (1216)" fillcolor=lightblue]
	2417185515360 -> 2416982710000
	2416982710000 [label=AccumulateGrad]
	2416982716528 -> 2416982717104
	2417185515840 [label="encoder.features.denseblock3.denselayer31.conv1.weight
 (128, 1216, 1, 1)" fillcolor=lightblue]
	2417185515840 -> 2416982716528
	2416982716528 [label=AccumulateGrad]
	2416982709952 -> 2416982706976
	2417185515600 [label="encoder.features.denseblock3.denselayer31.norm2.weight
 (128)" fillcolor=lightblue]
	2417185515600 -> 2416982709952
	2416982709952 [label=AccumulateGrad]
	2416982705152 -> 2416982706976
	2417185515520 [label="encoder.features.denseblock3.denselayer31.norm2.bias
 (128)" fillcolor=lightblue]
	2417185515520 -> 2416982705152
	2416982705152 [label=AccumulateGrad]
	2416982709328 -> 2417190386608
	2417185516480 [label="encoder.features.denseblock3.denselayer31.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2417185516480 -> 2416982709328
	2416982709328 [label=AccumulateGrad]
	2417190383680 -> 2417190386704
	2417190383680 [label=ConvolutionBackward0]
	2416982716624 -> 2417190383680
	2416982716624 [label=ReluBackward0]
	2416982704480 -> 2416982716624
	2416982704480 [label=CudnnBatchNormBackward0]
	2416982711872 -> 2416982704480
	2416982711872 [label=ConvolutionBackward0]
	2416982711296 -> 2416982711872
	2416982711296 [label=ReluBackward0]
	2416982712592 -> 2416982711296
	2416982712592 [label=CudnnBatchNormBackward0]
	2416982713840 -> 2416982712592
	2416982713840 [label=CatBackward0]
	2417190382288 -> 2416982713840
	2417190375184 -> 2416982713840
	2417190383584 -> 2416982713840
	2417190380656 -> 2416982713840
	2417190378880 -> 2416982713840
	2417190377968 -> 2416982713840
	2417190383440 -> 2416982713840
	2417190375232 -> 2416982713840
	2417190384688 -> 2416982713840
	2417190373984 -> 2416982713840
	2417190384208 -> 2416982713840
	2417190384784 -> 2416982713840
	2417190377104 -> 2416982713840
	2417190379936 -> 2416982713840
	2417190387664 -> 2416982713840
	2417190380896 -> 2416982713840
	2417190374944 -> 2416982713840
	2417190379504 -> 2416982713840
	2417190373888 -> 2416982713840
	2417190373168 -> 2416982713840
	2417190382816 -> 2416982713840
	2417190380320 -> 2416982713840
	2417190386464 -> 2416982713840
	2417190379456 -> 2416982713840
	2417190375904 -> 2416982713840
	2417190378832 -> 2416982713840
	2417190380800 -> 2416982713840
	2417190385792 -> 2416982713840
	2417190386176 -> 2416982713840
	2417190373744 -> 2416982713840
	2417190375424 -> 2416982713840
	2417190386608 -> 2416982713840
	2416982708128 -> 2416982712592
	2417185517360 [label="encoder.features.denseblock3.denselayer32.norm1.weight
 (1248)" fillcolor=lightblue]
	2417185517360 -> 2416982708128
	2416982708128 [label=AccumulateGrad]
	2416982712496 -> 2416982712592
	2417185517200 [label="encoder.features.denseblock3.denselayer32.norm1.bias
 (1248)" fillcolor=lightblue]
	2417185517200 -> 2416982712496
	2416982712496 [label=AccumulateGrad]
	2416982712208 -> 2416982711872
	2417185517760 [label="encoder.features.denseblock3.denselayer32.conv1.weight
 (128, 1248, 1, 1)" fillcolor=lightblue]
	2417185517760 -> 2416982712208
	2416982712208 [label=AccumulateGrad]
	2416982712064 -> 2416982704480
	2417185517600 [label="encoder.features.denseblock3.denselayer32.norm2.weight
 (128)" fillcolor=lightblue]
	2417185517600 -> 2416982712064
	2416982712064 [label=AccumulateGrad]
	2416982717584 -> 2416982704480
	2417185517840 [label="encoder.features.denseblock3.denselayer32.norm2.bias
 (128)" fillcolor=lightblue]
	2417185517840 -> 2416982717584
	2416982717584 [label=AccumulateGrad]
	2416982709664 -> 2417190383680
	2417185518480 [label="encoder.features.denseblock3.denselayer32.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2417185518480 -> 2416982709664
	2416982709664 [label=AccumulateGrad]
	2417190385888 -> 2417190371728
	2417185518320 [label="encoder.features.transition3.norm.weight
 (1280)" fillcolor=lightblue]
	2417185518320 -> 2417190385888
	2417190385888 [label=AccumulateGrad]
	2417190374800 -> 2417190371728
	2417185519440 [label="encoder.features.transition3.norm.bias
 (1280)" fillcolor=lightblue]
	2417185519440 -> 2417190374800
	2417190374800 [label=AccumulateGrad]
	2417190371968 -> 2417190373504
	2417185519920 [label="encoder.features.transition3.conv.weight
 (640, 1280, 1, 1)" fillcolor=lightblue]
	2417185519920 -> 2417190371968
	2417190371968 [label=AccumulateGrad]
	2416913644176 -> 2416913641008
	2416913644176 [label=ConvolutionBackward0]
	2417190382624 -> 2416913644176
	2417190382624 [label=ReluBackward0]
	2417190387424 -> 2417190382624
	2417190387424 [label=CudnnBatchNormBackward0]
	2416982711824 -> 2417190387424
	2416982711824 [label=ConvolutionBackward0]
	2416982708080 -> 2416982711824
	2416982708080 [label=ReluBackward0]
	2416982712304 -> 2416982708080
	2416982712304 [label=CudnnBatchNormBackward0]
	2416982711632 -> 2416982712304
	2416982711632 [label=CatBackward0]
	2416913644080 -> 2416982711632
	2416982708560 -> 2416982712304
	2417185520080 [label="encoder.features.denseblock4.denselayer1.norm1.weight
 (640)" fillcolor=lightblue]
	2417185520080 -> 2416982708560
	2416982708560 [label=AccumulateGrad]
	2416982712352 -> 2416982712304
	2417185519680 [label="encoder.features.denseblock4.denselayer1.norm1.bias
 (640)" fillcolor=lightblue]
	2417185519680 -> 2416982712352
	2416982712352 [label=AccumulateGrad]
	2416982708704 -> 2416982711824
	2417185520320 [label="encoder.features.denseblock4.denselayer1.conv1.weight
 (128, 640, 1, 1)" fillcolor=lightblue]
	2417185520320 -> 2416982708704
	2416982708704 [label=AccumulateGrad]
	2416982707792 -> 2417190387424
	2417185520560 [label="encoder.features.denseblock4.denselayer1.norm2.weight
 (128)" fillcolor=lightblue]
	2417185520560 -> 2416982707792
	2416982707792 [label=AccumulateGrad]
	2416982706400 -> 2417190387424
	2417185521440 [label="encoder.features.denseblock4.denselayer1.norm2.bias
 (128)" fillcolor=lightblue]
	2417185521440 -> 2416982706400
	2416982706400 [label=AccumulateGrad]
	2417190381424 -> 2416913644176
	2417185638272 [label="encoder.features.denseblock4.denselayer1.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2417185638272 -> 2417190381424
	2417190381424 [label=AccumulateGrad]
	2416913637984 -> 2416913641008
	2416913637984 [label=ConvolutionBackward0]
	2417190372640 -> 2416913637984
	2417190372640 [label=ReluBackward0]
	2416982712160 -> 2417190372640
	2416982712160 [label=CudnnBatchNormBackward0]
	2416982713744 -> 2416982712160
	2416982713744 [label=ConvolutionBackward0]
	2416982714176 -> 2416982713744
	2416982714176 [label=ReluBackward0]
	2416982714080 -> 2416982714176
	2416982714080 [label=CudnnBatchNormBackward0]
	2416982704720 -> 2416982714080
	2416982704720 [label=CatBackward0]
	2416913644080 -> 2416982704720
	2416913644176 -> 2416982704720
	2416982716336 -> 2416982714080
	2417185638032 [label="encoder.features.denseblock4.denselayer2.norm1.weight
 (672)" fillcolor=lightblue]
	2417185638032 -> 2416982716336
	2416982716336 [label=AccumulateGrad]
	2416982706256 -> 2416982714080
	2417185637952 [label="encoder.features.denseblock4.denselayer2.norm1.bias
 (672)" fillcolor=lightblue]
	2417185637952 -> 2416982706256
	2416982706256 [label=AccumulateGrad]
	2416982713888 -> 2416982713744
	2417185638432 [label="encoder.features.denseblock4.denselayer2.conv1.weight
 (128, 672, 1, 1)" fillcolor=lightblue]
	2417185638432 -> 2416982713888
	2416982713888 [label=AccumulateGrad]
	2416982714368 -> 2416982712160
	2417185638672 [label="encoder.features.denseblock4.denselayer2.norm2.weight
 (128)" fillcolor=lightblue]
	2417185638672 -> 2416982714368
	2416982714368 [label=AccumulateGrad]
	2416982712400 -> 2416982712160
	2417185639552 [label="encoder.features.denseblock4.denselayer2.norm2.bias
 (128)" fillcolor=lightblue]
	2417185639552 -> 2416982712400
	2416982712400 [label=AccumulateGrad]
	2417190372304 -> 2416913637984
	2417185636832 [label="encoder.features.denseblock4.denselayer2.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2417185636832 -> 2417190372304
	2417190372304 [label=AccumulateGrad]
	2416913630160 -> 2416913641008
	2416913630160 [label=ConvolutionBackward0]
	2416982714320 -> 2416913630160
	2416982714320 [label=ReluBackward0]
	2416982704816 -> 2416982714320
	2416982704816 [label=CudnnBatchNormBackward0]
	2416982708320 -> 2416982704816
	2416982708320 [label=ConvolutionBackward0]
	2416982714224 -> 2416982708320
	2416982714224 [label=ReluBackward0]
	2416982707696 -> 2416982714224
	2416982707696 [label=CudnnBatchNormBackward0]
	2416982716816 -> 2416982707696
	2416982716816 [label=CatBackward0]
	2416913644080 -> 2416982716816
	2416913644176 -> 2416982716816
	2416913637984 -> 2416982716816
	2416982715664 -> 2416982707696
	2417185636592 [label="encoder.features.denseblock4.denselayer3.norm1.weight
 (704)" fillcolor=lightblue]
	2417185636592 -> 2416982715664
	2416982715664 [label=AccumulateGrad]
	2416982713264 -> 2416982707696
	2417185636432 [label="encoder.features.denseblock4.denselayer3.norm1.bias
 (704)" fillcolor=lightblue]
	2417185636432 -> 2416982713264
	2416982713264 [label=AccumulateGrad]
	2416982714464 -> 2416982708320
	2417185637312 [label="encoder.features.denseblock4.denselayer3.conv1.weight
 (128, 704, 1, 1)" fillcolor=lightblue]
	2417185637312 -> 2416982714464
	2416982714464 [label=AccumulateGrad]
	2416982713216 -> 2416982704816
	2417185640032 [label="encoder.features.denseblock4.denselayer3.norm2.weight
 (128)" fillcolor=lightblue]
	2417185640032 -> 2416982713216
	2416982713216 [label=AccumulateGrad]
	2416982706064 -> 2416982704816
	2417185639952 [label="encoder.features.denseblock4.denselayer3.norm2.bias
 (128)" fillcolor=lightblue]
	2417185639952 -> 2416982706064
	2416982706064 [label=AccumulateGrad]
	2416982713648 -> 2416913630160
	2417185640512 [label="encoder.features.denseblock4.denselayer3.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2417185640512 -> 2416982713648
	2416982713648 [label=AccumulateGrad]
	2416913643696 -> 2416913641008
	2416913643696 [label=ConvolutionBackward0]
	2416982709232 -> 2416913643696
	2416982709232 [label=ReluBackward0]
	2416982714032 -> 2416982709232
	2416982714032 [label=CudnnBatchNormBackward0]
	2416982717536 -> 2416982714032
	2416982717536 [label=ConvolutionBackward0]
	2416982714512 -> 2416982717536
	2416982714512 [label=ReluBackward0]
	2416982717056 -> 2416982714512
	2416982717056 [label=CudnnBatchNormBackward0]
	2416982713408 -> 2416982717056
	2416982713408 [label=CatBackward0]
	2416913644080 -> 2416982713408
	2416913644176 -> 2416982713408
	2416913637984 -> 2416982713408
	2416913630160 -> 2416982713408
	2416982708512 -> 2416982717056
	2417185640272 [label="encoder.features.denseblock4.denselayer4.norm1.weight
 (736)" fillcolor=lightblue]
	2417185640272 -> 2416982708512
	2416982708512 [label=AccumulateGrad]
	2416982716960 -> 2416982717056
	2417185640192 [label="encoder.features.denseblock4.denselayer4.norm1.bias
 (736)" fillcolor=lightblue]
	2417185640192 -> 2416982716960
	2416982716960 [label=AccumulateGrad]
	2416982709568 -> 2416982717536
	2417185640912 [label="encoder.features.denseblock4.denselayer4.conv1.weight
 (128, 736, 1, 1)" fillcolor=lightblue]
	2417185640912 -> 2416982709568
	2416982709568 [label=AccumulateGrad]
	2416982707744 -> 2416982714032
	2417185641152 [label="encoder.features.denseblock4.denselayer4.norm2.weight
 (128)" fillcolor=lightblue]
	2417185641152 -> 2416982707744
	2416982707744 [label=AccumulateGrad]
	2416982707504 -> 2416982714032
	2417185642032 [label="encoder.features.denseblock4.denselayer4.norm2.bias
 (128)" fillcolor=lightblue]
	2417185642032 -> 2416982707504
	2416982707504 [label=AccumulateGrad]
	2416982704384 -> 2416913643696
	2417185642912 [label="encoder.features.denseblock4.denselayer4.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2417185642912 -> 2416982704384
	2416982704384 [label=AccumulateGrad]
	2416913631120 -> 2416913641008
	2416913631120 [label=ConvolutionBackward0]
	2416982707552 -> 2416913631120
	2416982707552 [label=ReluBackward0]
	2416982713504 -> 2416982707552
	2416982713504 [label=CudnnBatchNormBackward0]
	2416982716768 -> 2416982713504
	2416982716768 [label=ConvolutionBackward0]
	2416982713984 -> 2416982716768
	2416982713984 [label=ReluBackward0]
	2416982713072 -> 2416982713984
	2416982713072 [label=CudnnBatchNormBackward0]
	2416982712880 -> 2416982713072
	2416982712880 [label=CatBackward0]
	2416913644080 -> 2416982712880
	2416913644176 -> 2416982712880
	2416913637984 -> 2416982712880
	2416913630160 -> 2416982712880
	2416913643696 -> 2416982712880
	2416982713024 -> 2416982713072
	2417185641792 [label="encoder.features.denseblock4.denselayer5.norm1.weight
 (768)" fillcolor=lightblue]
	2417185641792 -> 2416982713024
	2416982713024 [label=AccumulateGrad]
	2416982709856 -> 2416982713072
	2417185642432 [label="encoder.features.denseblock4.denselayer5.norm1.bias
 (768)" fillcolor=lightblue]
	2417185642432 -> 2416982709856
	2416982709856 [label=AccumulateGrad]
	2416982708176 -> 2416982716768
	2417185642992 [label="encoder.features.denseblock4.denselayer5.conv1.weight
 (128, 768, 1, 1)" fillcolor=lightblue]
	2417185642992 -> 2416982708176
	2416982708176 [label=AccumulateGrad]
	2416982712688 -> 2416982713504
	2417185644032 [label="encoder.features.denseblock4.denselayer5.norm2.weight
 (128)" fillcolor=lightblue]
	2417185644032 -> 2416982712688
	2416982712688 [label=AccumulateGrad]
	2416982713456 -> 2416982713504
	2417185643872 [label="encoder.features.denseblock4.denselayer5.norm2.bias
 (128)" fillcolor=lightblue]
	2417185643872 -> 2416982713456
	2416982713456 [label=AccumulateGrad]
	2416982717632 -> 2416913631120
	2417185644272 [label="encoder.features.denseblock4.denselayer5.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2417185644272 -> 2416982717632
	2416982717632 [label=AccumulateGrad]
	2417190382864 -> 2416913641008
	2417190382864 [label=ConvolutionBackward0]
	2416982707408 -> 2417190382864
	2416982707408 [label=ReluBackward0]
	2416982706784 -> 2416982707408
	2416982706784 [label=CudnnBatchNormBackward0]
	2416982710576 -> 2416982706784
	2416982710576 [label=ConvolutionBackward0]
	2416982713168 -> 2416982710576
	2416982713168 [label=ReluBackward0]
	2416982710816 -> 2416982713168
	2416982710816 [label=CudnnBatchNormBackward0]
	2416982711200 -> 2416982710816
	2416982711200 [label=CatBackward0]
	2416913644080 -> 2416982711200
	2416913644176 -> 2416982711200
	2416913637984 -> 2416982711200
	2416913630160 -> 2416982711200
	2416913643696 -> 2416982711200
	2416913631120 -> 2416982711200
	2416982718352 -> 2416982710816
	2417185644112 [label="encoder.features.denseblock4.denselayer6.norm1.weight
 (800)" fillcolor=lightblue]
	2417185644112 -> 2416982718352
	2416982718352 [label=AccumulateGrad]
	2416982710672 -> 2416982710816
	2417185644352 [label="encoder.features.denseblock4.denselayer6.norm1.bias
 (800)" fillcolor=lightblue]
	2417185644352 -> 2416982710672
	2416982710672 [label=AccumulateGrad]
	2416982711152 -> 2416982710576
	2417185645952 [label="encoder.features.denseblock4.denselayer6.conv1.weight
 (128, 800, 1, 1)" fillcolor=lightblue]
	2417185645952 -> 2416982711152
	2416982711152 [label=AccumulateGrad]
	2416982714560 -> 2416982706784
	2417185645872 [label="encoder.features.denseblock4.denselayer6.norm2.weight
 (128)" fillcolor=lightblue]
	2417185645872 -> 2416982714560
	2416982714560 [label=AccumulateGrad]
	2416982706352 -> 2416982706784
	2417185645632 [label="encoder.features.denseblock4.denselayer6.norm2.bias
 (128)" fillcolor=lightblue]
	2417185645632 -> 2416982706352
	2416982706352 [label=AccumulateGrad]
	2416982716864 -> 2417190382864
	2417185646112 [label="encoder.features.denseblock4.denselayer6.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2417185646112 -> 2416982716864
	2416982716864 [label=AccumulateGrad]
	2417190374512 -> 2416913641008
	2417190374512 [label=ConvolutionBackward0]
	2416982713120 -> 2417190374512
	2416982713120 [label=ReluBackward0]
	2416982720224 -> 2416982713120
	2416982720224 [label=CudnnBatchNormBackward0]
	2416982711056 -> 2416982720224
	2416982711056 [label=ConvolutionBackward0]
	2416982716000 -> 2416982711056
	2416982716000 [label=ReluBackward0]
	2416982710960 -> 2416982716000
	2416982710960 [label=CudnnBatchNormBackward0]
	2416982706928 -> 2416982710960
	2416982706928 [label=CatBackward0]
	2416913644080 -> 2416982706928
	2416913644176 -> 2416982706928
	2416913637984 -> 2416982706928
	2416913630160 -> 2416982706928
	2416913643696 -> 2416982706928
	2416913631120 -> 2416982706928
	2417190382864 -> 2416982706928
	2416982715904 -> 2416982710960
	2417185646512 [label="encoder.features.denseblock4.denselayer7.norm1.weight
 (832)" fillcolor=lightblue]
	2417185646512 -> 2416982715904
	2416982715904 [label=AccumulateGrad]
	2416982706448 -> 2416982710960
	2417185647312 [label="encoder.features.denseblock4.denselayer7.norm1.bias
 (832)" fillcolor=lightblue]
	2417185647312 -> 2416982706448
	2416982706448 [label=AccumulateGrad]
	2416982716144 -> 2416982711056
	2417185647952 [label="encoder.features.denseblock4.denselayer7.conv1.weight
 (128, 832, 1, 1)" fillcolor=lightblue]
	2417185647952 -> 2416982716144
	2416982716144 [label=AccumulateGrad]
	2416982711104 -> 2416982720224
	2417185647712 [label="encoder.features.denseblock4.denselayer7.norm2.weight
 (128)" fillcolor=lightblue]
	2417185647712 -> 2416982711104
	2416982711104 [label=AccumulateGrad]
	2416982718112 -> 2416982720224
	2417185647472 [label="encoder.features.denseblock4.denselayer7.norm2.bias
 (128)" fillcolor=lightblue]
	2417185647472 -> 2416982718112
	2416982718112 [label=AccumulateGrad]
	2416982706208 -> 2417190374512
	2417185648432 [label="encoder.features.denseblock4.denselayer7.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2417185648432 -> 2416982706208
	2416982706208 [label=AccumulateGrad]
	2417190372400 -> 2416913641008
	2417190372400 [label=ConvolutionBackward0]
	2416982711248 -> 2417190372400
	2416982711248 [label=ReluBackward0]
	2416982712544 -> 2416982711248
	2416982712544 [label=CudnnBatchNormBackward0]
	2416982712112 -> 2416982712544
	2416982712112 [label=ConvolutionBackward0]
	2416982706832 -> 2416982712112
	2416982706832 [label=ReluBackward0]
	2416982705872 -> 2416982706832
	2416982705872 [label=CudnnBatchNormBackward0]
	2417186242176 -> 2416982705872
	2417186242176 [label=CatBackward0]
	2416913644080 -> 2417186242176
	2416913644176 -> 2417186242176
	2416913637984 -> 2417186242176
	2416913630160 -> 2417186242176
	2416913643696 -> 2417186242176
	2416913631120 -> 2417186242176
	2417190382864 -> 2417186242176
	2417190374512 -> 2417186242176
	2417186242320 -> 2416982705872
	2417185649472 [label="encoder.features.denseblock4.denselayer8.norm1.weight
 (864)" fillcolor=lightblue]
	2417185649472 -> 2417186242320
	2417186242320 [label=AccumulateGrad]
	2417186242128 -> 2416982705872
	2417185649312 [label="encoder.features.denseblock4.denselayer8.norm1.bias
 (864)" fillcolor=lightblue]
	2417185649312 -> 2417186242128
	2417186242128 [label=AccumulateGrad]
	2416982719504 -> 2416982712112
	2417185649712 [label="encoder.features.denseblock4.denselayer8.conv1.weight
 (128, 864, 1, 1)" fillcolor=lightblue]
	2417185649712 -> 2416982719504
	2416982719504 [label=AccumulateGrad]
	2416982715952 -> 2416982712544
	2417185649552 [label="encoder.features.denseblock4.denselayer8.norm2.weight
 (128)" fillcolor=lightblue]
	2417185649552 -> 2416982715952
	2416982715952 [label=AccumulateGrad]
	2416982718736 -> 2416982712544
	2417185649792 [label="encoder.features.denseblock4.denselayer8.norm2.bias
 (128)" fillcolor=lightblue]
	2417185649792 -> 2416982718736
	2416982718736 [label=AccumulateGrad]
	2416982709424 -> 2417190372400
	2417185651392 [label="encoder.features.denseblock4.denselayer8.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2417185651392 -> 2416982709424
	2416982709424 [label=AccumulateGrad]
	2417190379360 -> 2416913641008
	2417190379360 [label=ConvolutionBackward0]
	2416982711440 -> 2417190379360
	2416982711440 [label=ReluBackward0]
	2416982706880 -> 2416982711440
	2416982706880 [label=CudnnBatchNormBackward0]
	2417186242368 -> 2416982706880
	2417186242368 [label=ConvolutionBackward0]
	2417186240976 -> 2417186242368
	2417186240976 [label=ReluBackward0]
	2417186241216 -> 2417186240976
	2417186241216 [label=CudnnBatchNormBackward0]
	2417186240400 -> 2417186241216
	2417186240400 [label=CatBackward0]
	2416913644080 -> 2417186240400
	2416913644176 -> 2417186240400
	2416913637984 -> 2417186240400
	2416913630160 -> 2417186240400
	2416913643696 -> 2417186240400
	2416913631120 -> 2417186240400
	2417190382864 -> 2417186240400
	2417190374512 -> 2417186240400
	2417190372400 -> 2417186240400
	2417186240544 -> 2417186241216
	2417185651312 [label="encoder.features.denseblock4.denselayer9.norm1.weight
 (896)" fillcolor=lightblue]
	2417185651312 -> 2417186240544
	2417186240544 [label=AccumulateGrad]
	2417186241168 -> 2417186241216
	2417185651072 [label="encoder.features.denseblock4.denselayer9.norm1.bias
 (896)" fillcolor=lightblue]
	2417185651072 -> 2417186241168
	2417186241168 [label=AccumulateGrad]
	2417186241024 -> 2417186242368
	2416981673456 [label="encoder.features.denseblock4.denselayer9.conv1.weight
 (128, 896, 1, 1)" fillcolor=lightblue]
	2416981673456 -> 2417186241024
	2417186241024 [label=AccumulateGrad]
	2417186241600 -> 2416982706880
	2417001579216 [label="encoder.features.denseblock4.denselayer9.norm2.weight
 (128)" fillcolor=lightblue]
	2417001579216 -> 2417186241600
	2417186241600 [label=AccumulateGrad]
	2417186241552 -> 2416982706880
	2417001588576 [label="encoder.features.denseblock4.denselayer9.norm2.bias
 (128)" fillcolor=lightblue]
	2417001588576 -> 2417186241552
	2417186241552 [label=AccumulateGrad]
	2416982719072 -> 2417190379360
	2417001589616 [label="encoder.features.denseblock4.denselayer9.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2417001589616 -> 2416982719072
	2416982719072 [label=AccumulateGrad]
	2417190383248 -> 2416913641008
	2417190383248 [label=ConvolutionBackward0]
	2416982714416 -> 2417190383248
	2416982714416 [label=ReluBackward0]
	2417186241744 -> 2416982714416
	2417186241744 [label=CudnnBatchNormBackward0]
	2417186239728 -> 2417186241744
	2417186239728 [label=ConvolutionBackward0]
	2417186239104 -> 2417186239728
	2417186239104 [label=ReluBackward0]
	2417186239344 -> 2417186239104
	2417186239344 [label=CudnnBatchNormBackward0]
	2417186238528 -> 2417186239344
	2417186238528 [label=CatBackward0]
	2416913644080 -> 2417186238528
	2416913644176 -> 2417186238528
	2416913637984 -> 2417186238528
	2416913630160 -> 2417186238528
	2416913643696 -> 2417186238528
	2416913631120 -> 2417186238528
	2417190382864 -> 2417186238528
	2417190374512 -> 2417186238528
	2417190372400 -> 2417186238528
	2417190379360 -> 2417186238528
	2417186238672 -> 2417186239344
	2417001592896 [label="encoder.features.denseblock4.denselayer10.norm1.weight
 (928)" fillcolor=lightblue]
	2417001592896 -> 2417186238672
	2417186238672 [label=AccumulateGrad]
	2417186239296 -> 2417186239344
	2417001582656 [label="encoder.features.denseblock4.denselayer10.norm1.bias
 (928)" fillcolor=lightblue]
	2417001582656 -> 2417186239296
	2417186239296 [label=AccumulateGrad]
	2417186239152 -> 2417186239728
	2417001584416 [label="encoder.features.denseblock4.denselayer10.conv1.weight
 (128, 928, 1, 1)" fillcolor=lightblue]
	2417001584416 -> 2417186239152
	2417186239152 [label=AccumulateGrad]
	2417186239776 -> 2417186241744
	2417001589376 [label="encoder.features.denseblock4.denselayer10.norm2.weight
 (128)" fillcolor=lightblue]
	2417001589376 -> 2417186239776
	2417186239776 [label=AccumulateGrad]
	2417186241696 -> 2417186241744
	2417001583136 [label="encoder.features.denseblock4.denselayer10.norm2.bias
 (128)" fillcolor=lightblue]
	2417001583136 -> 2417186241696
	2417186241696 [label=AccumulateGrad]
	2416982711584 -> 2417190383248
	2417001593696 [label="encoder.features.denseblock4.denselayer10.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2417001593696 -> 2416982711584
	2416982711584 [label=AccumulateGrad]
	2417190380032 -> 2416913641008
	2417190380032 [label=ConvolutionBackward0]
	2417186239920 -> 2417190380032
	2417186239920 [label=ReluBackward0]
	2417186239968 -> 2417186239920
	2417186239968 [label=CudnnBatchNormBackward0]
	2417186237904 -> 2417186239968
	2417186237904 [label=ConvolutionBackward0]
	2417186237328 -> 2417186237904
	2417186237328 [label=ReluBackward0]
	2417186237520 -> 2417186237328
	2417186237520 [label=CudnnBatchNormBackward0]
	2417186236752 -> 2417186237520
	2417186236752 [label=CatBackward0]
	2416913644080 -> 2417186236752
	2416913644176 -> 2417186236752
	2416913637984 -> 2417186236752
	2416913630160 -> 2417186236752
	2416913643696 -> 2417186236752
	2416913631120 -> 2417186236752
	2417190382864 -> 2417186236752
	2417190374512 -> 2417186236752
	2417190372400 -> 2417186236752
	2417190379360 -> 2417186236752
	2417190383248 -> 2417186236752
	2417186236896 -> 2417186237520
	2417001588336 [label="encoder.features.denseblock4.denselayer11.norm1.weight
 (960)" fillcolor=lightblue]
	2417001588336 -> 2417186236896
	2417186236896 [label=AccumulateGrad]
	2417186237472 -> 2417186237520
	2417001591616 [label="encoder.features.denseblock4.denselayer11.norm1.bias
 (960)" fillcolor=lightblue]
	2417001591616 -> 2417186237472
	2417186237472 [label=AccumulateGrad]
	2417186237376 -> 2417186237904
	2417001579616 [label="encoder.features.denseblock4.denselayer11.conv1.weight
 (128, 960, 1, 1)" fillcolor=lightblue]
	2417001579616 -> 2417186237376
	2417186237376 [label=AccumulateGrad]
	2417186237952 -> 2417186239968
	2417001587776 [label="encoder.features.denseblock4.denselayer11.norm2.weight
 (128)" fillcolor=lightblue]
	2417001587776 -> 2417186237952
	2417186237952 [label=AccumulateGrad]
	2417186238480 -> 2417186239968
	2417001578576 [label="encoder.features.denseblock4.denselayer11.norm2.bias
 (128)" fillcolor=lightblue]
	2417001578576 -> 2417186238480
	2417186238480 [label=AccumulateGrad]
	2417186240592 -> 2417190380032
	2417001585056 [label="encoder.features.denseblock4.denselayer11.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2417001585056 -> 2417186240592
	2417186240592 [label=AccumulateGrad]
	2417190372112 -> 2416913641008
	2417190372112 [label=ConvolutionBackward0]
	2417186238096 -> 2417190372112
	2417186238096 [label=ReluBackward0]
	2417186238144 -> 2417186238096
	2417186238144 [label=CudnnBatchNormBackward0]
	2417186236128 -> 2417186238144
	2417186236128 [label=ConvolutionBackward0]
	2417186235504 -> 2417186236128
	2417186235504 [label=ReluBackward0]
	2417186235744 -> 2417186235504
	2417186235744 [label=CudnnBatchNormBackward0]
	2417186234928 -> 2417186235744
	2417186234928 [label=CatBackward0]
	2416913644080 -> 2417186234928
	2416913644176 -> 2417186234928
	2416913637984 -> 2417186234928
	2416913630160 -> 2417186234928
	2416913643696 -> 2417186234928
	2416913631120 -> 2417186234928
	2417190382864 -> 2417186234928
	2417190374512 -> 2417186234928
	2417190372400 -> 2417186234928
	2417190379360 -> 2417186234928
	2417190383248 -> 2417186234928
	2417190380032 -> 2417186234928
	2417186235072 -> 2417186235744
	2417001580016 [label="encoder.features.denseblock4.denselayer12.norm1.weight
 (992)" fillcolor=lightblue]
	2417001580016 -> 2417186235072
	2417186235072 [label=AccumulateGrad]
	2417186235696 -> 2417186235744
	2417001581536 [label="encoder.features.denseblock4.denselayer12.norm1.bias
 (992)" fillcolor=lightblue]
	2417001581536 -> 2417186235696
	2417186235696 [label=AccumulateGrad]
	2417186235552 -> 2417186236128
	2417001579856 [label="encoder.features.denseblock4.denselayer12.conv1.weight
 (128, 992, 1, 1)" fillcolor=lightblue]
	2417001579856 -> 2417186235552
	2417186235552 [label=AccumulateGrad]
	2417186236176 -> 2417186238144
	2417001587456 [label="encoder.features.denseblock4.denselayer12.norm2.weight
 (128)" fillcolor=lightblue]
	2417001587456 -> 2417186236176
	2417186236176 [label=AccumulateGrad]
	2417186236704 -> 2417186238144
	2417001582496 [label="encoder.features.denseblock4.denselayer12.norm2.bias
 (128)" fillcolor=lightblue]
	2417001582496 -> 2417186236704
	2417186236704 [label=AccumulateGrad]
	2417186238720 -> 2417190372112
	2417001579696 [label="encoder.features.denseblock4.denselayer12.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2417001579696 -> 2417186238720
	2417186238720 [label=AccumulateGrad]
	2417190378112 -> 2416913641008
	2417190378112 [label=ConvolutionBackward0]
	2417186236320 -> 2417190378112
	2417186236320 [label=ReluBackward0]
	2417186236368 -> 2417186236320
	2417186236368 [label=CudnnBatchNormBackward0]
	2417186234256 -> 2417186236368
	2417186234256 [label=ConvolutionBackward0]
	2417186233632 -> 2417186234256
	2417186233632 [label=ReluBackward0]
	2417186233872 -> 2417186233632
	2417186233872 [label=CudnnBatchNormBackward0]
	2417186233056 -> 2417186233872
	2417186233056 [label=CatBackward0]
	2416913644080 -> 2417186233056
	2416913644176 -> 2417186233056
	2416913637984 -> 2417186233056
	2416913630160 -> 2417186233056
	2416913643696 -> 2417186233056
	2416913631120 -> 2417186233056
	2417190382864 -> 2417186233056
	2417190374512 -> 2417186233056
	2417190372400 -> 2417186233056
	2417190379360 -> 2417186233056
	2417190383248 -> 2417186233056
	2417190380032 -> 2417186233056
	2417190372112 -> 2417186233056
	2417186233200 -> 2417186233872
	2417001590256 [label="encoder.features.denseblock4.denselayer13.norm1.weight
 (1024)" fillcolor=lightblue]
	2417001590256 -> 2417186233200
	2417186233200 [label=AccumulateGrad]
	2417186233824 -> 2417186233872
	2417001592416 [label="encoder.features.denseblock4.denselayer13.norm1.bias
 (1024)" fillcolor=lightblue]
	2417001592416 -> 2417186233824
	2417186233824 [label=AccumulateGrad]
	2417186233680 -> 2417186234256
	2417001584736 [label="encoder.features.denseblock4.denselayer13.conv1.weight
 (128, 1024, 1, 1)" fillcolor=lightblue]
	2417001584736 -> 2417186233680
	2417186233680 [label=AccumulateGrad]
	2417186234304 -> 2417186236368
	2417001592576 [label="encoder.features.denseblock4.denselayer13.norm2.weight
 (128)" fillcolor=lightblue]
	2417001592576 -> 2417186234304
	2417186234304 [label=AccumulateGrad]
	2417186234880 -> 2417186236368
	2417001582416 [label="encoder.features.denseblock4.denselayer13.norm2.bias
 (128)" fillcolor=lightblue]
	2417001582416 -> 2417186234880
	2417186234880 [label=AccumulateGrad]
	2417186236944 -> 2417190378112
	2417001580976 [label="encoder.features.denseblock4.denselayer13.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2417001580976 -> 2417186236944
	2417186236944 [label=AccumulateGrad]
	2417190382672 -> 2416913641008
	2417190382672 [label=ConvolutionBackward0]
	2417186234448 -> 2417190382672
	2417186234448 [label=ReluBackward0]
	2417186234496 -> 2417186234448
	2417186234496 [label=CudnnBatchNormBackward0]
	2417186232384 -> 2417186234496
	2417186232384 [label=ConvolutionBackward0]
	2417186231760 -> 2417186232384
	2417186231760 [label=ReluBackward0]
	2417186232000 -> 2417186231760
	2417186232000 [label=CudnnBatchNormBackward0]
	2417186231184 -> 2417186232000
	2417186231184 [label=CatBackward0]
	2416913644080 -> 2417186231184
	2416913644176 -> 2417186231184
	2416913637984 -> 2417186231184
	2416913630160 -> 2417186231184
	2416913643696 -> 2417186231184
	2416913631120 -> 2417186231184
	2417190382864 -> 2417186231184
	2417190374512 -> 2417186231184
	2417190372400 -> 2417186231184
	2417190379360 -> 2417186231184
	2417190383248 -> 2417186231184
	2417190380032 -> 2417186231184
	2417190372112 -> 2417186231184
	2417190378112 -> 2417186231184
	2417186231328 -> 2417186232000
	2417001590816 [label="encoder.features.denseblock4.denselayer14.norm1.weight
 (1056)" fillcolor=lightblue]
	2417001590816 -> 2417186231328
	2417186231328 [label=AccumulateGrad]
	2417186231952 -> 2417186232000
	2417001579376 [label="encoder.features.denseblock4.denselayer14.norm1.bias
 (1056)" fillcolor=lightblue]
	2417001579376 -> 2417186231952
	2417186231952 [label=AccumulateGrad]
	2417186231808 -> 2417186232384
	2417001581856 [label="encoder.features.denseblock4.denselayer14.conv1.weight
 (128, 1056, 1, 1)" fillcolor=lightblue]
	2417001581856 -> 2417186231808
	2417186231808 [label=AccumulateGrad]
	2417186232432 -> 2417186234496
	2417001582176 [label="encoder.features.denseblock4.denselayer14.norm2.weight
 (128)" fillcolor=lightblue]
	2417001582176 -> 2417186232432
	2417186232432 [label=AccumulateGrad]
	2417186233008 -> 2417186234496
	2417001589136 [label="encoder.features.denseblock4.denselayer14.norm2.bias
 (128)" fillcolor=lightblue]
	2417001589136 -> 2417186233008
	2417186233008 [label=AccumulateGrad]
	2417186235120 -> 2417190382672
	2417001592496 [label="encoder.features.denseblock4.denselayer14.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2417001592496 -> 2417186235120
	2417186235120 [label=AccumulateGrad]
	2417190379072 -> 2416913641008
	2417190379072 [label=ConvolutionBackward0]
	2417186232576 -> 2417190379072
	2417186232576 [label=ReluBackward0]
	2417186232624 -> 2417186232576
	2417186232624 [label=CudnnBatchNormBackward0]
	2417186230512 -> 2417186232624
	2417186230512 [label=ConvolutionBackward0]
	2417186229888 -> 2417186230512
	2417186229888 [label=ReluBackward0]
	2417186230128 -> 2417186229888
	2417186230128 [label=CudnnBatchNormBackward0]
	2417186229360 -> 2417186230128
	2417186229360 [label=CatBackward0]
	2416913644080 -> 2417186229360
	2416913644176 -> 2417186229360
	2416913637984 -> 2417186229360
	2416913630160 -> 2417186229360
	2416913643696 -> 2417186229360
	2416913631120 -> 2417186229360
	2417190382864 -> 2417186229360
	2417190374512 -> 2417186229360
	2417190372400 -> 2417186229360
	2417190379360 -> 2417186229360
	2417190383248 -> 2417186229360
	2417190380032 -> 2417186229360
	2417190372112 -> 2417186229360
	2417190378112 -> 2417186229360
	2417190382672 -> 2417186229360
	2417186229456 -> 2417186230128
	2417001582096 [label="encoder.features.denseblock4.denselayer15.norm1.weight
 (1088)" fillcolor=lightblue]
	2417001582096 -> 2417186229456
	2417186229456 [label=AccumulateGrad]
	2417186230080 -> 2417186230128
	2417001593296 [label="encoder.features.denseblock4.denselayer15.norm1.bias
 (1088)" fillcolor=lightblue]
	2417001593296 -> 2417186230080
	2417186230080 [label=AccumulateGrad]
	2417186229936 -> 2417186230512
	2417001588096 [label="encoder.features.denseblock4.denselayer15.conv1.weight
 (128, 1088, 1, 1)" fillcolor=lightblue]
	2417001588096 -> 2417186229936
	2417186229936 [label=AccumulateGrad]
	2417186230560 -> 2417186232624
	2417001589296 [label="encoder.features.denseblock4.denselayer15.norm2.weight
 (128)" fillcolor=lightblue]
	2417001589296 -> 2417186230560
	2417186230560 [label=AccumulateGrad]
	2417186231136 -> 2417186232624
	2417001581456 [label="encoder.features.denseblock4.denselayer15.norm2.bias
 (128)" fillcolor=lightblue]
	2417001581456 -> 2417186231136
	2417186231136 [label=AccumulateGrad]
	2417186233248 -> 2417190379072
	2417001586496 [label="encoder.features.denseblock4.denselayer15.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2417001586496 -> 2417186233248
	2417186233248 [label=AccumulateGrad]
	2417190376336 -> 2416913641008
	2417190376336 [label=ConvolutionBackward0]
	2417186230704 -> 2417190376336
	2417186230704 [label=ReluBackward0]
	2417186230752 -> 2417186230704
	2417186230752 [label=CudnnBatchNormBackward0]
	2417186228688 -> 2417186230752
	2417186228688 [label=ConvolutionBackward0]
	2417186228064 -> 2417186228688
	2417186228064 [label=ReluBackward0]
	2417186228304 -> 2417186228064
	2417186228304 [label=CudnnBatchNormBackward0]
	2417186227536 -> 2417186228304
	2417186227536 [label=CatBackward0]
	2416913644080 -> 2417186227536
	2416913644176 -> 2417186227536
	2416913637984 -> 2417186227536
	2416913630160 -> 2417186227536
	2416913643696 -> 2417186227536
	2416913631120 -> 2417186227536
	2417190382864 -> 2417186227536
	2417190374512 -> 2417186227536
	2417190372400 -> 2417186227536
	2417190379360 -> 2417186227536
	2417190383248 -> 2417186227536
	2417190380032 -> 2417186227536
	2417190372112 -> 2417186227536
	2417190378112 -> 2417186227536
	2417190382672 -> 2417186227536
	2417190379072 -> 2417186227536
	2417186227632 -> 2417186228304
	2417001591216 [label="encoder.features.denseblock4.denselayer16.norm1.weight
 (1120)" fillcolor=lightblue]
	2417001591216 -> 2417186227632
	2417186227632 [label=AccumulateGrad]
	2417186228256 -> 2417186228304
	2417001594176 [label="encoder.features.denseblock4.denselayer16.norm1.bias
 (1120)" fillcolor=lightblue]
	2417001594176 -> 2417186228256
	2417186228256 [label=AccumulateGrad]
	2417186228112 -> 2417186228688
	2417001587856 [label="encoder.features.denseblock4.denselayer16.conv1.weight
 (128, 1120, 1, 1)" fillcolor=lightblue]
	2417001587856 -> 2417186228112
	2417186228112 [label=AccumulateGrad]
	2417186228736 -> 2417186230752
	2417001581216 [label="encoder.features.denseblock4.denselayer16.norm2.weight
 (128)" fillcolor=lightblue]
	2417001581216 -> 2417186228736
	2417186228736 [label=AccumulateGrad]
	2417186229312 -> 2417186230752
	2417001586336 [label="encoder.features.denseblock4.denselayer16.norm2.bias
 (128)" fillcolor=lightblue]
	2417001586336 -> 2417186229312
	2417186229312 [label=AccumulateGrad]
	2417186231376 -> 2417190376336
	2417001591136 [label="encoder.features.denseblock4.denselayer16.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2417001591136 -> 2417186231376
	2417186231376 [label=AccumulateGrad]
	2417190379408 -> 2416913641008
	2417190379408 [label=ConvolutionBackward0]
	2417186228880 -> 2417190379408
	2417186228880 [label=ReluBackward0]
	2417186228928 -> 2417186228880
	2417186228928 [label=CudnnBatchNormBackward0]
	2417186226864 -> 2417186228928
	2417186226864 [label=ConvolutionBackward0]
	2417186226240 -> 2417186226864
	2417186226240 [label=ReluBackward0]
	2417186226480 -> 2417186226240
	2417186226480 [label=CudnnBatchNormBackward0]
	2417186242512 -> 2417186226480
	2417186242512 [label=CatBackward0]
	2416913644080 -> 2417186242512
	2416913644176 -> 2417186242512
	2416913637984 -> 2417186242512
	2416913630160 -> 2417186242512
	2416913643696 -> 2417186242512
	2416913631120 -> 2417186242512
	2417190382864 -> 2417186242512
	2417190374512 -> 2417186242512
	2417190372400 -> 2417186242512
	2417190379360 -> 2417186242512
	2417190383248 -> 2417186242512
	2417190380032 -> 2417186242512
	2417190372112 -> 2417186242512
	2417190378112 -> 2417186242512
	2417190382672 -> 2417186242512
	2417190379072 -> 2417186242512
	2417190376336 -> 2417186242512
	2417186242272 -> 2417186226480
	2417001582336 [label="encoder.features.denseblock4.denselayer17.norm1.weight
 (1152)" fillcolor=lightblue]
	2417001582336 -> 2417186242272
	2417186242272 [label=AccumulateGrad]
	2417186226432 -> 2417186226480
	2417001586736 [label="encoder.features.denseblock4.denselayer17.norm1.bias
 (1152)" fillcolor=lightblue]
	2417001586736 -> 2417186226432
	2417186226432 [label=AccumulateGrad]
	2417186226288 -> 2417186226864
	2417001585216 [label="encoder.features.denseblock4.denselayer17.conv1.weight
 (128, 1152, 1, 1)" fillcolor=lightblue]
	2417001585216 -> 2417186226288
	2417186226288 [label=AccumulateGrad]
	2417186226912 -> 2417186228928
	2417001585536 [label="encoder.features.denseblock4.denselayer17.norm2.weight
 (128)" fillcolor=lightblue]
	2417001585536 -> 2417186226912
	2417186226912 [label=AccumulateGrad]
	2417186227488 -> 2417186228928
	2417001586256 [label="encoder.features.denseblock4.denselayer17.norm2.bias
 (128)" fillcolor=lightblue]
	2417001586256 -> 2417186227488
	2417186227488 [label=AccumulateGrad]
	2417186229504 -> 2417190379408
	2417001591776 [label="encoder.features.denseblock4.denselayer17.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2417001591776 -> 2417186229504
	2417186229504 [label=AccumulateGrad]
	2417190385552 -> 2416913641008
	2417190385552 [label=ConvolutionBackward0]
	2417186227056 -> 2417190385552
	2417186227056 [label=ReluBackward0]
	2417186227104 -> 2417186227056
	2417186227104 [label=CudnnBatchNormBackward0]
	2417186242032 -> 2417186227104
	2417186242032 [label=ConvolutionBackward0]
	2417186241888 -> 2417186242032
	2417186241888 [label=ReluBackward0]
	2417186241456 -> 2417186241888
	2417186241456 [label=CudnnBatchNormBackward0]
	2417186241360 -> 2417186241456
	2417186241360 [label=CatBackward0]
	2416913644080 -> 2417186241360
	2416913644176 -> 2417186241360
	2416913637984 -> 2417186241360
	2416913630160 -> 2417186241360
	2416913643696 -> 2417186241360
	2416913631120 -> 2417186241360
	2417190382864 -> 2417186241360
	2417190374512 -> 2417186241360
	2417190372400 -> 2417186241360
	2417190379360 -> 2417186241360
	2417190383248 -> 2417186241360
	2417190380032 -> 2417186241360
	2417190372112 -> 2417186241360
	2417190378112 -> 2417186241360
	2417190382672 -> 2417186241360
	2417190379072 -> 2417186241360
	2417190376336 -> 2417186241360
	2417190379408 -> 2417186241360
	2417186241504 -> 2417186241456
	2417001585696 [label="encoder.features.denseblock4.denselayer18.norm1.weight
 (1184)" fillcolor=lightblue]
	2417001585696 -> 2417186241504
	2417186241504 [label=AccumulateGrad]
	2417186241648 -> 2417186241456
	2417001587936 [label="encoder.features.denseblock4.denselayer18.norm1.bias
 (1184)" fillcolor=lightblue]
	2417001587936 -> 2417186241648
	2417186241648 [label=AccumulateGrad]
	2417186241984 -> 2417186242032
	2417001582896 [label="encoder.features.denseblock4.denselayer18.conv1.weight
 (128, 1184, 1, 1)" fillcolor=lightblue]
	2417001582896 -> 2417186241984
	2417186241984 [label=AccumulateGrad]
	2417186241840 -> 2417186227104
	2417001594096 [label="encoder.features.denseblock4.denselayer18.norm2.weight
 (128)" fillcolor=lightblue]
	2417001594096 -> 2417186241840
	2417186241840 [label=AccumulateGrad]
	2417186242464 -> 2417186227104
	2417001592976 [label="encoder.features.denseblock4.denselayer18.norm2.bias
 (128)" fillcolor=lightblue]
	2417001592976 -> 2417186242464
	2417186242464 [label=AccumulateGrad]
	2417186227680 -> 2417190385552
	2417001587616 [label="encoder.features.denseblock4.denselayer18.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2417001587616 -> 2417186227680
	2417186227680 [label=AccumulateGrad]
	2417190378352 -> 2416913641008
	2417190378352 [label=ConvolutionBackward0]
	2417186241936 -> 2417190378352
	2417186241936 [label=ReluBackward0]
	2417186242080 -> 2417186241936
	2417186242080 [label=CudnnBatchNormBackward0]
	2417186241408 -> 2417186242080
	2417186241408 [label=ConvolutionBackward0]
	2417186240688 -> 2417186241408
	2417186240688 [label=ReluBackward0]
	2417186240736 -> 2417186240688
	2417186240736 [label=CudnnBatchNormBackward0]
	2417186240496 -> 2417186240736
	2417186240496 [label=CatBackward0]
	2416913644080 -> 2417186240496
	2416913644176 -> 2417186240496
	2416913637984 -> 2417186240496
	2416913630160 -> 2417186240496
	2416913643696 -> 2417186240496
	2416913631120 -> 2417186240496
	2417190382864 -> 2417186240496
	2417190374512 -> 2417186240496
	2417190372400 -> 2417186240496
	2417190379360 -> 2417186240496
	2417190383248 -> 2417186240496
	2417190380032 -> 2417186240496
	2417190372112 -> 2417186240496
	2417190378112 -> 2417186240496
	2417190382672 -> 2417186240496
	2417190379072 -> 2417186240496
	2417190376336 -> 2417186240496
	2417190379408 -> 2417186240496
	2417190385552 -> 2417186240496
	2417186240448 -> 2417186240736
	2417001580736 [label="encoder.features.denseblock4.denselayer19.norm1.weight
 (1216)" fillcolor=lightblue]
	2417001580736 -> 2417186240448
	2417186240448 [label=AccumulateGrad]
	2417186240928 -> 2417186240736
	2417001592816 [label="encoder.features.denseblock4.denselayer19.norm1.bias
 (1216)" fillcolor=lightblue]
	2417001592816 -> 2417186240928
	2417186240928 [label=AccumulateGrad]
	2417186240784 -> 2417186241408
	2417001582816 [label="encoder.features.denseblock4.denselayer19.conv1.weight
 (128, 1216, 1, 1)" fillcolor=lightblue]
	2417001582816 -> 2417186240784
	2417186240784 [label=AccumulateGrad]
	2417186241120 -> 2417186242080
	2417001593936 [label="encoder.features.denseblock4.denselayer19.norm2.weight
 (128)" fillcolor=lightblue]
	2417001593936 -> 2417186241120
	2417186241120 [label=AccumulateGrad]
	2417186241264 -> 2417186242080
	2417001582256 [label="encoder.features.denseblock4.denselayer19.norm2.bias
 (128)" fillcolor=lightblue]
	2417001582256 -> 2417186241264
	2417186241264 [label=AccumulateGrad]
	2417186242224 -> 2417190378352
	2417001583696 [label="encoder.features.denseblock4.denselayer19.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2417001583696 -> 2417186242224
	2417186242224 [label=AccumulateGrad]
	2417190372976 -> 2416913641008
	2417190372976 [label=ConvolutionBackward0]
	2417186241072 -> 2417190372976
	2417186241072 [label=ReluBackward0]
	2417186240880 -> 2417186241072
	2417186240880 [label=CudnnBatchNormBackward0]
	2417186240064 -> 2417186240880
	2417186240064 [label=ConvolutionBackward0]
	2417186240208 -> 2417186240064
	2417186240208 [label=ReluBackward0]
	2417186239632 -> 2417186240208
	2417186239632 [label=CudnnBatchNormBackward0]
	2417186239536 -> 2417186239632
	2417186239536 [label=CatBackward0]
	2416913644080 -> 2417186239536
	2416913644176 -> 2417186239536
	2416913637984 -> 2417186239536
	2416913630160 -> 2417186239536
	2416913643696 -> 2417186239536
	2416913631120 -> 2417186239536
	2417190382864 -> 2417186239536
	2417190374512 -> 2417186239536
	2417190372400 -> 2417186239536
	2417190379360 -> 2417186239536
	2417190383248 -> 2417186239536
	2417190380032 -> 2417186239536
	2417190372112 -> 2417186239536
	2417190378112 -> 2417186239536
	2417190382672 -> 2417186239536
	2417190379072 -> 2417186239536
	2417190376336 -> 2417186239536
	2417190379408 -> 2417186239536
	2417190385552 -> 2417186239536
	2417190378352 -> 2417186239536
	2417186239680 -> 2417186239632
	2417001585776 [label="encoder.features.denseblock4.denselayer20.norm1.weight
 (1248)" fillcolor=lightblue]
	2417001585776 -> 2417186239680
	2417186239680 [label=AccumulateGrad]
	2417186239824 -> 2417186239632
	2417001581296 [label="encoder.features.denseblock4.denselayer20.norm1.bias
 (1248)" fillcolor=lightblue]
	2417001581296 -> 2417186239824
	2417186239824 [label=AccumulateGrad]
	2417186239872 -> 2417186240064
	2417001591536 [label="encoder.features.denseblock4.denselayer20.conv1.weight
 (128, 1248, 1, 1)" fillcolor=lightblue]
	2417001591536 -> 2417186239872
	2417186239872 [label=AccumulateGrad]
	2417186240160 -> 2417186240880
	2417001587056 [label="encoder.features.denseblock4.denselayer20.norm2.weight
 (128)" fillcolor=lightblue]
	2417001587056 -> 2417186240160
	2417186240160 [label=AccumulateGrad]
	2417186240832 -> 2417186240880
	2417001579136 [label="encoder.features.denseblock4.denselayer20.norm2.bias
 (128)" fillcolor=lightblue]
	2417001579136 -> 2417186240832
	2417186240832 [label=AccumulateGrad]
	2417186241312 -> 2417190372976
	2417001587136 [label="encoder.features.denseblock4.denselayer20.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2417001587136 -> 2417186241312
	2417186241312 [label=AccumulateGrad]
	2417190386560 -> 2416913641008
	2417190386560 [label=ConvolutionBackward0]
	2417186240304 -> 2417190386560
	2417186240304 [label=ReluBackward0]
	2417186240112 -> 2417186240304
	2417186240112 [label=CudnnBatchNormBackward0]
	2417186239584 -> 2417186240112
	2417186239584 [label=ConvolutionBackward0]
	2417186238816 -> 2417186239584
	2417186238816 [label=ReluBackward0]
	2417186238864 -> 2417186238816
	2417186238864 [label=CudnnBatchNormBackward0]
	2417186238624 -> 2417186238864
	2417186238624 [label=CatBackward0]
	2416913644080 -> 2417186238624
	2416913644176 -> 2417186238624
	2416913637984 -> 2417186238624
	2416913630160 -> 2417186238624
	2416913643696 -> 2417186238624
	2416913631120 -> 2417186238624
	2417190382864 -> 2417186238624
	2417190374512 -> 2417186238624
	2417190372400 -> 2417186238624
	2417190379360 -> 2417186238624
	2417190383248 -> 2417186238624
	2417190380032 -> 2417186238624
	2417190372112 -> 2417186238624
	2417190378112 -> 2417186238624
	2417190382672 -> 2417186238624
	2417190379072 -> 2417186238624
	2417190376336 -> 2417186238624
	2417190379408 -> 2417186238624
	2417190385552 -> 2417186238624
	2417190378352 -> 2417186238624
	2417190372976 -> 2417186238624
	2417186238576 -> 2417186238864
	2417001583056 [label="encoder.features.denseblock4.denselayer21.norm1.weight
 (1280)" fillcolor=lightblue]
	2417001583056 -> 2417186238576
	2417186238576 [label=AccumulateGrad]
	2417186239056 -> 2417186238864
	2417001591696 [label="encoder.features.denseblock4.denselayer21.norm1.bias
 (1280)" fillcolor=lightblue]
	2417001591696 -> 2417186239056
	2417186239056 [label=AccumulateGrad]
	2417186238912 -> 2417186239584
	2417001591296 [label="encoder.features.denseblock4.denselayer21.conv1.weight
 (128, 1280, 1, 1)" fillcolor=lightblue]
	2417001591296 -> 2417186238912
	2417186238912 [label=AccumulateGrad]
	2417186239248 -> 2417186240112
	2417001589936 [label="encoder.features.denseblock4.denselayer21.norm2.weight
 (128)" fillcolor=lightblue]
	2417001589936 -> 2417186239248
	2417186239248 [label=AccumulateGrad]
	2417186239440 -> 2417186240112
	2417001593136 [label="encoder.features.denseblock4.denselayer21.norm2.bias
 (128)" fillcolor=lightblue]
	2417001593136 -> 2417186239440
	2417186239440 [label=AccumulateGrad]
	2417186240256 -> 2417190386560
	2417001581376 [label="encoder.features.denseblock4.denselayer21.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2417001581376 -> 2417186240256
	2417186240256 [label=AccumulateGrad]
	2417190387088 -> 2416913641008
	2417190387088 [label=ConvolutionBackward0]
	2417186239200 -> 2417190387088
	2417186239200 [label=ReluBackward0]
	2417186239008 -> 2417186239200
	2417186239008 [label=CudnnBatchNormBackward0]
	2417186238192 -> 2417186239008
	2417186238192 [label=ConvolutionBackward0]
	2417186238336 -> 2417186238192
	2417186238336 [label=ReluBackward0]
	2417186237808 -> 2417186238336
	2417186237808 [label=CudnnBatchNormBackward0]
	2417186237712 -> 2417186237808
	2417186237712 [label=CatBackward0]
	2416913644080 -> 2417186237712
	2416913644176 -> 2417186237712
	2416913637984 -> 2417186237712
	2416913630160 -> 2417186237712
	2416913643696 -> 2417186237712
	2416913631120 -> 2417186237712
	2417190382864 -> 2417186237712
	2417190374512 -> 2417186237712
	2417190372400 -> 2417186237712
	2417190379360 -> 2417186237712
	2417190383248 -> 2417186237712
	2417190380032 -> 2417186237712
	2417190372112 -> 2417186237712
	2417190378112 -> 2417186237712
	2417190382672 -> 2417186237712
	2417190379072 -> 2417186237712
	2417190376336 -> 2417186237712
	2417190379408 -> 2417186237712
	2417190385552 -> 2417186237712
	2417190378352 -> 2417186237712
	2417190372976 -> 2417186237712
	2417190386560 -> 2417186237712
	2417186237856 -> 2417186237808
	2417001583616 [label="encoder.features.denseblock4.denselayer22.norm1.weight
 (1312)" fillcolor=lightblue]
	2417001583616 -> 2417186237856
	2417186237856 [label=AccumulateGrad]
	2417186238000 -> 2417186237808
	2417001593856 [label="encoder.features.denseblock4.denselayer22.norm1.bias
 (1312)" fillcolor=lightblue]
	2417001593856 -> 2417186238000
	2417186238000 [label=AccumulateGrad]
	2417186238048 -> 2417186238192
	2417001539984 [label="encoder.features.denseblock4.denselayer22.conv1.weight
 (128, 1312, 1, 1)" fillcolor=lightblue]
	2417001539984 -> 2417186238048
	2417186238048 [label=AccumulateGrad]
	2417186238288 -> 2417186239008
	2417001543984 [label="encoder.features.denseblock4.denselayer22.norm2.weight
 (128)" fillcolor=lightblue]
	2417001543984 -> 2417186238288
	2417186238288 [label=AccumulateGrad]
	2417186238960 -> 2417186239008
	2417001543264 [label="encoder.features.denseblock4.denselayer22.norm2.bias
 (128)" fillcolor=lightblue]
	2417001543264 -> 2417186238960
	2417186238960 [label=AccumulateGrad]
	2417186239488 -> 2417190387088
	2417001537344 [label="encoder.features.denseblock4.denselayer22.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2417001537344 -> 2417186239488
	2417186239488 [label=AccumulateGrad]
	2417190374656 -> 2416913641008
	2417190374656 [label=ConvolutionBackward0]
	2417186238432 -> 2417190374656
	2417186238432 [label=ReluBackward0]
	2417186238240 -> 2417186238432
	2417186238240 [label=CudnnBatchNormBackward0]
	2417186237760 -> 2417186238240
	2417186237760 [label=ConvolutionBackward0]
	2417186237136 -> 2417186237760
	2417186237136 [label=ReluBackward0]
	2417186237184 -> 2417186237136
	2417186237184 [label=CudnnBatchNormBackward0]
	2417186236800 -> 2417186237184
	2417186236800 [label=CatBackward0]
	2416913644080 -> 2417186236800
	2416913644176 -> 2417186236800
	2416913637984 -> 2417186236800
	2416913630160 -> 2417186236800
	2416913643696 -> 2417186236800
	2416913631120 -> 2417186236800
	2417190382864 -> 2417186236800
	2417190374512 -> 2417186236800
	2417190372400 -> 2417186236800
	2417190379360 -> 2417186236800
	2417190383248 -> 2417186236800
	2417190380032 -> 2417186236800
	2417190372112 -> 2417186236800
	2417190378112 -> 2417186236800
	2417190382672 -> 2417186236800
	2417190379072 -> 2417186236800
	2417190376336 -> 2417186236800
	2417190379408 -> 2417186236800
	2417190385552 -> 2417186236800
	2417190378352 -> 2417186236800
	2417190372976 -> 2417186236800
	2417190386560 -> 2417186236800
	2417190387088 -> 2417186236800
	2417186236608 -> 2417186237184
	2417001537024 [label="encoder.features.denseblock4.denselayer23.norm1.weight
 (1344)" fillcolor=lightblue]
	2417001537024 -> 2417186236608
	2417186236608 [label=AccumulateGrad]
	2417186237088 -> 2417186237184
	2417001539904 [label="encoder.features.denseblock4.denselayer23.norm1.bias
 (1344)" fillcolor=lightblue]
	2417001539904 -> 2417186237088
	2417186237088 [label=AccumulateGrad]
	2417186237280 -> 2417186237760
	2417001539264 [label="encoder.features.denseblock4.denselayer23.conv1.weight
 (128, 1344, 1, 1)" fillcolor=lightblue]
	2417001539264 -> 2417186237280
	2417186237280 [label=AccumulateGrad]
	2417186237424 -> 2417186238240
	2417001538704 [label="encoder.features.denseblock4.denselayer23.norm2.weight
 (128)" fillcolor=lightblue]
	2417001538704 -> 2417186237424
	2417186237424 [label=AccumulateGrad]
	2417186237616 -> 2417186238240
	2417001537504 [label="encoder.features.denseblock4.denselayer23.norm2.bias
 (128)" fillcolor=lightblue]
	2417001537504 -> 2417186237616
	2417186237616 [label=AccumulateGrad]
	2417186238384 -> 2417190374656
	2417001540784 [label="encoder.features.denseblock4.denselayer23.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2417001540784 -> 2417186238384
	2417186238384 [label=AccumulateGrad]
	2417190372592 -> 2416913641008
	2417190372592 [label=ConvolutionBackward0]
	2417186237232 -> 2417190372592
	2417186237232 [label=ReluBackward0]
	2417186237040 -> 2417186237232
	2417186237040 [label=CudnnBatchNormBackward0]
	2417186236512 -> 2417186237040
	2417186236512 [label=ConvolutionBackward0]
	2417186236272 -> 2417186236512
	2417186236272 [label=ReluBackward0]
	2417186235840 -> 2417186236272
	2417186235840 [label=CudnnBatchNormBackward0]
	2417186236080 -> 2417186235840
	2417186236080 [label=CatBackward0]
	2416913644080 -> 2417186236080
	2416913644176 -> 2417186236080
	2416913637984 -> 2417186236080
	2416913630160 -> 2417186236080
	2416913643696 -> 2417186236080
	2416913631120 -> 2417186236080
	2417190382864 -> 2417186236080
	2417190374512 -> 2417186236080
	2417190372400 -> 2417186236080
	2417190379360 -> 2417186236080
	2417190383248 -> 2417186236080
	2417190380032 -> 2417186236080
	2417190372112 -> 2417186236080
	2417190378112 -> 2417186236080
	2417190382672 -> 2417186236080
	2417190379072 -> 2417186236080
	2417190376336 -> 2417186236080
	2417190379408 -> 2417186236080
	2417190385552 -> 2417186236080
	2417190378352 -> 2417186236080
	2417190372976 -> 2417186236080
	2417190386560 -> 2417186236080
	2417190387088 -> 2417186236080
	2417190374656 -> 2417186236080
	2417186235888 -> 2417186235840
	2417001541344 [label="encoder.features.denseblock4.denselayer24.norm1.weight
 (1376)" fillcolor=lightblue]
	2417001541344 -> 2417186235888
	2417186235888 [label=AccumulateGrad]
	2417186236032 -> 2417186235840
	2417001537184 [label="encoder.features.denseblock4.denselayer24.norm1.bias
 (1376)" fillcolor=lightblue]
	2417001537184 -> 2417186236032
	2417186236032 [label=AccumulateGrad]
	2417186236224 -> 2417186236512
	2417001541904 [label="encoder.features.denseblock4.denselayer24.conv1.weight
 (128, 1376, 1, 1)" fillcolor=lightblue]
	2417001541904 -> 2417186236224
	2417186236224 [label=AccumulateGrad]
	2417186236656 -> 2417186237040
	2417001545504 [label="encoder.features.denseblock4.denselayer24.norm2.weight
 (128)" fillcolor=lightblue]
	2417001545504 -> 2417186236656
	2417186236656 [label=AccumulateGrad]
	2417186236848 -> 2417186237040
	2417001539504 [label="encoder.features.denseblock4.denselayer24.norm2.bias
 (128)" fillcolor=lightblue]
	2417001539504 -> 2417186236848
	2417186236848 [label=AccumulateGrad]
	2417186237664 -> 2417190372592
	2417001538224 [label="encoder.features.denseblock4.denselayer24.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2417001538224 -> 2417186237664
	2417186237664 [label=AccumulateGrad]
	2417190382000 -> 2416913641008
	2417190382000 [label=ConvolutionBackward0]
	2417186236464 -> 2417190382000
	2417186236464 [label=ReluBackward0]
	2417186236560 -> 2417186236464
	2417186236560 [label=CudnnBatchNormBackward0]
	2417186235648 -> 2417186236560
	2417186235648 [label=ConvolutionBackward0]
	2417186235312 -> 2417186235648
	2417186235312 [label=ReluBackward0]
	2417186235360 -> 2417186235312
	2417186235360 [label=CudnnBatchNormBackward0]
	2417186234976 -> 2417186235360
	2417186234976 [label=CatBackward0]
	2416913644080 -> 2417186234976
	2416913644176 -> 2417186234976
	2416913637984 -> 2417186234976
	2416913630160 -> 2417186234976
	2416913643696 -> 2417186234976
	2416913631120 -> 2417186234976
	2417190382864 -> 2417186234976
	2417190374512 -> 2417186234976
	2417190372400 -> 2417186234976
	2417190379360 -> 2417186234976
	2417190383248 -> 2417186234976
	2417190380032 -> 2417186234976
	2417190372112 -> 2417186234976
	2417190378112 -> 2417186234976
	2417190382672 -> 2417186234976
	2417190379072 -> 2417186234976
	2417190376336 -> 2417186234976
	2417190379408 -> 2417186234976
	2417190385552 -> 2417186234976
	2417190378352 -> 2417186234976
	2417190372976 -> 2417186234976
	2417190386560 -> 2417186234976
	2417190387088 -> 2417186234976
	2417190374656 -> 2417186234976
	2417190372592 -> 2417186234976
	2417186234784 -> 2417186235360
	2417001537824 [label="encoder.features.denseblock4.denselayer25.norm1.weight
 (1408)" fillcolor=lightblue]
	2417001537824 -> 2417186234784
	2417186234784 [label=AccumulateGrad]
	2417186235264 -> 2417186235360
	2417001537984 [label="encoder.features.denseblock4.denselayer25.norm1.bias
 (1408)" fillcolor=lightblue]
	2417001537984 -> 2417186235264
	2417186235264 [label=AccumulateGrad]
	2417186235456 -> 2417186235648
	2417001542384 [label="encoder.features.denseblock4.denselayer25.conv1.weight
 (128, 1408, 1, 1)" fillcolor=lightblue]
	2417001542384 -> 2417186235456
	2417186235456 [label=AccumulateGrad]
	2417186235600 -> 2417186236560
	2417001543664 [label="encoder.features.denseblock4.denselayer25.norm2.weight
 (128)" fillcolor=lightblue]
	2417001543664 -> 2417186235600
	2417186235600 [label=AccumulateGrad]
	2417186235936 -> 2417186236560
	2417001540064 [label="encoder.features.denseblock4.denselayer25.norm2.bias
 (128)" fillcolor=lightblue]
	2417001540064 -> 2417186235936
	2417186235936 [label=AccumulateGrad]
	2417186236416 -> 2417190382000
	2417001538784 [label="encoder.features.denseblock4.denselayer25.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2417001538784 -> 2417186236416
	2417186236416 [label=AccumulateGrad]
	2417190375664 -> 2416913641008
	2417190375664 [label=ConvolutionBackward0]
	2417186235408 -> 2417190375664
	2417186235408 [label=ReluBackward0]
	2417186235216 -> 2417186235408
	2417186235216 [label=CudnnBatchNormBackward0]
	2417186234688 -> 2417186235216
	2417186234688 [label=ConvolutionBackward0]
	2417186234400 -> 2417186234688
	2417186234400 [label=ReluBackward0]
	2417186233968 -> 2417186234400
	2417186233968 [label=CudnnBatchNormBackward0]
	2417186234208 -> 2417186233968
	2417186234208 [label=CatBackward0]
	2416913644080 -> 2417186234208
	2416913644176 -> 2417186234208
	2416913637984 -> 2417186234208
	2416913630160 -> 2417186234208
	2416913643696 -> 2417186234208
	2416913631120 -> 2417186234208
	2417190382864 -> 2417186234208
	2417190374512 -> 2417186234208
	2417190372400 -> 2417186234208
	2417190379360 -> 2417186234208
	2417190383248 -> 2417186234208
	2417190380032 -> 2417186234208
	2417190372112 -> 2417186234208
	2417190378112 -> 2417186234208
	2417190382672 -> 2417186234208
	2417190379072 -> 2417186234208
	2417190376336 -> 2417186234208
	2417190379408 -> 2417186234208
	2417190385552 -> 2417186234208
	2417190378352 -> 2417186234208
	2417190372976 -> 2417186234208
	2417190386560 -> 2417186234208
	2417190387088 -> 2417186234208
	2417190374656 -> 2417186234208
	2417190372592 -> 2417186234208
	2417190382000 -> 2417186234208
	2417186234016 -> 2417186233968
	2417001540384 [label="encoder.features.denseblock4.denselayer26.norm1.weight
 (1440)" fillcolor=lightblue]
	2417001540384 -> 2417186234016
	2417186234016 [label=AccumulateGrad]
	2417186234160 -> 2417186233968
	2417001540944 [label="encoder.features.denseblock4.denselayer26.norm1.bias
 (1440)" fillcolor=lightblue]
	2417001540944 -> 2417186234160
	2417186234160 [label=AccumulateGrad]
	2417186234352 -> 2417186234688
	2417001538864 [label="encoder.features.denseblock4.denselayer26.conv1.weight
 (128, 1440, 1, 1)" fillcolor=lightblue]
	2417001538864 -> 2417186234352
	2417186234352 [label=AccumulateGrad]
	2417186234832 -> 2417186235216
	2417001536944 [label="encoder.features.denseblock4.denselayer26.norm2.weight
 (128)" fillcolor=lightblue]
	2417001536944 -> 2417186234832
	2417186234832 [label=AccumulateGrad]
	2417186235024 -> 2417186235216
	2417001545184 [label="encoder.features.denseblock4.denselayer26.norm2.bias
 (128)" fillcolor=lightblue]
	2417001545184 -> 2417186235024
	2417186235024 [label=AccumulateGrad]
	2417186235984 -> 2417190375664
	2417001538624 [label="encoder.features.denseblock4.denselayer26.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2417001538624 -> 2417186235984
	2417186235984 [label=AccumulateGrad]
	2417190387520 -> 2416913641008
	2417190387520 [label=ConvolutionBackward0]
	2417186234640 -> 2417190387520
	2417186234640 [label=ReluBackward0]
	2417186234736 -> 2417186234640
	2417186234736 [label=CudnnBatchNormBackward0]
	2417186233776 -> 2417186234736
	2417186233776 [label=ConvolutionBackward0]
	2417186233440 -> 2417186233776
	2417186233440 [label=ReluBackward0]
	2417186233488 -> 2417186233440
	2417186233488 [label=CudnnBatchNormBackward0]
	2417186233104 -> 2417186233488
	2417186233104 [label=CatBackward0]
	2416913644080 -> 2417186233104
	2416913644176 -> 2417186233104
	2416913637984 -> 2417186233104
	2416913630160 -> 2417186233104
	2416913643696 -> 2417186233104
	2416913631120 -> 2417186233104
	2417190382864 -> 2417186233104
	2417190374512 -> 2417186233104
	2417190372400 -> 2417186233104
	2417190379360 -> 2417186233104
	2417190383248 -> 2417186233104
	2417190380032 -> 2417186233104
	2417190372112 -> 2417186233104
	2417190378112 -> 2417186233104
	2417190382672 -> 2417186233104
	2417190379072 -> 2417186233104
	2417190376336 -> 2417186233104
	2417190379408 -> 2417186233104
	2417190385552 -> 2417186233104
	2417190378352 -> 2417186233104
	2417190372976 -> 2417186233104
	2417190386560 -> 2417186233104
	2417190387088 -> 2417186233104
	2417190374656 -> 2417186233104
	2417190372592 -> 2417186233104
	2417190382000 -> 2417186233104
	2417190375664 -> 2417186233104
	2417186232912 -> 2417186233488
	2417001537104 [label="encoder.features.denseblock4.denselayer27.norm1.weight
 (1472)" fillcolor=lightblue]
	2417001537104 -> 2417186232912
	2417186232912 [label=AccumulateGrad]
	2417186233392 -> 2417186233488
	2417001532384 [label="encoder.features.denseblock4.denselayer27.norm1.bias
 (1472)" fillcolor=lightblue]
	2417001532384 -> 2417186233392
	2417186233392 [label=AccumulateGrad]
	2417186233584 -> 2417186233776
	2417001543424 [label="encoder.features.denseblock4.denselayer27.conv1.weight
 (128, 1472, 1, 1)" fillcolor=lightblue]
	2417001543424 -> 2417186233584
	2417186233584 [label=AccumulateGrad]
	2417186233728 -> 2417186234736
	2417001544624 [label="encoder.features.denseblock4.denselayer27.norm2.weight
 (128)" fillcolor=lightblue]
	2417001544624 -> 2417186233728
	2417186233728 [label=AccumulateGrad]
	2417186234064 -> 2417186234736
	2417001542464 [label="encoder.features.denseblock4.denselayer27.norm2.bias
 (128)" fillcolor=lightblue]
	2417001542464 -> 2417186234064
	2417186234064 [label=AccumulateGrad]
	2417186234592 -> 2417190387520
	2417001540704 [label="encoder.features.denseblock4.denselayer27.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2417001540704 -> 2417186234592
	2417186234592 [label=AccumulateGrad]
	2417190375088 -> 2416913641008
	2417190375088 [label=ConvolutionBackward0]
	2417186233536 -> 2417190375088
	2417186233536 [label=ReluBackward0]
	2417186233344 -> 2417186233536
	2417186233344 [label=CudnnBatchNormBackward0]
	2417186232816 -> 2417186233344
	2417186232816 [label=ConvolutionBackward0]
	2417186232528 -> 2417186232816
	2417186232528 [label=ReluBackward0]
	2417186232096 -> 2417186232528
	2417186232096 [label=CudnnBatchNormBackward0]
	2417186232336 -> 2417186232096
	2417186232336 [label=CatBackward0]
	2416913644080 -> 2417186232336
	2416913644176 -> 2417186232336
	2416913637984 -> 2417186232336
	2416913630160 -> 2417186232336
	2416913643696 -> 2417186232336
	2416913631120 -> 2417186232336
	2417190382864 -> 2417186232336
	2417190374512 -> 2417186232336
	2417190372400 -> 2417186232336
	2417190379360 -> 2417186232336
	2417190383248 -> 2417186232336
	2417190380032 -> 2417186232336
	2417190372112 -> 2417186232336
	2417190378112 -> 2417186232336
	2417190382672 -> 2417186232336
	2417190379072 -> 2417186232336
	2417190376336 -> 2417186232336
	2417190379408 -> 2417186232336
	2417190385552 -> 2417186232336
	2417190378352 -> 2417186232336
	2417190372976 -> 2417186232336
	2417190386560 -> 2417186232336
	2417190387088 -> 2417186232336
	2417190374656 -> 2417186232336
	2417190372592 -> 2417186232336
	2417190382000 -> 2417186232336
	2417190375664 -> 2417186232336
	2417190387520 -> 2417186232336
	2417186232144 -> 2417186232096
	2417001543104 [label="encoder.features.denseblock4.denselayer28.norm1.weight
 (1504)" fillcolor=lightblue]
	2417001543104 -> 2417186232144
	2417186232144 [label=AccumulateGrad]
	2417186232288 -> 2417186232096
	2417001539184 [label="encoder.features.denseblock4.denselayer28.norm1.bias
 (1504)" fillcolor=lightblue]
	2417001539184 -> 2417186232288
	2417186232288 [label=AccumulateGrad]
	2417186232480 -> 2417186232816
	2417001537744 [label="encoder.features.denseblock4.denselayer28.conv1.weight
 (128, 1504, 1, 1)" fillcolor=lightblue]
	2417001537744 -> 2417186232480
	2417186232480 [label=AccumulateGrad]
	2417186232960 -> 2417186233344
	2417001539824 [label="encoder.features.denseblock4.denselayer28.norm2.weight
 (128)" fillcolor=lightblue]
	2417001539824 -> 2417186232960
	2417186232960 [label=AccumulateGrad]
	2417186233152 -> 2417186233344
	2417001545024 [label="encoder.features.denseblock4.denselayer28.norm2.bias
 (128)" fillcolor=lightblue]
	2417001545024 -> 2417186233152
	2417186233152 [label=AccumulateGrad]
	2417186234112 -> 2417190375088
	2417001543184 [label="encoder.features.denseblock4.denselayer28.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2417001543184 -> 2417186234112
	2417186234112 [label=AccumulateGrad]
	2417190383872 -> 2416913641008
	2417190383872 [label=ConvolutionBackward0]
	2417186232768 -> 2417190383872
	2417186232768 [label=ReluBackward0]
	2417186232864 -> 2417186232768
	2417186232864 [label=CudnnBatchNormBackward0]
	2417186231904 -> 2417186232864
	2417186231904 [label=ConvolutionBackward0]
	2417186231568 -> 2417186231904
	2417186231568 [label=ReluBackward0]
	2417186231616 -> 2417186231568
	2417186231616 [label=CudnnBatchNormBackward0]
	2417186231232 -> 2417186231616
	2417186231232 [label=CatBackward0]
	2416913644080 -> 2417186231232
	2416913644176 -> 2417186231232
	2416913637984 -> 2417186231232
	2416913630160 -> 2417186231232
	2416913643696 -> 2417186231232
	2416913631120 -> 2417186231232
	2417190382864 -> 2417186231232
	2417190374512 -> 2417186231232
	2417190372400 -> 2417186231232
	2417190379360 -> 2417186231232
	2417190383248 -> 2417186231232
	2417190380032 -> 2417186231232
	2417190372112 -> 2417186231232
	2417190378112 -> 2417186231232
	2417190382672 -> 2417186231232
	2417190379072 -> 2417186231232
	2417190376336 -> 2417186231232
	2417190379408 -> 2417186231232
	2417190385552 -> 2417186231232
	2417190378352 -> 2417186231232
	2417190372976 -> 2417186231232
	2417190386560 -> 2417186231232
	2417190387088 -> 2417186231232
	2417190374656 -> 2417186231232
	2417190372592 -> 2417186231232
	2417190382000 -> 2417186231232
	2417190375664 -> 2417186231232
	2417190387520 -> 2417186231232
	2417190375088 -> 2417186231232
	2417186231040 -> 2417186231616
	2417001539744 [label="encoder.features.denseblock4.denselayer29.norm1.weight
 (1536)" fillcolor=lightblue]
	2417001539744 -> 2417186231040
	2417186231040 [label=AccumulateGrad]
	2417186231520 -> 2417186231616
	2417001538944 [label="encoder.features.denseblock4.denselayer29.norm1.bias
 (1536)" fillcolor=lightblue]
	2417001538944 -> 2417186231520
	2417186231520 [label=AccumulateGrad]
	2417186231712 -> 2417186231904
	2417001538464 [label="encoder.features.denseblock4.denselayer29.conv1.weight
 (128, 1536, 1, 1)" fillcolor=lightblue]
	2417001538464 -> 2417186231712
	2417186231712 [label=AccumulateGrad]
	2417186231856 -> 2417186232864
	2417001539104 [label="encoder.features.denseblock4.denselayer29.norm2.weight
 (128)" fillcolor=lightblue]
	2417001539104 -> 2417186231856
	2417186231856 [label=AccumulateGrad]
	2417186232192 -> 2417186232864
	2417001487952 [label="encoder.features.denseblock4.denselayer29.norm2.bias
 (128)" fillcolor=lightblue]
	2417001487952 -> 2417186232192
	2417186232192 [label=AccumulateGrad]
	2417186232720 -> 2417190383872
	2417185816272 [label="encoder.features.denseblock4.denselayer29.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2417185816272 -> 2417186232720
	2417186232720 [label=AccumulateGrad]
	2417190381520 -> 2416913641008
	2417190381520 [label=ConvolutionBackward0]
	2417186231664 -> 2417190381520
	2417186231664 [label=ReluBackward0]
	2417186231472 -> 2417186231664
	2417186231472 [label=CudnnBatchNormBackward0]
	2417186230944 -> 2417186231472
	2417186230944 [label=ConvolutionBackward0]
	2417186230656 -> 2417186230944
	2417186230656 [label=ReluBackward0]
	2417186230224 -> 2417186230656
	2417186230224 [label=CudnnBatchNormBackward0]
	2417186230464 -> 2417186230224
	2417186230464 [label=CatBackward0]
	2416913644080 -> 2417186230464
	2416913644176 -> 2417186230464
	2416913637984 -> 2417186230464
	2416913630160 -> 2417186230464
	2416913643696 -> 2417186230464
	2416913631120 -> 2417186230464
	2417190382864 -> 2417186230464
	2417190374512 -> 2417186230464
	2417190372400 -> 2417186230464
	2417190379360 -> 2417186230464
	2417190383248 -> 2417186230464
	2417190380032 -> 2417186230464
	2417190372112 -> 2417186230464
	2417190378112 -> 2417186230464
	2417190382672 -> 2417186230464
	2417190379072 -> 2417186230464
	2417190376336 -> 2417186230464
	2417190379408 -> 2417186230464
	2417190385552 -> 2417186230464
	2417190378352 -> 2417186230464
	2417190372976 -> 2417186230464
	2417190386560 -> 2417186230464
	2417190387088 -> 2417186230464
	2417190374656 -> 2417186230464
	2417190372592 -> 2417186230464
	2417190382000 -> 2417186230464
	2417190375664 -> 2417186230464
	2417190387520 -> 2417186230464
	2417190375088 -> 2417186230464
	2417190383872 -> 2417186230464
	2417186230272 -> 2417186230224
	2417185816032 [label="encoder.features.denseblock4.denselayer30.norm1.weight
 (1568)" fillcolor=lightblue]
	2417185816032 -> 2417186230272
	2417186230272 [label=AccumulateGrad]
	2417186230416 -> 2417186230224
	2417185815952 [label="encoder.features.denseblock4.denselayer30.norm1.bias
 (1568)" fillcolor=lightblue]
	2417185815952 -> 2417186230416
	2417186230416 [label=AccumulateGrad]
	2417186230608 -> 2417186230944
	2417185800592 [label="encoder.features.denseblock4.denselayer30.conv1.weight
 (128, 1568, 1, 1)" fillcolor=lightblue]
	2417185800592 -> 2417186230608
	2417186230608 [label=AccumulateGrad]
	2417186231088 -> 2417186231472
	2417185801472 [label="encoder.features.denseblock4.denselayer30.norm2.weight
 (128)" fillcolor=lightblue]
	2417185801472 -> 2417186231088
	2417186231088 [label=AccumulateGrad]
	2417186231280 -> 2417186231472
	2417185801312 [label="encoder.features.denseblock4.denselayer30.norm2.bias
 (128)" fillcolor=lightblue]
	2417185801312 -> 2417186231280
	2417186231280 [label=AccumulateGrad]
	2417186232240 -> 2417190381520
	2417185801712 [label="encoder.features.denseblock4.denselayer30.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2417185801712 -> 2417186232240
	2417186232240 [label=AccumulateGrad]
	2417190380560 -> 2416913641008
	2417190380560 [label=ConvolutionBackward0]
	2417186230896 -> 2417190380560
	2417186230896 [label=ReluBackward0]
	2417186230992 -> 2417186230896
	2417186230992 [label=CudnnBatchNormBackward0]
	2417186230032 -> 2417186230992
	2417186230032 [label=ConvolutionBackward0]
	2417186229696 -> 2417186230032
	2417186229696 [label=ReluBackward0]
	2417186229744 -> 2417186229696
	2417186229744 [label=CudnnBatchNormBackward0]
	2417186229216 -> 2417186229744
	2417186229216 [label=CatBackward0]
	2416913644080 -> 2417186229216
	2416913644176 -> 2417186229216
	2416913637984 -> 2417186229216
	2416913630160 -> 2417186229216
	2416913643696 -> 2417186229216
	2416913631120 -> 2417186229216
	2417190382864 -> 2417186229216
	2417190374512 -> 2417186229216
	2417190372400 -> 2417186229216
	2417190379360 -> 2417186229216
	2417190383248 -> 2417186229216
	2417190380032 -> 2417186229216
	2417190372112 -> 2417186229216
	2417190378112 -> 2417186229216
	2417190382672 -> 2417186229216
	2417190379072 -> 2417186229216
	2417190376336 -> 2417186229216
	2417190379408 -> 2417186229216
	2417190385552 -> 2417186229216
	2417190378352 -> 2417186229216
	2417190372976 -> 2417186229216
	2417190386560 -> 2417186229216
	2417190387088 -> 2417186229216
	2417190374656 -> 2417186229216
	2417190372592 -> 2417186229216
	2417190382000 -> 2417186229216
	2417190375664 -> 2417186229216
	2417190387520 -> 2417186229216
	2417190375088 -> 2417186229216
	2417190383872 -> 2417186229216
	2417190381520 -> 2417186229216
	2417186229024 -> 2417186229744
	2417185801552 [label="encoder.features.denseblock4.denselayer31.norm1.weight
 (1600)" fillcolor=lightblue]
	2417185801552 -> 2417186229024
	2417186229024 [label=AccumulateGrad]
	2417186229648 -> 2417186229744
	2417185801952 [label="encoder.features.denseblock4.denselayer31.norm1.bias
 (1600)" fillcolor=lightblue]
	2417185801952 -> 2417186229648
	2417186229648 [label=AccumulateGrad]
	2417186229840 -> 2417186230032
	2417185803552 [label="encoder.features.denseblock4.denselayer31.conv1.weight
 (128, 1600, 1, 1)" fillcolor=lightblue]
	2417185803552 -> 2417186229840
	2417186229840 [label=AccumulateGrad]
	2417186229984 -> 2417186230992
	2417185803472 [label="encoder.features.denseblock4.denselayer31.norm2.weight
 (128)" fillcolor=lightblue]
	2417185803472 -> 2417186229984
	2417186229984 [label=AccumulateGrad]
	2417186230320 -> 2417186230992
	2417185803072 [label="encoder.features.denseblock4.denselayer31.norm2.bias
 (128)" fillcolor=lightblue]
	2417185803072 -> 2417186230320
	2417186230320 [label=AccumulateGrad]
	2417186230848 -> 2417190380560
	2417185803712 [label="encoder.features.denseblock4.denselayer31.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2417185803712 -> 2417186230848
	2417186230848 [label=AccumulateGrad]
	2417190379024 -> 2416913641008
	2417190379024 [label=ConvolutionBackward0]
	2417186229792 -> 2417190379024
	2417186229792 [label=ReluBackward0]
	2417186229600 -> 2417186229792
	2417186229600 [label=CudnnBatchNormBackward0]
	2417186229264 -> 2417186229600
	2417186229264 [label=ConvolutionBackward0]
	2417186228784 -> 2417186229264
	2417186228784 [label=ReluBackward0]
	2417186228496 -> 2417186228784
	2417186228496 [label=CudnnBatchNormBackward0]
	2417186228448 -> 2417186228496
	2417186228448 [label=CatBackward0]
	2416913644080 -> 2417186228448
	2416913644176 -> 2417186228448
	2416913637984 -> 2417186228448
	2416913630160 -> 2417186228448
	2416913643696 -> 2417186228448
	2416913631120 -> 2417186228448
	2417190382864 -> 2417186228448
	2417190374512 -> 2417186228448
	2417190372400 -> 2417186228448
	2417190379360 -> 2417186228448
	2417190383248 -> 2417186228448
	2417190380032 -> 2417186228448
	2417190372112 -> 2417186228448
	2417190378112 -> 2417186228448
	2417190382672 -> 2417186228448
	2417190379072 -> 2417186228448
	2417190376336 -> 2417186228448
	2417190379408 -> 2417186228448
	2417190385552 -> 2417186228448
	2417190378352 -> 2417186228448
	2417190372976 -> 2417186228448
	2417190386560 -> 2417186228448
	2417190387088 -> 2417186228448
	2417190374656 -> 2417186228448
	2417190372592 -> 2417186228448
	2417190382000 -> 2417186228448
	2417190375664 -> 2417186228448
	2417190387520 -> 2417186228448
	2417190375088 -> 2417186228448
	2417190383872 -> 2417186228448
	2417190381520 -> 2417186228448
	2417190380560 -> 2417186228448
	2417186228544 -> 2417186228496
	2417185803952 [label="encoder.features.denseblock4.denselayer32.norm1.weight
 (1632)" fillcolor=lightblue]
	2417185803952 -> 2417186228544
	2417186228544 [label=AccumulateGrad]
	2417186228400 -> 2417186228496
	2417185804912 [label="encoder.features.denseblock4.denselayer32.norm1.bias
 (1632)" fillcolor=lightblue]
	2417185804912 -> 2417186228400
	2417186228400 [label=AccumulateGrad]
	2417186228592 -> 2417186229264
	2417185805552 [label="encoder.features.denseblock4.denselayer32.conv1.weight
 (128, 1632, 1, 1)" fillcolor=lightblue]
	2417185805552 -> 2417186228592
	2417186228592 [label=AccumulateGrad]
	2417186229072 -> 2417186229600
	2417185805392 [label="encoder.features.denseblock4.denselayer32.norm2.weight
 (128)" fillcolor=lightblue]
	2417185805392 -> 2417186229072
	2417186229072 [label=AccumulateGrad]
	2417186229408 -> 2417186229600
	2417185805152 [label="encoder.features.denseblock4.denselayer32.norm2.bias
 (128)" fillcolor=lightblue]
	2417185805152 -> 2417186229408
	2417186229408 [label=AccumulateGrad]
	2417186230368 -> 2417190379024
	2417185805632 [label="encoder.features.denseblock4.denselayer32.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2417185805632 -> 2417186230368
	2417186230368 [label=AccumulateGrad]
	2416913633040 -> 2416913631504
	2417185805792 [label="encoder.features.norm5.weight
 (1664)" fillcolor=lightblue]
	2417185805792 -> 2416913633040
	2416913633040 [label=AccumulateGrad]
	2416913645184 -> 2416913631504
	2417185806032 [label="encoder.features.norm5.bias
 (1664)" fillcolor=lightblue]
	2417185806032 -> 2416913645184
	2416913645184 [label=AccumulateGrad]
	2416913642640 -> 2416913635680
	2416913634768 -> 2416913643168
	2417192386416 [label="decoder.blocks.0.conv1.0.weight
 (256, 2944, 3, 3)" fillcolor=lightblue]
	2417192386416 -> 2416913634768
	2416913634768 [label=AccumulateGrad]
	2416913640288 -> 2416913633808
	2417192386336 [label="decoder.blocks.0.conv1.1.weight
 (256)" fillcolor=lightblue]
	2417192386336 -> 2416913640288
	2416913640288 [label=AccumulateGrad]
	2416913640432 -> 2416913633808
	2417192386256 [label="decoder.blocks.0.conv1.1.bias
 (256)" fillcolor=lightblue]
	2417192386256 -> 2416913640432
	2416913640432 [label=AccumulateGrad]
	2416913629248 -> 2416913632368
	2417192385776 [label="decoder.blocks.0.conv2.0.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2417192385776 -> 2416913629248
	2416913629248 [label=AccumulateGrad]
	2416913630880 -> 2416913641488
	2417192385696 [label="decoder.blocks.0.conv2.1.weight
 (256)" fillcolor=lightblue]
	2417192385696 -> 2416913630880
	2416913630880 [label=AccumulateGrad]
	2416913640000 -> 2416913641488
	2417192385616 [label="decoder.blocks.0.conv2.1.bias
 (256)" fillcolor=lightblue]
	2417192385616 -> 2416913640000
	2416913640000 [label=AccumulateGrad]
	2416913636784 -> 2416913644896
	2416913642256 -> 2416913629584
	2417192385136 [label="decoder.blocks.1.conv1.0.weight
 (128, 768, 3, 3)" fillcolor=lightblue]
	2417192385136 -> 2416913642256
	2416913642256 [label=AccumulateGrad]
	2416913631360 -> 2416913645040
	2417192385056 [label="decoder.blocks.1.conv1.1.weight
 (128)" fillcolor=lightblue]
	2417192385056 -> 2416913631360
	2416913631360 [label=AccumulateGrad]
	2416913639232 -> 2416913645040
	2417192384976 [label="decoder.blocks.1.conv1.1.bias
 (128)" fillcolor=lightblue]
	2417192384976 -> 2416913639232
	2416913639232 [label=AccumulateGrad]
	2416913631984 -> 2416913638704
	2417192384496 [label="decoder.blocks.1.conv2.0.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2417192384496 -> 2416913631984
	2416913631984 [label=AccumulateGrad]
	2416913642400 -> 2416913635824
	2417192384416 [label="decoder.blocks.1.conv2.1.weight
 (128)" fillcolor=lightblue]
	2417192384416 -> 2416913642400
	2416913642400 [label=AccumulateGrad]
	2416913636928 -> 2416913635824
	2417192384336 [label="decoder.blocks.1.conv2.1.bias
 (128)" fillcolor=lightblue]
	2417192384336 -> 2416913636928
	2416913636928 [label=AccumulateGrad]
	2416913638080 -> 2416913638560
	2416913636304 -> 2416913642736
	2417192383936 [label="decoder.blocks.2.conv1.0.weight
 (64, 384, 3, 3)" fillcolor=lightblue]
	2417192383936 -> 2416913636304
	2416913636304 [label=AccumulateGrad]
	2416913638320 -> 2416913633712
	2417192383856 [label="decoder.blocks.2.conv1.1.weight
 (64)" fillcolor=lightblue]
	2417192383856 -> 2416913638320
	2416913638320 [label=AccumulateGrad]
	2416913634000 -> 2416913633712
	2417192383776 [label="decoder.blocks.2.conv1.1.bias
 (64)" fillcolor=lightblue]
	2417192383776 -> 2416913634000
	2416913634000 [label=AccumulateGrad]
	2416913640768 -> 2416913632272
	2417192383296 [label="decoder.blocks.2.conv2.0.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2417192383296 -> 2416913640768
	2416913640768 [label=AccumulateGrad]
	2416913631552 -> 2416913637648
	2417192383216 [label="decoder.blocks.2.conv2.1.weight
 (64)" fillcolor=lightblue]
	2417192383216 -> 2416913631552
	2416913631552 [label=AccumulateGrad]
	2416913635248 -> 2416913637648
	2417192383136 [label="decoder.blocks.2.conv2.1.bias
 (64)" fillcolor=lightblue]
	2417192383136 -> 2416913635248
	2416913635248 [label=AccumulateGrad]
	2416913641248 -> 2416913645424
	2416913636736 -> 2416913641968
	2417192382656 [label="decoder.blocks.3.conv1.0.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2417192382656 -> 2416913636736
	2416913636736 [label=AccumulateGrad]
	2416913641632 -> 2416913633520
	2417192382576 [label="decoder.blocks.3.conv1.1.weight
 (32)" fillcolor=lightblue]
	2417192382576 -> 2416913641632
	2416913641632 [label=AccumulateGrad]
	2416913643504 -> 2416913633520
	2417192382496 [label="decoder.blocks.3.conv1.1.bias
 (32)" fillcolor=lightblue]
	2417192382496 -> 2416913643504
	2416913643504 [label=AccumulateGrad]
	2416913630928 -> 2416913634144
	2417192382016 [label="decoder.blocks.3.conv2.0.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	2417192382016 -> 2416913630928
	2416913630928 [label=AccumulateGrad]
	2416913640864 -> 2416913640240
	2417192381936 [label="decoder.blocks.3.conv2.1.weight
 (32)" fillcolor=lightblue]
	2417192381936 -> 2416913640864
	2416913640864 [label=AccumulateGrad]
	2416913633472 -> 2416913640240
	2417192381856 [label="decoder.blocks.3.conv2.1.bias
 (32)" fillcolor=lightblue]
	2417192381856 -> 2416913633472
	2416913633472 [label=AccumulateGrad]
	2416982788272 -> 2416913422160
	2417192381376 [label="decoder.blocks.4.conv1.0.weight
 (16, 32, 3, 3)" fillcolor=lightblue]
	2417192381376 -> 2416982788272
	2416982788272 [label=AccumulateGrad]
	2416980941488 -> 2416913551456
	2417192381296 [label="decoder.blocks.4.conv1.1.weight
 (16)" fillcolor=lightblue]
	2417192381296 -> 2416980941488
	2416980941488 [label=AccumulateGrad]
	2416913257168 -> 2416913551456
	2417192381216 [label="decoder.blocks.4.conv1.1.bias
 (16)" fillcolor=lightblue]
	2417192381216 -> 2416913257168
	2416913257168 [label=AccumulateGrad]
	2416913958320 -> 2416773402864
	2417192380816 [label="decoder.blocks.4.conv2.0.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	2417192380816 -> 2416913958320
	2416913958320 [label=AccumulateGrad]
	2417190179488 -> 2416914199648
	2417192380736 [label="decoder.blocks.4.conv2.1.weight
 (16)" fillcolor=lightblue]
	2417192380736 -> 2417190179488
	2417190179488 [label=AccumulateGrad]
	2417190185440 -> 2416914199648
	2417192380656 [label="decoder.blocks.4.conv2.1.bias
 (16)" fillcolor=lightblue]
	2417192380656 -> 2417190185440
	2417190185440 [label=AccumulateGrad]
	2416982621632 -> 2417187390128
	2417192380176 [label="segmentation_head.0.weight
 (5, 16, 3, 3)" fillcolor=lightblue]
	2417192380176 -> 2416982621632
	2416982621632 [label=AccumulateGrad]
	2417187392288 -> 2417187390128
	2417192380096 [label="segmentation_head.0.bias
 (5)" fillcolor=lightblue]
	2417192380096 -> 2417187392288
	2417187392288 [label=AccumulateGrad]
	2417187390128 -> 2417191304432
}
