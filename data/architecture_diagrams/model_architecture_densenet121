digraph {
	graph [size="457.5,457.5"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	2463245183616 [label="
 (1, 5, 256, 256)" fillcolor=darkolivegreen1]
	2464465887600 [label=ConvolutionBackward0]
	2464502433632 -> 2464465887600
	2464502433632 [label=ReluBackward0]
	2464339166832 -> 2464502433632
	2464339166832 [label=CudnnBatchNormBackward0]
	2464213438608 -> 2464339166832
	2464213438608 [label=ConvolutionBackward0]
	2464596934032 -> 2464213438608
	2464596934032 [label=ReluBackward0]
	2464213206832 -> 2464596934032
	2464213206832 [label=CudnnBatchNormBackward0]
	2464372886160 -> 2464213206832
	2464372886160 [label=ConvolutionBackward0]
	2464338879360 -> 2464372886160
	2464338879360 [label=UpsampleNearest2DBackward0]
	2464338878496 -> 2464338879360
	2464338878496 [label=ReluBackward0]
	2464338884688 -> 2464338878496
	2464338884688 [label=CudnnBatchNormBackward0]
	2464338883392 -> 2464338884688
	2464338883392 [label=ConvolutionBackward0]
	2464338880032 -> 2464338883392
	2464338880032 [label=ReluBackward0]
	2464338873984 -> 2464338880032
	2464338873984 [label=CudnnBatchNormBackward0]
	2464338871200 -> 2464338873984
	2464338871200 [label=ConvolutionBackward0]
	2464338876096 -> 2464338871200
	2464338876096 [label=CatBackward0]
	2464851117920 -> 2464338876096
	2464851117920 [label=UpsampleNearest2DBackward0]
	2464338875376 -> 2464851117920
	2464338875376 [label=ReluBackward0]
	2464338885408 -> 2464338875376
	2464338885408 [label=CudnnBatchNormBackward0]
	2464338880896 -> 2464338885408
	2464338880896 [label=ConvolutionBackward0]
	2464338883152 -> 2464338880896
	2464338883152 [label=ReluBackward0]
	2464338873360 -> 2464338883152
	2464338873360 [label=CudnnBatchNormBackward0]
	2464338870576 -> 2464338873360
	2464338870576 [label=ConvolutionBackward0]
	2464338875040 -> 2464338870576
	2464338875040 [label=CatBackward0]
	2464338885504 -> 2464338875040
	2464338885504 [label=UpsampleNearest2DBackward0]
	2464338885456 -> 2464338885504
	2464338885456 [label=ReluBackward0]
	2464338871968 -> 2464338885456
	2464338871968 [label=CudnnBatchNormBackward0]
	2464338871344 -> 2464338871968
	2464338871344 [label=ConvolutionBackward0]
	2464338874464 -> 2464338871344
	2464338874464 [label=ReluBackward0]
	2464339019616 -> 2464338874464
	2464339019616 [label=CudnnBatchNormBackward0]
	2464339019568 -> 2464339019616
	2464339019568 [label=ConvolutionBackward0]
	2464339026192 -> 2464339019568
	2464339026192 [label=CatBackward0]
	2464339025280 -> 2464339026192
	2464339025280 [label=UpsampleNearest2DBackward0]
	2464339024704 -> 2464339025280
	2464339024704 [label=ReluBackward0]
	2464339024272 -> 2464339024704
	2464339024272 [label=CudnnBatchNormBackward0]
	2464339023792 -> 2464339024272
	2464339023792 [label=ConvolutionBackward0]
	2464339024032 -> 2464339023792
	2464339024032 [label=ReluBackward0]
	2464339026240 -> 2464339024032
	2464339026240 [label=CudnnBatchNormBackward0]
	2464339025088 -> 2464339026240
	2464339025088 [label=ConvolutionBackward0]
	2464339023840 -> 2464339025088
	2464339023840 [label=CatBackward0]
	2464339020288 -> 2464339023840
	2464339020288 [label=UpsampleNearest2DBackward0]
	2464339022304 -> 2464339020288
	2464339022304 [label=CudnnBatchNormBackward0]
	2464339027296 -> 2464339022304
	2464339027296 [label=CatBackward0]
	2464339031184 -> 2464339027296
	2464339031184 [label=AvgPool2DBackward0]
	2464339020480 -> 2464339031184
	2464339020480 [label=ConvolutionBackward0]
	2464339022208 -> 2464339020480
	2464339022208 [label=ReluBackward0]
	2464339023984 -> 2464339022208
	2464339023984 [label=CudnnBatchNormBackward0]
	2464339029984 -> 2464339023984
	2464339029984 [label=CatBackward0]
	2464339029264 -> 2464339029984
	2464339029264 [label=AvgPool2DBackward0]
	2464339021392 -> 2464339029264
	2464339021392 [label=ConvolutionBackward0]
	2464339025136 -> 2464339021392
	2464339025136 [label=ReluBackward0]
	2464339020912 -> 2464339025136
	2464339020912 [label=CudnnBatchNormBackward0]
	2464339018224 -> 2464339020912
	2464339018224 [label=CatBackward0]
	2464339022160 -> 2464339018224
	2464339022160 [label=AvgPool2DBackward0]
	2464339018560 -> 2464339022160
	2464339018560 [label=ConvolutionBackward0]
	2464338876384 -> 2464339018560
	2464338876384 [label=ReluBackward0]
	2464339025664 -> 2464338876384
	2464339025664 [label=CudnnBatchNormBackward0]
	2464339026432 -> 2464339025664
	2464339026432 [label=CatBackward0]
	2464339021056 -> 2464339026432
	2464339021056 [label=MaxPool2DWithIndicesBackward0]
	2464338870864 -> 2464339021056
	2464338870864 [label=ReluBackward0]
	2464339018128 -> 2464338870864
	2464339018128 [label=CudnnBatchNormBackward0]
	2464339018848 -> 2464339018128
	2464339018848 [label=ConvolutionBackward0]
	2464339019472 -> 2464339018848
	2464338621648 [label="encoder.features.conv0.weight
 (64, 3, 7, 7)" fillcolor=lightblue]
	2464338621648 -> 2464339019472
	2464339019472 [label=AccumulateGrad]
	2464339019184 -> 2464339018128
	2464338621008 [label="encoder.features.norm0.weight
 (64)" fillcolor=lightblue]
	2464338621008 -> 2464339019184
	2464339019184 [label=AccumulateGrad]
	2464339018176 -> 2464339018128
	2464338620208 [label="encoder.features.norm0.bias
 (64)" fillcolor=lightblue]
	2464338620208 -> 2464339018176
	2464339018176 [label=AccumulateGrad]
	2464339027776 -> 2464339026432
	2464339027776 [label=ConvolutionBackward0]
	2464851119216 -> 2464339027776
	2464851119216 [label=ReluBackward0]
	2464339020000 -> 2464851119216
	2464339020000 [label=CudnnBatchNormBackward0]
	2464339019424 -> 2464339020000
	2464339019424 [label=ConvolutionBackward0]
	2464339021680 -> 2464339019424
	2464339021680 [label=ReluBackward0]
	2464339022352 -> 2464339021680
	2464339022352 [label=CudnnBatchNormBackward0]
	2464339022928 -> 2464339022352
	2464339022928 [label=CatBackward0]
	2464339021056 -> 2464339022928
	2464339023120 -> 2464339022352
	2464338616288 [label="encoder.features.denseblock1.denselayer1.norm1.weight
 (64)" fillcolor=lightblue]
	2464338616288 -> 2464339023120
	2464339023120 [label=AccumulateGrad]
	2464339022256 -> 2464339022352
	2464338617408 [label="encoder.features.denseblock1.denselayer1.norm1.bias
 (64)" fillcolor=lightblue]
	2464338617408 -> 2464339022256
	2464339022256 [label=AccumulateGrad]
	2464339021872 -> 2464339019424
	2464338616528 [label="encoder.features.denseblock1.denselayer1.conv1.weight
 (128, 64, 1, 1)" fillcolor=lightblue]
	2464338616528 -> 2464339021872
	2464339021872 [label=AccumulateGrad]
	2464339020576 -> 2464339020000
	2464338616768 [label="encoder.features.denseblock1.denselayer1.norm2.weight
 (128)" fillcolor=lightblue]
	2464338616768 -> 2464339020576
	2464339020576 [label=AccumulateGrad]
	2464339020384 -> 2464339020000
	2464338608528 [label="encoder.features.denseblock1.denselayer1.norm2.bias
 (128)" fillcolor=lightblue]
	2464338608528 -> 2464339020384
	2464339020384 [label=AccumulateGrad]
	2464339019232 -> 2464339027776
	2464338609008 [label="encoder.features.denseblock1.denselayer1.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2464338609008 -> 2464339019232
	2464339019232 [label=AccumulateGrad]
	2464339033632 -> 2464339026432
	2464339033632 [label=ConvolutionBackward0]
	2464339021104 -> 2464339033632
	2464339021104 [label=ReluBackward0]
	2464339021584 -> 2464339021104
	2464339021584 [label=CudnnBatchNormBackward0]
	2464339023408 -> 2464339021584
	2464339023408 [label=ConvolutionBackward0]
	2464339024608 -> 2464339023408
	2464339024608 [label=ReluBackward0]
	2464339025232 -> 2464339024608
	2464339025232 [label=CudnnBatchNormBackward0]
	2464339025424 -> 2464339025232
	2464339025424 [label=CatBackward0]
	2464339021056 -> 2464339025424
	2464339027776 -> 2464339025424
	2464339025904 -> 2464339025232
	2464338608768 [label="encoder.features.denseblock1.denselayer2.norm1.weight
 (96)" fillcolor=lightblue]
	2464338608768 -> 2464339025904
	2464339025904 [label=AccumulateGrad]
	2464339024944 -> 2464339025232
	2464338608608 [label="encoder.features.denseblock1.denselayer2.norm1.bias
 (96)" fillcolor=lightblue]
	2464338608608 -> 2464339024944
	2464339024944 [label=AccumulateGrad]
	2464339024656 -> 2464339023408
	2464338615808 [label="encoder.features.denseblock1.denselayer2.conv1.weight
 (128, 96, 1, 1)" fillcolor=lightblue]
	2464338615808 -> 2464339024656
	2464339024656 [label=AccumulateGrad]
	2464339024080 -> 2464339021584
	2464338615648 [label="encoder.features.denseblock1.denselayer2.norm2.weight
 (128)" fillcolor=lightblue]
	2464338615648 -> 2464339024080
	2464339024080 [label=AccumulateGrad]
	2464339022640 -> 2464339021584
	2464338615408 [label="encoder.features.denseblock1.denselayer2.norm2.bias
 (128)" fillcolor=lightblue]
	2464338615408 -> 2464339022640
	2464339022640 [label=AccumulateGrad]
	2464339020192 -> 2464339033632
	2464851275088 [label="encoder.features.denseblock1.denselayer2.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2464851275088 -> 2464339020192
	2464339020192 [label=AccumulateGrad]
	2464339032576 -> 2464339026432
	2464339032576 [label=ConvolutionBackward0]
	2464339024176 -> 2464339032576
	2464339024176 [label=ReluBackward0]
	2464339024560 -> 2464339024176
	2464339024560 [label=CudnnBatchNormBackward0]
	2464339026048 -> 2464339024560
	2464339026048 [label=ConvolutionBackward0]
	2464339026768 -> 2464339026048
	2464339026768 [label=ReluBackward0]
	2464339027152 -> 2464339026768
	2464339027152 [label=CudnnBatchNormBackward0]
	2464339027488 -> 2464339027152
	2464339027488 [label=CatBackward0]
	2464339021056 -> 2464339027488
	2464339027776 -> 2464339027488
	2464339033632 -> 2464339027488
	2464339028016 -> 2464339027152
	2464851274848 [label="encoder.features.denseblock1.denselayer3.norm1.weight
 (128)" fillcolor=lightblue]
	2464851274848 -> 2464339028016
	2464339028016 [label=AccumulateGrad]
	2464339027104 -> 2464339027152
	2464851274688 [label="encoder.features.denseblock1.denselayer3.norm1.bias
 (128)" fillcolor=lightblue]
	2464851274688 -> 2464339027104
	2464339027104 [label=AccumulateGrad]
	2464339026864 -> 2464339026048
	2464851278368 [label="encoder.features.denseblock1.denselayer3.conv1.weight
 (128, 128, 1, 1)" fillcolor=lightblue]
	2464851278368 -> 2464339026864
	2464339026864 [label=AccumulateGrad]
	2464339026288 -> 2464339024560
	2464851275968 [label="encoder.features.denseblock1.denselayer3.norm2.weight
 (128)" fillcolor=lightblue]
	2464851275968 -> 2464339026288
	2464339026288 [label=AccumulateGrad]
	2464339025376 -> 2464339024560
	2464851270128 [label="encoder.features.denseblock1.denselayer3.norm2.bias
 (128)" fillcolor=lightblue]
	2464851270128 -> 2464339025376
	2464339025376 [label=AccumulateGrad]
	2464339023312 -> 2464339032576
	2464851279488 [label="encoder.features.denseblock1.denselayer3.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2464851279488 -> 2464339023312
	2464339023312 [label=AccumulateGrad]
	2464339029168 -> 2464339026432
	2464339029168 [label=ConvolutionBackward0]
	2464339026384 -> 2464339029168
	2464339026384 [label=ReluBackward0]
	2464339026576 -> 2464339026384
	2464339026576 [label=CudnnBatchNormBackward0]
	2464339028352 -> 2464339026576
	2464339028352 [label=ConvolutionBackward0]
	2464339029216 -> 2464339028352
	2464339029216 [label=ReluBackward0]
	2464339029888 -> 2464339029216
	2464339029888 [label=CudnnBatchNormBackward0]
	2464339030128 -> 2464339029888
	2464339030128 [label=CatBackward0]
	2464339021056 -> 2464339030128
	2464339027776 -> 2464339030128
	2464339033632 -> 2464339030128
	2464339032576 -> 2464339030128
	2464339030320 -> 2464339029888
	2464851273568 [label="encoder.features.denseblock1.denselayer4.norm1.weight
 (160)" fillcolor=lightblue]
	2464851273568 -> 2464339030320
	2464339030320 [label=AccumulateGrad]
	2464339029600 -> 2464339029888
	2464851275648 [label="encoder.features.denseblock1.denselayer4.norm1.bias
 (160)" fillcolor=lightblue]
	2464851275648 -> 2464339029600
	2464339029600 [label=AccumulateGrad]
	2464339029504 -> 2464339028352
	2464851279008 [label="encoder.features.denseblock1.denselayer4.conv1.weight
 (128, 160, 1, 1)" fillcolor=lightblue]
	2464851279008 -> 2464339029504
	2464339029504 [label=AccumulateGrad]
	2464339028640 -> 2464339026576
	2464851278928 [label="encoder.features.denseblock1.denselayer4.norm2.weight
 (128)" fillcolor=lightblue]
	2464851278928 -> 2464339028640
	2464339028640 [label=AccumulateGrad]
	2464339027248 -> 2464339026576
	2464851276688 [label="encoder.features.denseblock1.denselayer4.norm2.bias
 (128)" fillcolor=lightblue]
	2464851276688 -> 2464339027248
	2464339027248 [label=AccumulateGrad]
	2464339026000 -> 2464339029168
	2464851274448 [label="encoder.features.denseblock1.denselayer4.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2464851274448 -> 2464339026000
	2464339026000 [label=AccumulateGrad]
	2464339019664 -> 2464339026432
	2464339019664 [label=ConvolutionBackward0]
	2464339028688 -> 2464339019664
	2464339028688 [label=ReluBackward0]
	2464339028928 -> 2464339028688
	2464339028928 [label=CudnnBatchNormBackward0]
	2464339030800 -> 2464339028928
	2464339030800 [label=ConvolutionBackward0]
	2464339031376 -> 2464339030800
	2464339031376 [label=ReluBackward0]
	2464339031760 -> 2464339031376
	2464339031760 [label=CudnnBatchNormBackward0]
	2464339032048 -> 2464339031760
	2464339032048 [label=CatBackward0]
	2464339021056 -> 2464339032048
	2464339027776 -> 2464339032048
	2464339033632 -> 2464339032048
	2464339032576 -> 2464339032048
	2464339029168 -> 2464339032048
	2464339032144 -> 2464339031760
	2464851278208 [label="encoder.features.denseblock1.denselayer5.norm1.weight
 (192)" fillcolor=lightblue]
	2464851278208 -> 2464339032144
	2464339032144 [label=AccumulateGrad]
	2464339031568 -> 2464339031760
	2464851277008 [label="encoder.features.denseblock1.denselayer5.norm1.bias
 (192)" fillcolor=lightblue]
	2464851277008 -> 2464339031568
	2464339031568 [label=AccumulateGrad]
	2464339031424 -> 2464339030800
	2464851278288 [label="encoder.features.denseblock1.denselayer5.conv1.weight
 (128, 192, 1, 1)" fillcolor=lightblue]
	2464851278288 -> 2464339031424
	2464339031424 [label=AccumulateGrad]
	2464339030896 -> 2464339028928
	2464851276608 [label="encoder.features.denseblock1.denselayer5.norm2.weight
 (128)" fillcolor=lightblue]
	2464851276608 -> 2464339030896
	2464339030896 [label=AccumulateGrad]
	2464339029936 -> 2464339028928
	2464851276288 [label="encoder.features.denseblock1.denselayer5.norm2.bias
 (128)" fillcolor=lightblue]
	2464851276288 -> 2464339029936
	2464339029936 [label=AccumulateGrad]
	2464339028112 -> 2464339019664
	2464850480336 [label="encoder.features.denseblock1.denselayer5.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2464850480336 -> 2464339028112
	2464339028112 [label=AccumulateGrad]
	2464339017840 -> 2464339026432
	2464339017840 [label=ConvolutionBackward0]
	2464339031040 -> 2464339017840
	2464339031040 [label=ReluBackward0]
	2464339031088 -> 2464339031040
	2464339031088 [label=CudnnBatchNormBackward0]
	2464339032288 -> 2464339031088
	2464339032288 [label=ConvolutionBackward0]
	2464339033392 -> 2464339032288
	2464339033392 [label=ReluBackward0]
	2464339033872 -> 2464339033392
	2464339033872 [label=CudnnBatchNormBackward0]
	2464339034016 -> 2464339033872
	2464339034016 [label=CatBackward0]
	2464339021056 -> 2464339034016
	2464339027776 -> 2464339034016
	2464339033632 -> 2464339034016
	2464339032576 -> 2464339034016
	2464339029168 -> 2464339034016
	2464339019664 -> 2464339034016
	2464339022880 -> 2464339033872
	2464850486736 [label="encoder.features.denseblock1.denselayer6.norm1.weight
 (224)" fillcolor=lightblue]
	2464850486736 -> 2464339022880
	2464339022880 [label=AccumulateGrad]
	2464339033776 -> 2464339033872
	2464850483936 [label="encoder.features.denseblock1.denselayer6.norm1.bias
 (224)" fillcolor=lightblue]
	2464850483936 -> 2464339033776
	2464339033776 [label=AccumulateGrad]
	2464339033584 -> 2464339032288
	2464851969680 [label="encoder.features.denseblock1.denselayer6.conv1.weight
 (128, 224, 1, 1)" fillcolor=lightblue]
	2464851969680 -> 2464339033584
	2464339033584 [label=AccumulateGrad]
	2464339032432 -> 2464339031088
	2464851974720 [label="encoder.features.denseblock1.denselayer6.norm2.weight
 (128)" fillcolor=lightblue]
	2464851974720 -> 2464339032432
	2464339032432 [label=AccumulateGrad]
	2464339032000 -> 2464339031088
	2464851976240 [label="encoder.features.denseblock1.denselayer6.norm2.bias
 (128)" fillcolor=lightblue]
	2464851976240 -> 2464339032000
	2464339032000 [label=AccumulateGrad]
	2464339030560 -> 2464339017840
	2464851968320 [label="encoder.features.denseblock1.denselayer6.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2464851968320 -> 2464339030560
	2464339030560 [label=AccumulateGrad]
	2464339026624 -> 2464339025664
	2464851969760 [label="encoder.features.transition1.norm.weight
 (256)" fillcolor=lightblue]
	2464851969760 -> 2464339026624
	2464339026624 [label=AccumulateGrad]
	2464339030944 -> 2464339025664
	2464851969600 [label="encoder.features.transition1.norm.bias
 (256)" fillcolor=lightblue]
	2464851969600 -> 2464339030944
	2464339030944 [label=AccumulateGrad]
	2464339031280 -> 2464339018560
	2464851970240 [label="encoder.features.transition1.conv.weight
 (128, 256, 1, 1)" fillcolor=lightblue]
	2464851970240 -> 2464339031280
	2464339031280 [label=AccumulateGrad]
	2464339021728 -> 2464339018224
	2464339021728 [label=ConvolutionBackward0]
	2464339025328 -> 2464339021728
	2464339025328 [label=ReluBackward0]
	2464339032816 -> 2464339025328
	2464339032816 [label=CudnnBatchNormBackward0]
	2464339018704 -> 2464339032816
	2464339018704 [label=ConvolutionBackward0]
	2464339022688 -> 2464339018704
	2464339022688 [label=ReluBackward0]
	2464339021200 -> 2464339022688
	2464339021200 [label=CudnnBatchNormBackward0]
	2464339028736 -> 2464339021200
	2464339028736 [label=CatBackward0]
	2464339022160 -> 2464339028736
	2464339022064 -> 2464339021200
	2464851970560 [label="encoder.features.denseblock2.denselayer1.norm1.weight
 (128)" fillcolor=lightblue]
	2464851970560 -> 2464339022064
	2464339022064 [label=AccumulateGrad]
	2464339019856 -> 2464339021200
	2464851969920 [label="encoder.features.denseblock2.denselayer1.norm1.bias
 (128)" fillcolor=lightblue]
	2464851969920 -> 2464339019856
	2464339019856 [label=AccumulateGrad]
	2464339021536 -> 2464339018704
	2464851971520 [label="encoder.features.denseblock2.denselayer1.conv1.weight
 (128, 128, 1, 1)" fillcolor=lightblue]
	2464851971520 -> 2464339021536
	2464339021536 [label=AccumulateGrad]
	2464339032240 -> 2464339032816
	2464851972880 [label="encoder.features.denseblock2.denselayer1.norm2.weight
 (128)" fillcolor=lightblue]
	2464851972880 -> 2464339032240
	2464339032240 [label=AccumulateGrad]
	2464339025856 -> 2464339032816
	2464851972720 [label="encoder.features.denseblock2.denselayer1.norm2.bias
 (128)" fillcolor=lightblue]
	2464851972720 -> 2464339025856
	2464339025856 [label=AccumulateGrad]
	2464339018896 -> 2464339021728
	2464851973040 [label="encoder.features.denseblock2.denselayer1.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2464851973040 -> 2464339018896
	2464339018896 [label=AccumulateGrad]
	2464339027968 -> 2464339018224
	2464339027968 [label=ConvolutionBackward0]
	2464339033968 -> 2464339027968
	2464339033968 [label=ReluBackward0]
	2464339032864 -> 2464339033968
	2464339032864 [label=CudnnBatchNormBackward0]
	2464339022592 -> 2464339032864
	2464339022592 [label=ConvolutionBackward0]
	2464339025184 -> 2464339022592
	2464339025184 [label=ReluBackward0]
	2464339032768 -> 2464339025184
	2464339032768 [label=CudnnBatchNormBackward0]
	2464339022784 -> 2464339032768
	2464339022784 [label=CatBackward0]
	2464339022160 -> 2464339022784
	2464339021728 -> 2464339022784
	2464339017936 -> 2464339032768
	2464851973360 [label="encoder.features.denseblock2.denselayer2.norm1.weight
 (160)" fillcolor=lightblue]
	2464851973360 -> 2464339017936
	2464339017936 [label=AccumulateGrad]
	2464339023552 -> 2464339032768
	2464851973520 [label="encoder.features.denseblock2.denselayer2.norm1.bias
 (160)" fillcolor=lightblue]
	2464851973520 -> 2464339023552
	2464339023552 [label=AccumulateGrad]
	2464339033344 -> 2464339022592
	2464851975840 [label="encoder.features.denseblock2.denselayer2.conv1.weight
 (128, 160, 1, 1)" fillcolor=lightblue]
	2464851975840 -> 2464339033344
	2464339033344 [label=AccumulateGrad]
	2464339023696 -> 2464339032864
	2464851975600 [label="encoder.features.denseblock2.denselayer2.norm2.weight
 (128)" fillcolor=lightblue]
	2464851975600 -> 2464339023696
	2464339023696 [label=AccumulateGrad]
	2464339029360 -> 2464339032864
	2464851975440 [label="encoder.features.denseblock2.denselayer2.norm2.bias
 (128)" fillcolor=lightblue]
	2464851975440 -> 2464339029360
	2464339029360 [label=AccumulateGrad]
	2464339017984 -> 2464339027968
	2464851976160 [label="encoder.features.denseblock2.denselayer2.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2464851976160 -> 2464339017984
	2464339017984 [label=AccumulateGrad]
	2464339029312 -> 2464339018224
	2464339029312 [label=ConvolutionBackward0]
	2464339028592 -> 2464339029312
	2464339028592 [label=ReluBackward0]
	2464339028832 -> 2464339028592
	2464339028832 [label=CudnnBatchNormBackward0]
	2464339023360 -> 2464339028832
	2464339023360 [label=ConvolutionBackward0]
	2464339025616 -> 2464339023360
	2464339025616 [label=ReluBackward0]
	2464339027344 -> 2464339025616
	2464339027344 [label=CudnnBatchNormBackward0]
	2464339027920 -> 2464339027344
	2464339027920 [label=CatBackward0]
	2464339022160 -> 2464339027920
	2464339021728 -> 2464339027920
	2464339027968 -> 2464339027920
	2464339021152 -> 2464339027344
	2464851976480 [label="encoder.features.denseblock2.denselayer3.norm1.weight
 (192)" fillcolor=lightblue]
	2464851976480 -> 2464339021152
	2464339021152 [label=AccumulateGrad]
	2464339018080 -> 2464339027344
	2464851978000 [label="encoder.features.denseblock2.denselayer3.norm1.bias
 (192)" fillcolor=lightblue]
	2464851978000 -> 2464339018080
	2464339018080 [label=AccumulateGrad]
	2464339032336 -> 2464339023360
	2464851978720 [label="encoder.features.denseblock2.denselayer3.conv1.weight
 (128, 192, 1, 1)" fillcolor=lightblue]
	2464851978720 -> 2464339032336
	2464339032336 [label=AccumulateGrad]
	2464339030752 -> 2464339028832
	2464851976880 [label="encoder.features.denseblock2.denselayer3.norm2.weight
 (128)" fillcolor=lightblue]
	2464851976880 -> 2464339030752
	2464339030752 [label=AccumulateGrad]
	2464339018032 -> 2464339028832
	2464851978160 [label="encoder.features.denseblock2.denselayer3.norm2.bias
 (128)" fillcolor=lightblue]
	2464851978160 -> 2464339018032
	2464339018032 [label=AccumulateGrad]
	2464339019760 -> 2464339029312
	2464851980720 [label="encoder.features.denseblock2.denselayer3.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2464851980720 -> 2464339019760
	2464339019760 [label=AccumulateGrad]
	2464339027056 -> 2464339018224
	2464339027056 [label=ConvolutionBackward0]
	2464339022496 -> 2464339027056
	2464339022496 [label=ReluBackward0]
	2464339029024 -> 2464339022496
	2464339029024 [label=CudnnBatchNormBackward0]
	2464339029456 -> 2464339029024
	2464339029456 [label=ConvolutionBackward0]
	2464339019328 -> 2464339029456
	2464339019328 [label=ReluBackward0]
	2464339026720 -> 2464339019328
	2464339026720 [label=CudnnBatchNormBackward0]
	2464339031664 -> 2464339026720
	2464339031664 [label=CatBackward0]
	2464339022160 -> 2464339031664
	2464339021728 -> 2464339031664
	2464339027968 -> 2464339031664
	2464339029312 -> 2464339031664
	2464339020432 -> 2464339026720
	2464851980560 [label="encoder.features.denseblock2.denselayer4.norm1.weight
 (224)" fillcolor=lightblue]
	2464851980560 -> 2464339020432
	2464339020432 [label=AccumulateGrad]
	2464339017888 -> 2464339026720
	2464851980400 [label="encoder.features.denseblock2.denselayer4.norm1.bias
 (224)" fillcolor=lightblue]
	2464851980400 -> 2464339017888
	2464339017888 [label=AccumulateGrad]
	2464339020864 -> 2464339029456
	2464851981360 [label="encoder.features.denseblock2.denselayer4.conv1.weight
 (128, 224, 1, 1)" fillcolor=lightblue]
	2464851981360 -> 2464339020864
	2464339020864 [label=AccumulateGrad]
	2464339022544 -> 2464339029024
	2464851982640 [label="encoder.features.denseblock2.denselayer4.norm2.weight
 (128)" fillcolor=lightblue]
	2464851982640 -> 2464339022544
	2464339022544 [label=AccumulateGrad]
	2464339034064 -> 2464339029024
	2464851982480 [label="encoder.features.denseblock2.denselayer4.norm2.bias
 (128)" fillcolor=lightblue]
	2464851982480 -> 2464339034064
	2464339034064 [label=AccumulateGrad]
	2464339033200 -> 2464339027056
	2464851982960 [label="encoder.features.denseblock2.denselayer4.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2464851982960 -> 2464339033200
	2464339033200 [label=AccumulateGrad]
	2464339033680 -> 2464339018224
	2464339033680 [label=ConvolutionBackward0]
	2464339031232 -> 2464339033680
	2464339031232 [label=ReluBackward0]
	2464339026096 -> 2464339031232
	2464339026096 [label=CudnnBatchNormBackward0]
	2464339018608 -> 2464339026096
	2464339018608 [label=ConvolutionBackward0]
	2464339033824 -> 2464339018608
	2464339033824 [label=ReluBackward0]
	2464339027632 -> 2464339033824
	2464339027632 [label=CudnnBatchNormBackward0]
	2464339024800 -> 2464339027632
	2464339024800 [label=CatBackward0]
	2464339022160 -> 2464339024800
	2464339021728 -> 2464339024800
	2464339027968 -> 2464339024800
	2464339029312 -> 2464339024800
	2464339027056 -> 2464339024800
	2464339032624 -> 2464339027632
	2464851983280 [label="encoder.features.denseblock2.denselayer5.norm1.weight
 (256)" fillcolor=lightblue]
	2464851983280 -> 2464339032624
	2464339032624 [label=AccumulateGrad]
	2464339030704 -> 2464339027632
	2464851978640 [label="encoder.features.denseblock2.denselayer5.norm1.bias
 (256)" fillcolor=lightblue]
	2464851978640 -> 2464339030704
	2464339030704 [label=AccumulateGrad]
	2464339031328 -> 2464339018608
	2464851969040 [label="encoder.features.denseblock2.denselayer5.conv1.weight
 (128, 256, 1, 1)" fillcolor=lightblue]
	2464851969040 -> 2464339031328
	2464339031328 [label=AccumulateGrad]
	2464339020240 -> 2464339026096
	2464851983680 [label="encoder.features.denseblock2.denselayer5.norm2.weight
 (128)" fillcolor=lightblue]
	2464851983680 -> 2464339020240
	2464339020240 [label=AccumulateGrad]
	2464339030656 -> 2464339026096
	2464851979200 [label="encoder.features.denseblock2.denselayer5.norm2.bias
 (128)" fillcolor=lightblue]
	2464851979200 -> 2464339030656
	2464339030656 [label=AccumulateGrad]
	2464339027536 -> 2464339033680
	2464851979840 [label="encoder.features.denseblock2.denselayer5.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2464851979840 -> 2464339027536
	2464339027536 [label=AccumulateGrad]
	2464339030992 -> 2464339018224
	2464339030992 [label=ConvolutionBackward0]
	2464339028976 -> 2464339030992
	2464339028976 [label=ReluBackward0]
	2464339021440 -> 2464339028976
	2464339021440 [label=CudnnBatchNormBackward0]
	2464339021008 -> 2464339021440
	2464339021008 [label=ConvolutionBackward0]
	2464339022112 -> 2464339021008
	2464339022112 [label=ReluBackward0]
	2464339026528 -> 2464339022112
	2464339026528 [label=CudnnBatchNormBackward0]
	2464339031904 -> 2464339026528
	2464339031904 [label=CatBackward0]
	2464339022160 -> 2464339031904
	2464339021728 -> 2464339031904
	2464339027968 -> 2464339031904
	2464339029312 -> 2464339031904
	2464339027056 -> 2464339031904
	2464339033680 -> 2464339031904
	2464339023648 -> 2464339026528
	2464851516688 [label="encoder.features.denseblock2.denselayer6.norm1.weight
 (288)" fillcolor=lightblue]
	2464851516688 -> 2464339023648
	2464339023648 [label=AccumulateGrad]
	2464339033056 -> 2464339026528
	2464851509408 [label="encoder.features.denseblock2.denselayer6.norm1.bias
 (288)" fillcolor=lightblue]
	2464851509408 -> 2464339033056
	2464339033056 [label=AccumulateGrad]
	2464339020816 -> 2464339021008
	2464849241712 [label="encoder.features.denseblock2.denselayer6.conv1.weight
 (128, 288, 1, 1)" fillcolor=lightblue]
	2464849241712 -> 2464339020816
	2464339020816 [label=AccumulateGrad]
	2464339033152 -> 2464339021440
	2464849242992 [label="encoder.features.denseblock2.denselayer6.norm2.weight
 (128)" fillcolor=lightblue]
	2464849242992 -> 2464339033152
	2464339033152 [label=AccumulateGrad]
	2464339020768 -> 2464339021440
	2464849239152 [label="encoder.features.denseblock2.denselayer6.norm2.bias
 (128)" fillcolor=lightblue]
	2464849239152 -> 2464339020768
	2464339020768 [label=AccumulateGrad]
	2464339028304 -> 2464339030992
	2464849233712 [label="encoder.features.denseblock2.denselayer6.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2464849233712 -> 2464339028304
	2464339028304 [label=AccumulateGrad]
	2464339025808 -> 2464339018224
	2464339025808 [label=ConvolutionBackward0]
	2464339031808 -> 2464339025808
	2464339031808 [label=ReluBackward0]
	2464339026672 -> 2464339031808
	2464339026672 [label=CudnnBatchNormBackward0]
	2464339020048 -> 2464339026672
	2464339020048 [label=ConvolutionBackward0]
	2464339028400 -> 2464339020048
	2464339028400 [label=ReluBackward0]
	2464339019904 -> 2464339028400
	2464339019904 [label=CudnnBatchNormBackward0]
	2464339031952 -> 2464339019904
	2464339031952 [label=CatBackward0]
	2464339022160 -> 2464339031952
	2464339021728 -> 2464339031952
	2464339027968 -> 2464339031952
	2464339029312 -> 2464339031952
	2464339027056 -> 2464339031952
	2464339033680 -> 2464339031952
	2464339030992 -> 2464339031952
	2464339020624 -> 2464339019904
	2464849233552 [label="encoder.features.denseblock2.denselayer7.norm1.weight
 (320)" fillcolor=lightblue]
	2464849233552 -> 2464339020624
	2464339020624 [label=AccumulateGrad]
	2464339020672 -> 2464339019904
	2464849232992 [label="encoder.features.denseblock2.denselayer7.norm1.bias
 (320)" fillcolor=lightblue]
	2464849232992 -> 2464339020672
	2464339020672 [label=AccumulateGrad]
	2464339024512 -> 2464339020048
	2464849234192 [label="encoder.features.denseblock2.denselayer7.conv1.weight
 (128, 320, 1, 1)" fillcolor=lightblue]
	2464849234192 -> 2464339024512
	2464339024512 [label=AccumulateGrad]
	2464339028160 -> 2464339026672
	2464849235552 [label="encoder.features.denseblock2.denselayer7.norm2.weight
 (128)" fillcolor=lightblue]
	2464849235552 -> 2464339028160
	2464339028160 [label=AccumulateGrad]
	2464339032672 -> 2464339026672
	2464849235472 [label="encoder.features.denseblock2.denselayer7.norm2.bias
 (128)" fillcolor=lightblue]
	2464849235472 -> 2464339032672
	2464339032672 [label=AccumulateGrad]
	2464339031520 -> 2464339025808
	2464849236112 [label="encoder.features.denseblock2.denselayer7.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2464849236112 -> 2464339031520
	2464339031520 [label=AccumulateGrad]
	2464339030176 -> 2464339018224
	2464339030176 [label=ConvolutionBackward0]
	2464339029120 -> 2464339030176
	2464339029120 [label=ReluBackward0]
	2464339026816 -> 2464339029120
	2464339026816 [label=CudnnBatchNormBackward0]
	2464339026144 -> 2464339026816
	2464339026144 [label=ConvolutionBackward0]
	2464339023504 -> 2464339026144
	2464339023504 [label=ReluBackward0]
	2464339031712 -> 2464339023504
	2464339031712 [label=CudnnBatchNormBackward0]
	2464339022976 -> 2464339031712
	2464339022976 [label=CatBackward0]
	2464339022160 -> 2464339022976
	2464339021728 -> 2464339022976
	2464339027968 -> 2464339022976
	2464339029312 -> 2464339022976
	2464339027056 -> 2464339022976
	2464339033680 -> 2464339022976
	2464339030992 -> 2464339022976
	2464339025808 -> 2464339022976
	2464339020960 -> 2464339031712
	2464849235952 [label="encoder.features.denseblock2.denselayer8.norm1.weight
 (352)" fillcolor=lightblue]
	2464849235952 -> 2464339020960
	2464339020960 [label=AccumulateGrad]
	2464339032480 -> 2464339031712
	2464849236272 [label="encoder.features.denseblock2.denselayer8.norm1.bias
 (352)" fillcolor=lightblue]
	2464849236272 -> 2464339032480
	2464339032480 [label=AccumulateGrad]
	2464339030416 -> 2464339026144
	2464849239072 [label="encoder.features.denseblock2.denselayer8.conv1.weight
 (128, 352, 1, 1)" fillcolor=lightblue]
	2464849239072 -> 2464339030416
	2464339030416 [label=AccumulateGrad]
	2464339029744 -> 2464339026816
	2464849238752 [label="encoder.features.denseblock2.denselayer8.norm2.weight
 (128)" fillcolor=lightblue]
	2464849238752 -> 2464339029744
	2464339029744 [label=AccumulateGrad]
	2464339029072 -> 2464339026816
	2464849238432 [label="encoder.features.denseblock2.denselayer8.norm2.bias
 (128)" fillcolor=lightblue]
	2464849238432 -> 2464339029072
	2464339029072 [label=AccumulateGrad]
	2464339018272 -> 2464339030176
	2464849239392 [label="encoder.features.denseblock2.denselayer8.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2464849239392 -> 2464339018272
	2464339018272 [label=AccumulateGrad]
	2464339028784 -> 2464339018224
	2464339028784 [label=ConvolutionBackward0]
	2464339031136 -> 2464339028784
	2464339031136 [label=ReluBackward0]
	2464339033440 -> 2464339031136
	2464339033440 [label=CudnnBatchNormBackward0]
	2464338776016 -> 2464339033440
	2464338776016 [label=ConvolutionBackward0]
	2464338788064 -> 2464338776016
	2464338788064 [label=ReluBackward0]
	2464338776880 -> 2464338788064
	2464338776880 [label=CudnnBatchNormBackward0]
	2464338773328 -> 2464338776880
	2464338773328 [label=CatBackward0]
	2464339022160 -> 2464338773328
	2464339021728 -> 2464338773328
	2464339027968 -> 2464338773328
	2464339029312 -> 2464338773328
	2464339027056 -> 2464338773328
	2464339033680 -> 2464338773328
	2464339030992 -> 2464338773328
	2464339025808 -> 2464338773328
	2464339030176 -> 2464338773328
	2464338786816 -> 2464338776880
	2464849239232 [label="encoder.features.denseblock2.denselayer9.norm1.weight
 (384)" fillcolor=lightblue]
	2464849239232 -> 2464338786816
	2464338786816 [label=AccumulateGrad]
	2464338779856 -> 2464338776880
	2464849240672 [label="encoder.features.denseblock2.denselayer9.norm1.bias
 (384)" fillcolor=lightblue]
	2464849240672 -> 2464338779856
	2464338779856 [label=AccumulateGrad]
	2464338787824 -> 2464338776016
	2464849241152 [label="encoder.features.denseblock2.denselayer9.conv1.weight
 (128, 384, 1, 1)" fillcolor=lightblue]
	2464849241152 -> 2464338787824
	2464338787824 [label=AccumulateGrad]
	2464338785856 -> 2464339033440
	2464849240992 [label="encoder.features.denseblock2.denselayer9.norm2.weight
 (128)" fillcolor=lightblue]
	2464849240992 -> 2464338785856
	2464338785856 [label=AccumulateGrad]
	2464338779904 -> 2464339033440
	2464849241312 [label="encoder.features.denseblock2.denselayer9.norm2.bias
 (128)" fillcolor=lightblue]
	2464849241312 -> 2464338779904
	2464338779904 [label=AccumulateGrad]
	2464339022400 -> 2464339028784
	2464849243552 [label="encoder.features.denseblock2.denselayer9.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2464849243552 -> 2464339022400
	2464339022400 [label=AccumulateGrad]
	2464339018656 -> 2464339018224
	2464339018656 [label=ConvolutionBackward0]
	2464339028880 -> 2464339018656
	2464339028880 [label=ReluBackward0]
	2464338786000 -> 2464339028880
	2464338786000 [label=CudnnBatchNormBackward0]
	2464338785520 -> 2464338786000
	2464338785520 [label=ConvolutionBackward0]
	2464338784512 -> 2464338785520
	2464338784512 [label=ReluBackward0]
	2464338776352 -> 2464338784512
	2464338776352 [label=CudnnBatchNormBackward0]
	2464338781584 -> 2464338776352
	2464338781584 [label=CatBackward0]
	2464339022160 -> 2464338781584
	2464339021728 -> 2464338781584
	2464339027968 -> 2464338781584
	2464339029312 -> 2464338781584
	2464339027056 -> 2464338781584
	2464339033680 -> 2464338781584
	2464339030992 -> 2464338781584
	2464339025808 -> 2464338781584
	2464339030176 -> 2464338781584
	2464339028784 -> 2464338781584
	2464338782928 -> 2464338776352
	2464849243072 [label="encoder.features.denseblock2.denselayer10.norm1.weight
 (416)" fillcolor=lightblue]
	2464849243072 -> 2464338782928
	2464338782928 [label=AccumulateGrad]
	2464338783504 -> 2464338776352
	2464849242912 [label="encoder.features.denseblock2.denselayer10.norm1.bias
 (416)" fillcolor=lightblue]
	2464849242912 -> 2464338783504
	2464338783504 [label=AccumulateGrad]
	2464338784176 -> 2464338785520
	2464849244432 [label="encoder.features.denseblock2.denselayer10.conv1.weight
 (128, 416, 1, 1)" fillcolor=lightblue]
	2464849244432 -> 2464338784176
	2464338784176 [label=AccumulateGrad]
	2464338785280 -> 2464338786000
	2464849245952 [label="encoder.features.denseblock2.denselayer10.norm2.weight
 (128)" fillcolor=lightblue]
	2464849245952 -> 2464338785280
	2464338785280 [label=AccumulateGrad]
	2464338784128 -> 2464338786000
	2464849245632 [label="encoder.features.denseblock2.denselayer10.norm2.bias
 (128)" fillcolor=lightblue]
	2464849245632 -> 2464338784128
	2464338784128 [label=AccumulateGrad]
	2464339033536 -> 2464339018656
	2464849246272 [label="encoder.features.denseblock2.denselayer10.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2464849246272 -> 2464339033536
	2464339033536 [label=AccumulateGrad]
	2464339026960 -> 2464339018224
	2464339026960 [label=ConvolutionBackward0]
	2464338777024 -> 2464339026960
	2464338777024 [label=ReluBackward0]
	2464338782832 -> 2464338777024
	2464338782832 [label=CudnnBatchNormBackward0]
	2464338788256 -> 2464338782832
	2464338788256 [label=ConvolutionBackward0]
	2464338784800 -> 2464338788256
	2464338784800 [label=ReluBackward0]
	2464338780384 -> 2464338784800
	2464338780384 [label=CudnnBatchNormBackward0]
	2464338781248 -> 2464338780384
	2464338781248 [label=CatBackward0]
	2464339022160 -> 2464338781248
	2464339021728 -> 2464338781248
	2464339027968 -> 2464338781248
	2464339029312 -> 2464338781248
	2464339027056 -> 2464338781248
	2464339033680 -> 2464338781248
	2464339030992 -> 2464338781248
	2464339025808 -> 2464338781248
	2464339030176 -> 2464338781248
	2464339028784 -> 2464338781248
	2464339018656 -> 2464338781248
	2464338779568 -> 2464338780384
	2464849246112 [label="encoder.features.denseblock2.denselayer11.norm1.weight
 (448)" fillcolor=lightblue]
	2464849246112 -> 2464338779568
	2464338779568 [label=AccumulateGrad]
	2464338783552 -> 2464338780384
	2464849246592 [label="encoder.features.denseblock2.denselayer11.norm1.bias
 (448)" fillcolor=lightblue]
	2464849246592 -> 2464338783552
	2464338783552 [label=AccumulateGrad]
	2464338773616 -> 2464338788256
	2464849234112 [label="encoder.features.denseblock2.denselayer11.conv1.weight
 (128, 448, 1, 1)" fillcolor=lightblue]
	2464849234112 -> 2464338773616
	2464338773616 [label=AccumulateGrad]
	2464338782112 -> 2464338782832
	2464849232912 [label="encoder.features.denseblock2.denselayer11.norm2.weight
 (128)" fillcolor=lightblue]
	2464849232912 -> 2464338782112
	2464338782112 [label=AccumulateGrad]
	2464338783408 -> 2464338782832
	2464849232272 [label="encoder.features.denseblock2.denselayer11.norm2.bias
 (128)" fillcolor=lightblue]
	2464849232272 -> 2464338783408
	2464338783408 [label=AccumulateGrad]
	2464338785616 -> 2464339026960
	2464849242352 [label="encoder.features.denseblock2.denselayer11.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2464849242352 -> 2464338785616
	2464338785616 [label=AccumulateGrad]
	2464339033728 -> 2464339018224
	2464339033728 [label=ConvolutionBackward0]
	2464338781728 -> 2464339033728
	2464338781728 [label=ReluBackward0]
	2464338785232 -> 2464338781728
	2464338785232 [label=CudnnBatchNormBackward0]
	2464338779184 -> 2464338785232
	2464338779184 [label=ConvolutionBackward0]
	2464338778080 -> 2464338779184
	2464338778080 [label=ReluBackward0]
	2464338777264 -> 2464338778080
	2464338777264 [label=CudnnBatchNormBackward0]
	2464338776928 -> 2464338777264
	2464338776928 [label=CatBackward0]
	2464339022160 -> 2464338776928
	2464339021728 -> 2464338776928
	2464339027968 -> 2464338776928
	2464339029312 -> 2464338776928
	2464339027056 -> 2464338776928
	2464339033680 -> 2464338776928
	2464339030992 -> 2464338776928
	2464339025808 -> 2464338776928
	2464339030176 -> 2464338776928
	2464339028784 -> 2464338776928
	2464339018656 -> 2464338776928
	2464339026960 -> 2464338776928
	2464338773856 -> 2464338777264
	2464849234752 [label="encoder.features.denseblock2.denselayer12.norm1.weight
 (480)" fillcolor=lightblue]
	2464849234752 -> 2464338773856
	2464338773856 [label=AccumulateGrad]
	2464338777552 -> 2464338777264
	2464849027680 [label="encoder.features.denseblock2.denselayer12.norm1.bias
 (480)" fillcolor=lightblue]
	2464849027680 -> 2464338777552
	2464338777552 [label=AccumulateGrad]
	2464338777792 -> 2464338779184
	2464849030080 [label="encoder.features.denseblock2.denselayer12.conv1.weight
 (128, 480, 1, 1)" fillcolor=lightblue]
	2464849030080 -> 2464338777792
	2464338777792 [label=AccumulateGrad]
	2464338779040 -> 2464338785232
	2464849020800 [label="encoder.features.denseblock2.denselayer12.norm2.weight
 (128)" fillcolor=lightblue]
	2464849020800 -> 2464338779040
	2464338779040 [label=AccumulateGrad]
	2464338780096 -> 2464338785232
	2464849019120 [label="encoder.features.denseblock2.denselayer12.norm2.bias
 (128)" fillcolor=lightblue]
	2464849019120 -> 2464338780096
	2464338780096 [label=AccumulateGrad]
	2464338782592 -> 2464339033728
	2464849020080 [label="encoder.features.denseblock2.denselayer12.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2464849020080 -> 2464338782592
	2464338782592 [label=AccumulateGrad]
	2464339027392 -> 2464339020912
	2464849019600 [label="encoder.features.transition2.norm.weight
 (512)" fillcolor=lightblue]
	2464849019600 -> 2464339027392
	2464339027392 [label=AccumulateGrad]
	2464339023264 -> 2464339020912
	2464849019440 [label="encoder.features.transition2.norm.bias
 (512)" fillcolor=lightblue]
	2464849019440 -> 2464339023264
	2464339023264 [label=AccumulateGrad]
	2464339024752 -> 2464339021392
	2464849020880 [label="encoder.features.transition2.conv.weight
 (256, 512, 1, 1)" fillcolor=lightblue]
	2464849020880 -> 2464339024752
	2464339024752 [label=AccumulateGrad]
	2464339033248 -> 2464339029984
	2464339033248 [label=ConvolutionBackward0]
	2464339019040 -> 2464339033248
	2464339019040 [label=ReluBackward0]
	2464339018752 -> 2464339019040
	2464339018752 [label=CudnnBatchNormBackward0]
	2464338778224 -> 2464339018752
	2464338778224 [label=ConvolutionBackward0]
	2464338776496 -> 2464338778224
	2464338776496 [label=ReluBackward0]
	2464338775632 -> 2464338776496
	2464338775632 [label=CudnnBatchNormBackward0]
	2464338775248 -> 2464338775632
	2464338775248 [label=CatBackward0]
	2464339029264 -> 2464338775248
	2464338774816 -> 2464338775632
	2464851975360 [label="encoder.features.denseblock3.denselayer1.norm1.weight
 (256)" fillcolor=lightblue]
	2464851975360 -> 2464338774816
	2464338774816 [label=AccumulateGrad]
	2464338775824 -> 2464338775632
	2464466073984 [label="encoder.features.denseblock3.denselayer1.norm1.bias
 (256)" fillcolor=lightblue]
	2464466073984 -> 2464338775824
	2464338775824 [label=AccumulateGrad]
	2464338780480 -> 2464338778224
	2464849022000 [label="encoder.features.denseblock3.denselayer1.conv1.weight
 (128, 256, 1, 1)" fillcolor=lightblue]
	2464849022000 -> 2464338780480
	2464338780480 [label=AccumulateGrad]
	2464338779472 -> 2464339018752
	2464849023440 [label="encoder.features.denseblock3.denselayer1.norm2.weight
 (128)" fillcolor=lightblue]
	2464849023440 -> 2464338779472
	2464338779472 [label=AccumulateGrad]
	2464338788208 -> 2464339018752
	2464849023280 [label="encoder.features.denseblock3.denselayer1.norm2.bias
 (128)" fillcolor=lightblue]
	2464849023280 -> 2464338788208
	2464338788208 [label=AccumulateGrad]
	2464339032192 -> 2464339033248
	2464849023920 [label="encoder.features.denseblock3.denselayer1.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2464849023920 -> 2464339032192
	2464339032192 [label=AccumulateGrad]
	2464339027440 -> 2464339029984
	2464339027440 [label=ConvolutionBackward0]
	2464339030608 -> 2464339027440
	2464339030608 [label=ReluBackward0]
	2464338777216 -> 2464339030608
	2464338777216 [label=CudnnBatchNormBackward0]
	2464338784992 -> 2464338777216
	2464338784992 [label=ConvolutionBackward0]
	2464338773808 -> 2464338784992
	2464338773808 [label=ReluBackward0]
	2464338772272 -> 2464338773808
	2464338772272 [label=CudnnBatchNormBackward0]
	2464338772608 -> 2464338772272
	2464338772608 [label=CatBackward0]
	2464339029264 -> 2464338772608
	2464339033248 -> 2464338772608
	2464338776400 -> 2464338772272
	2464849023600 [label="encoder.features.denseblock3.denselayer2.norm1.weight
 (288)" fillcolor=lightblue]
	2464849023600 -> 2464338776400
	2464338776400 [label=AccumulateGrad]
	2464338772320 -> 2464338772272
	2464849024080 [label="encoder.features.denseblock3.denselayer2.norm1.bias
 (288)" fillcolor=lightblue]
	2464849024080 -> 2464338772320
	2464338772320 [label=AccumulateGrad]
	2464338772944 -> 2464338784992
	2464849026640 [label="encoder.features.denseblock3.denselayer2.conv1.weight
 (128, 288, 1, 1)" fillcolor=lightblue]
	2464849026640 -> 2464338772944
	2464338772944 [label=AccumulateGrad]
	2464338778272 -> 2464338777216
	2464849026480 [label="encoder.features.denseblock3.denselayer2.norm2.weight
 (128)" fillcolor=lightblue]
	2464849026480 -> 2464338778272
	2464338778272 [label=AccumulateGrad]
	2464338777120 -> 2464338777216
	2464849026080 [label="encoder.features.denseblock3.denselayer2.norm2.bias
 (128)" fillcolor=lightblue]
	2464849026080 -> 2464338777120
	2464338777120 [label=AccumulateGrad]
	2464339029840 -> 2464339027440
	2464849026960 [label="encoder.features.denseblock3.denselayer2.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2464849026960 -> 2464339029840
	2464339029840 [label=AccumulateGrad]
	2464339026912 -> 2464339029984
	2464339026912 [label=ConvolutionBackward0]
	2464338773760 -> 2464339026912
	2464338773760 [label=ReluBackward0]
	2464338773568 -> 2464338773760
	2464338773568 [label=CudnnBatchNormBackward0]
	2464338786480 -> 2464338773568
	2464338786480 [label=ConvolutionBackward0]
	2464338785040 -> 2464338786480
	2464338785040 [label=ReluBackward0]
	2464338777408 -> 2464338785040
	2464338777408 [label=CudnnBatchNormBackward0]
	2464338787584 -> 2464338777408
	2464338787584 [label=CatBackward0]
	2464339029264 -> 2464338787584
	2464339033248 -> 2464338787584
	2464339027440 -> 2464338787584
	2464338781008 -> 2464338777408
	2464849027280 [label="encoder.features.denseblock3.denselayer3.norm1.weight
 (320)" fillcolor=lightblue]
	2464849027280 -> 2464338781008
	2464338781008 [label=AccumulateGrad]
	2464338775968 -> 2464338777408
	2464849028880 [label="encoder.features.denseblock3.denselayer3.norm1.bias
 (320)" fillcolor=lightblue]
	2464849028880 -> 2464338775968
	2464338775968 [label=AccumulateGrad]
	2464338782880 -> 2464338786480
	2464849030000 [label="encoder.features.denseblock3.denselayer3.conv1.weight
 (128, 320, 1, 1)" fillcolor=lightblue]
	2464849030000 -> 2464338782880
	2464338782880 [label=AccumulateGrad]
	2464338776208 -> 2464338773568
	2464849029440 [label="encoder.features.denseblock3.denselayer3.norm2.weight
 (128)" fillcolor=lightblue]
	2464849029440 -> 2464338776208
	2464338776208 [label=AccumulateGrad]
	2464338786528 -> 2464338773568
	2464849029120 [label="encoder.features.denseblock3.denselayer3.norm2.bias
 (128)" fillcolor=lightblue]
	2464849029120 -> 2464338786528
	2464338786528 [label=AccumulateGrad]
	2464338774720 -> 2464339026912
	2464849030880 [label="encoder.features.denseblock3.denselayer3.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2464849030880 -> 2464338774720
	2464338774720 [label=AccumulateGrad]
	2464339033488 -> 2464339029984
	2464339033488 [label=ConvolutionBackward0]
	2464338774144 -> 2464339033488
	2464338774144 [label=ReluBackward0]
	2464338780336 -> 2464338774144
	2464338780336 [label=CudnnBatchNormBackward0]
	2464338784224 -> 2464338780336
	2464338784224 [label=ConvolutionBackward0]
	2464338772992 -> 2464338784224
	2464338772992 [label=ReluBackward0]
	2464338776976 -> 2464338772992
	2464338776976 [label=CudnnBatchNormBackward0]
	2464338780048 -> 2464338776976
	2464338780048 [label=CatBackward0]
	2464339029264 -> 2464338780048
	2464339033248 -> 2464338780048
	2464339027440 -> 2464338780048
	2464339026912 -> 2464338780048
	2464338781296 -> 2464338776976
	2464849032480 [label="encoder.features.denseblock3.denselayer4.norm1.weight
 (352)" fillcolor=lightblue]
	2464849032480 -> 2464338781296
	2464338781296 [label=AccumulateGrad]
	2464338775344 -> 2464338776976
	2464849032320 [label="encoder.features.denseblock3.denselayer4.norm1.bias
 (352)" fillcolor=lightblue]
	2464849032320 -> 2464338775344
	2464338775344 [label=AccumulateGrad]
	2464338774576 -> 2464338784224
	2464849032720 [label="encoder.features.denseblock3.denselayer4.conv1.weight
 (128, 352, 1, 1)" fillcolor=lightblue]
	2464849032720 -> 2464338774576
	2464338774576 [label=AccumulateGrad]
	2464338786144 -> 2464338780336
	2464849033360 [label="encoder.features.denseblock3.denselayer4.norm2.weight
 (128)" fillcolor=lightblue]
	2464849033360 -> 2464338786144
	2464338786144 [label=AccumulateGrad]
	2464338773472 -> 2464338780336
	2464849034560 [label="encoder.features.denseblock3.denselayer4.norm2.bias
 (128)" fillcolor=lightblue]
	2464849034560 -> 2464338773472
	2464338773472 [label=AccumulateGrad]
	2464338780624 -> 2464339033488
	2464849035200 [label="encoder.features.denseblock3.denselayer4.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2464849035200 -> 2464338780624
	2464338780624 [label=AccumulateGrad]
	2464339018944 -> 2464339029984
	2464339018944 [label=ConvolutionBackward0]
	2464338785952 -> 2464339018944
	2464338785952 [label=ReluBackward0]
	2464338772128 -> 2464338785952
	2464338772128 [label=CudnnBatchNormBackward0]
	2464338784416 -> 2464338772128
	2464338784416 [label=ConvolutionBackward0]
	2464338786384 -> 2464338784416
	2464338786384 [label=ReluBackward0]
	2464338786240 -> 2464338786384
	2464338786240 [label=CudnnBatchNormBackward0]
	2464338776736 -> 2464338786240
	2464338776736 [label=CatBackward0]
	2464339029264 -> 2464338776736
	2464339033248 -> 2464338776736
	2464339027440 -> 2464338776736
	2464339026912 -> 2464338776736
	2464339033488 -> 2464338776736
	2464338776448 -> 2464338786240
	2464849035040 [label="encoder.features.denseblock3.denselayer5.norm1.weight
 (384)" fillcolor=lightblue]
	2464849035040 -> 2464338776448
	2464338776448 [label=AccumulateGrad]
	2464338785328 -> 2464338786240
	2464849034880 [label="encoder.features.denseblock3.denselayer5.norm1.bias
 (384)" fillcolor=lightblue]
	2464849034880 -> 2464338785328
	2464338785328 [label=AccumulateGrad]
	2464338783264 -> 2464338784416
	2464849033760 [label="encoder.features.denseblock3.denselayer5.conv1.weight
 (128, 384, 1, 1)" fillcolor=lightblue]
	2464849033760 -> 2464338783264
	2464338783264 [label=AccumulateGrad]
	2464338785472 -> 2464338772128
	2464849024000 [label="encoder.features.denseblock3.denselayer5.norm2.weight
 (128)" fillcolor=lightblue]
	2464849024000 -> 2464338785472
	2464338785472 [label=AccumulateGrad]
	2464338778320 -> 2464338772128
	2464849034960 [label="encoder.features.denseblock3.denselayer5.norm2.bias
 (128)" fillcolor=lightblue]
	2464849034960 -> 2464338778320
	2464338778320 [label=AccumulateGrad]
	2464338775584 -> 2464339018944
	2464596807584 [label="encoder.features.denseblock3.denselayer5.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2464596807584 -> 2464338775584
	2464338775584 [label=AccumulateGrad]
	2464339030464 -> 2464339029984
	2464339030464 [label=ConvolutionBackward0]
	2464338787104 -> 2464339030464
	2464338787104 [label=ReluBackward0]
	2464338788304 -> 2464338787104
	2464338788304 [label=CudnnBatchNormBackward0]
	2464338778416 -> 2464338788304
	2464338778416 [label=ConvolutionBackward0]
	2464338777072 -> 2464338778416
	2464338777072 [label=ReluBackward0]
	2464338784032 -> 2464338777072
	2464338784032 [label=CudnnBatchNormBackward0]
	2464338772224 -> 2464338784032
	2464338772224 [label=CatBackward0]
	2464339029264 -> 2464338772224
	2464339033248 -> 2464338772224
	2464339027440 -> 2464338772224
	2464339026912 -> 2464338772224
	2464339033488 -> 2464338772224
	2464339018944 -> 2464338772224
	2464338772512 -> 2464338784032
	2464596811264 [label="encoder.features.denseblock3.denselayer6.norm1.weight
 (416)" fillcolor=lightblue]
	2464596811264 -> 2464338772512
	2464338772512 [label=AccumulateGrad]
	2464338787248 -> 2464338784032
	2464596806784 [label="encoder.features.denseblock3.denselayer6.norm1.bias
 (416)" fillcolor=lightblue]
	2464596806784 -> 2464338787248
	2464338787248 [label=AccumulateGrad]
	2464338772848 -> 2464338778416
	2464596810624 [label="encoder.features.denseblock3.denselayer6.conv1.weight
 (128, 416, 1, 1)" fillcolor=lightblue]
	2464596810624 -> 2464338772848
	2464338772848 [label=AccumulateGrad]
	2464338787440 -> 2464338788304
	2464596811584 [label="encoder.features.denseblock3.denselayer6.norm2.weight
 (128)" fillcolor=lightblue]
	2464596811584 -> 2464338787440
	2464338787440 [label=AccumulateGrad]
	2464338780432 -> 2464338788304
	2464596812704 [label="encoder.features.denseblock3.denselayer6.norm2.bias
 (128)" fillcolor=lightblue]
	2464596812704 -> 2464338780432
	2464338780432 [label=AccumulateGrad]
	2464338782784 -> 2464339030464
	2464849675760 [label="encoder.features.denseblock3.denselayer6.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2464849675760 -> 2464338782784
	2464338782784 [label=AccumulateGrad]
	2464339022736 -> 2464339029984
	2464339022736 [label=ConvolutionBackward0]
	2464338778752 -> 2464339022736
	2464338778752 [label=ReluBackward0]
	2464338786096 -> 2464338778752
	2464338786096 [label=CudnnBatchNormBackward0]
	2464338772656 -> 2464338786096
	2464338772656 [label=ConvolutionBackward0]
	2464338773136 -> 2464338772656
	2464338773136 [label=ReluBackward0]
	2464338774048 -> 2464338773136
	2464338774048 [label=CudnnBatchNormBackward0]
	2464338774432 -> 2464338774048
	2464338774432 [label=CatBackward0]
	2464339029264 -> 2464338774432
	2464339033248 -> 2464338774432
	2464339027440 -> 2464338774432
	2464339026912 -> 2464338774432
	2464339033488 -> 2464338774432
	2464339018944 -> 2464338774432
	2464339030464 -> 2464338774432
	2464338774528 -> 2464338774048
	2464849682880 [label="encoder.features.denseblock3.denselayer7.norm1.weight
 (448)" fillcolor=lightblue]
	2464849682880 -> 2464338774528
	2464338774528 [label=AccumulateGrad]
	2464338773952 -> 2464338774048
	2464849681440 [label="encoder.features.denseblock3.denselayer7.norm1.bias
 (448)" fillcolor=lightblue]
	2464849681440 -> 2464338773952
	2464338773952 [label=AccumulateGrad]
	2464338777648 -> 2464338772656
	2464849683040 [label="encoder.features.denseblock3.denselayer7.conv1.weight
 (128, 448, 1, 1)" fillcolor=lightblue]
	2464849683040 -> 2464338777648
	2464338777648 [label=AccumulateGrad]
	2464338772704 -> 2464338786096
	2464849682800 [label="encoder.features.denseblock3.denselayer7.norm2.weight
 (128)" fillcolor=lightblue]
	2464849682800 -> 2464338772704
	2464338772704 [label=AccumulateGrad]
	2464338772080 -> 2464338786096
	2464849683120 [label="encoder.features.denseblock3.denselayer7.norm2.bias
 (128)" fillcolor=lightblue]
	2464849683120 -> 2464338772080
	2464338772080 [label=AccumulateGrad]
	2464338783936 -> 2464339022736
	2464849684720 [label="encoder.features.denseblock3.denselayer7.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2464849684720 -> 2464338783936
	2464338783936 [label=AccumulateGrad]
	2464339017792 -> 2464339029984
	2464339017792 [label=ConvolutionBackward0]
	2464338772752 -> 2464339017792
	2464338772752 [label=ReluBackward0]
	2464338772896 -> 2464338772752
	2464338772896 [label=CudnnBatchNormBackward0]
	2464338775008 -> 2464338772896
	2464338775008 [label=ConvolutionBackward0]
	2464338775488 -> 2464338775008
	2464338775488 [label=ReluBackward0]
	2464338776304 -> 2464338775488
	2464338776304 [label=CudnnBatchNormBackward0]
	2464338776784 -> 2464338776304
	2464338776784 [label=CatBackward0]
	2464339029264 -> 2464338776784
	2464339033248 -> 2464338776784
	2464339027440 -> 2464338776784
	2464339026912 -> 2464338776784
	2464339033488 -> 2464338776784
	2464339018944 -> 2464338776784
	2464339030464 -> 2464338776784
	2464339022736 -> 2464338776784
	2464338777168 -> 2464338776304
	2464849684640 [label="encoder.features.denseblock3.denselayer8.norm1.weight
 (480)" fillcolor=lightblue]
	2464849684640 -> 2464338777168
	2464338777168 [label=AccumulateGrad]
	2464338776160 -> 2464338776304
	2464849684400 [label="encoder.features.denseblock3.denselayer8.norm1.bias
 (480)" fillcolor=lightblue]
	2464849684400 -> 2464338776160
	2464338776160 [label=AccumulateGrad]
	2464338775680 -> 2464338775008
	2464849684880 [label="encoder.features.denseblock3.denselayer8.conv1.weight
 (128, 480, 1, 1)" fillcolor=lightblue]
	2464849684880 -> 2464338775680
	2464338775680 [label=AccumulateGrad]
	2464338775104 -> 2464338772896
	2464849685280 [label="encoder.features.denseblock3.denselayer8.norm2.weight
 (128)" fillcolor=lightblue]
	2464849685280 -> 2464338775104
	2464338775104 [label=AccumulateGrad]
	2464338774240 -> 2464338772896
	2464849686080 [label="encoder.features.denseblock3.denselayer8.norm2.bias
 (128)" fillcolor=lightblue]
	2464849686080 -> 2464338774240
	2464338774240 [label=AccumulateGrad]
	2464338772560 -> 2464339017792
	2464849686720 [label="encoder.features.denseblock3.denselayer8.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2464849686720 -> 2464338772560
	2464338772560 [label=AccumulateGrad]
	2464339032384 -> 2464339029984
	2464339032384 [label=ConvolutionBackward0]
	2464338775152 -> 2464339032384
	2464338775152 [label=ReluBackward0]
	2464338775296 -> 2464338775152
	2464338775296 [label=CudnnBatchNormBackward0]
	2464338777600 -> 2464338775296
	2464338777600 [label=ConvolutionBackward0]
	2464338777984 -> 2464338777600
	2464338777984 [label=ReluBackward0]
	2464338778368 -> 2464338777984
	2464338778368 [label=CudnnBatchNormBackward0]
	2464338778608 -> 2464338778368
	2464338778608 [label=CatBackward0]
	2464339029264 -> 2464338778608
	2464339033248 -> 2464338778608
	2464339027440 -> 2464338778608
	2464339026912 -> 2464338778608
	2464339033488 -> 2464338778608
	2464339018944 -> 2464338778608
	2464339030464 -> 2464338778608
	2464339022736 -> 2464338778608
	2464339017792 -> 2464338778608
	2464338778896 -> 2464338778368
	2464849686480 [label="encoder.features.denseblock3.denselayer9.norm1.weight
 (512)" fillcolor=lightblue]
	2464849686480 -> 2464338778896
	2464338778896 [label=AccumulateGrad]
	2464338778176 -> 2464338778368
	2464849686240 [label="encoder.features.denseblock3.denselayer9.norm1.bias
 (512)" fillcolor=lightblue]
	2464849686240 -> 2464338778176
	2464338778176 [label=AccumulateGrad]
	2464338778128 -> 2464338777600
	2464849687360 [label="encoder.features.denseblock3.denselayer9.conv1.weight
 (128, 512, 1, 1)" fillcolor=lightblue]
	2464849687360 -> 2464338778128
	2464338778128 [label=AccumulateGrad]
	2464338777696 -> 2464338775296
	2464849688400 [label="encoder.features.denseblock3.denselayer9.norm2.weight
 (128)" fillcolor=lightblue]
	2464849688400 -> 2464338777696
	2464338777696 [label=AccumulateGrad]
	2464338776544 -> 2464338775296
	2464849688240 [label="encoder.features.denseblock3.denselayer9.norm2.bias
 (128)" fillcolor=lightblue]
	2464849688240 -> 2464338776544
	2464338776544 [label=AccumulateGrad]
	2464338774768 -> 2464339032384
	2464849688640 [label="encoder.features.denseblock3.denselayer9.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2464849688640 -> 2464338774768
	2464338774768 [label=AccumulateGrad]
	2464339027200 -> 2464339029984
	2464339027200 [label=ConvolutionBackward0]
	2464338777840 -> 2464339027200
	2464338777840 [label=ReluBackward0]
	2464338777936 -> 2464338777840
	2464338777936 [label=CudnnBatchNormBackward0]
	2464338779088 -> 2464338777936
	2464338779088 [label=ConvolutionBackward0]
	2464338779664 -> 2464338779088
	2464338779664 [label=ReluBackward0]
	2464338780240 -> 2464338779664
	2464338780240 [label=CudnnBatchNormBackward0]
	2464338780720 -> 2464338780240
	2464338780720 [label=CatBackward0]
	2464339029264 -> 2464338780720
	2464339033248 -> 2464338780720
	2464339027440 -> 2464338780720
	2464339026912 -> 2464338780720
	2464339033488 -> 2464338780720
	2464339018944 -> 2464338780720
	2464339030464 -> 2464338780720
	2464339022736 -> 2464338780720
	2464339017792 -> 2464338780720
	2464339032384 -> 2464338780720
	2464338780768 -> 2464338780240
	2464849688480 [label="encoder.features.denseblock3.denselayer10.norm1.weight
 (544)" fillcolor=lightblue]
	2464849688480 -> 2464338780768
	2464338780768 [label=AccumulateGrad]
	2464338779952 -> 2464338780240
	2464849688720 [label="encoder.features.denseblock3.denselayer10.norm1.bias
 (544)" fillcolor=lightblue]
	2464849688720 -> 2464338779952
	2464338779952 [label=AccumulateGrad]
	2464338779808 -> 2464338779088
	2464849690320 [label="encoder.features.denseblock3.denselayer10.conv1.weight
 (128, 544, 1, 1)" fillcolor=lightblue]
	2464849690320 -> 2464338779808
	2464338779808 [label=AccumulateGrad]
	2464338779232 -> 2464338777936
	2464849690240 [label="encoder.features.denseblock3.denselayer10.norm2.weight
 (128)" fillcolor=lightblue]
	2464849690240 -> 2464338779232
	2464338779232 [label=AccumulateGrad]
	2464338778560 -> 2464338777936
	2464849690000 [label="encoder.features.denseblock3.denselayer10.norm2.bias
 (128)" fillcolor=lightblue]
	2464849690000 -> 2464338778560
	2464338778560 [label=AccumulateGrad]
	2464338777504 -> 2464339027200
	2464849690480 [label="encoder.features.denseblock3.denselayer10.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2464849690480 -> 2464338777504
	2464338777504 [label=AccumulateGrad]
	2464339030272 -> 2464339029984
	2464339030272 [label=ConvolutionBackward0]
	2464338779328 -> 2464339030272
	2464338779328 [label=ReluBackward0]
	2464338779520 -> 2464338779328
	2464338779520 [label=CudnnBatchNormBackward0]
	2464338780960 -> 2464338779520
	2464338780960 [label=ConvolutionBackward0]
	2464338781632 -> 2464338780960
	2464338781632 [label=ReluBackward0]
	2464338781872 -> 2464338781632
	2464338781872 [label=CudnnBatchNormBackward0]
	2464338782160 -> 2464338781872
	2464338782160 [label=CatBackward0]
	2464339029264 -> 2464338782160
	2464339033248 -> 2464338782160
	2464339027440 -> 2464338782160
	2464339026912 -> 2464338782160
	2464339033488 -> 2464338782160
	2464339018944 -> 2464338782160
	2464339030464 -> 2464338782160
	2464339022736 -> 2464338782160
	2464339017792 -> 2464338782160
	2464339032384 -> 2464338782160
	2464339027200 -> 2464338782160
	2464338782208 -> 2464338781872
	2464849674560 [label="encoder.features.denseblock3.denselayer11.norm1.weight
 (576)" fillcolor=lightblue]
	2464849674560 -> 2464338782208
	2464338782208 [label=AccumulateGrad]
	2464338781824 -> 2464338781872
	2464849676000 [label="encoder.features.denseblock3.denselayer11.norm1.bias
 (576)" fillcolor=lightblue]
	2464849676000 -> 2464338781824
	2464338781824 [label=AccumulateGrad]
	2464338781776 -> 2464338780960
	2464849676960 [label="encoder.features.denseblock3.denselayer11.conv1.weight
 (128, 576, 1, 1)" fillcolor=lightblue]
	2464849676960 -> 2464338781776
	2464338781776 [label=AccumulateGrad]
	2464338781056 -> 2464338779520
	2464849677120 [label="encoder.features.denseblock3.denselayer11.norm2.weight
 (128)" fillcolor=lightblue]
	2464849677120 -> 2464338781056
	2464338781056 [label=AccumulateGrad]
	2464338780672 -> 2464338779520
	2464849676320 [label="encoder.features.denseblock3.denselayer11.norm2.bias
 (128)" fillcolor=lightblue]
	2464849676320 -> 2464338780672
	2464338780672 [label=AccumulateGrad]
	2464338778992 -> 2464339030272
	2464849677760 [label="encoder.features.denseblock3.denselayer11.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2464849677760 -> 2464338778992
	2464338778992 [label=AccumulateGrad]
	2464339030032 -> 2464339029984
	2464339030032 [label=ConvolutionBackward0]
	2464338781104 -> 2464339030032
	2464338781104 [label=ReluBackward0]
	2464338781440 -> 2464338781104
	2464338781440 [label=CudnnBatchNormBackward0]
	2464338782400 -> 2464338781440
	2464338782400 [label=ConvolutionBackward0]
	2464338783168 -> 2464338782400
	2464338783168 [label=ReluBackward0]
	2464338783600 -> 2464338783168
	2464338783600 [label=CudnnBatchNormBackward0]
	2464338783984 -> 2464338783600
	2464338783984 [label=CatBackward0]
	2464339029264 -> 2464338783984
	2464339033248 -> 2464338783984
	2464339027440 -> 2464338783984
	2464339026912 -> 2464338783984
	2464339033488 -> 2464338783984
	2464339018944 -> 2464338783984
	2464339030464 -> 2464338783984
	2464339022736 -> 2464338783984
	2464339017792 -> 2464338783984
	2464339032384 -> 2464338783984
	2464339027200 -> 2464338783984
	2464339030272 -> 2464338783984
	2464338784080 -> 2464338783600
	2464849679200 [label="encoder.features.denseblock3.denselayer12.norm1.weight
 (608)" fillcolor=lightblue]
	2464849679200 -> 2464338784080
	2464338784080 [label=AccumulateGrad]
	2464338783456 -> 2464338783600
	2464849679040 [label="encoder.features.denseblock3.denselayer12.norm1.bias
 (608)" fillcolor=lightblue]
	2464849679040 -> 2464338783456
	2464338783456 [label=AccumulateGrad]
	2464338783360 -> 2464338782400
	2464849679680 [label="encoder.features.denseblock3.denselayer12.conv1.weight
 (128, 608, 1, 1)" fillcolor=lightblue]
	2464849679680 -> 2464338783360
	2464338783360 [label=AccumulateGrad]
	2464338782496 -> 2464338781440
	2464849679520 [label="encoder.features.denseblock3.denselayer12.norm2.weight
 (128)" fillcolor=lightblue]
	2464849679520 -> 2464338782496
	2464338782496 [label=AccumulateGrad]
	2464338782016 -> 2464338781440
	2464849679840 [label="encoder.features.denseblock3.denselayer12.norm2.bias
 (128)" fillcolor=lightblue]
	2464849679840 -> 2464338782016
	2464338782016 [label=AccumulateGrad]
	2464338780864 -> 2464339030032
	2464849682640 [label="encoder.features.denseblock3.denselayer12.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2464849682640 -> 2464338780864
	2464338780864 [label=AccumulateGrad]
	2464339032528 -> 2464339029984
	2464339032528 [label=ConvolutionBackward0]
	2464338782976 -> 2464339032528
	2464338782976 [label=ReluBackward0]
	2464338783072 -> 2464338782976
	2464338783072 [label=CudnnBatchNormBackward0]
	2464338784368 -> 2464338783072
	2464338784368 [label=ConvolutionBackward0]
	2464338784944 -> 2464338784368
	2464338784944 [label=ReluBackward0]
	2464338785760 -> 2464338784944
	2464338785760 [label=CudnnBatchNormBackward0]
	2464338786192 -> 2464338785760
	2464338786192 [label=CatBackward0]
	2464339029264 -> 2464338786192
	2464339033248 -> 2464338786192
	2464339027440 -> 2464338786192
	2464339026912 -> 2464338786192
	2464339033488 -> 2464338786192
	2464339018944 -> 2464338786192
	2464339030464 -> 2464338786192
	2464339022736 -> 2464338786192
	2464339017792 -> 2464338786192
	2464339032384 -> 2464338786192
	2464339027200 -> 2464338786192
	2464339030272 -> 2464338786192
	2464339030032 -> 2464338786192
	2464338786336 -> 2464338785760
	2464849682480 [label="encoder.features.denseblock3.denselayer13.norm1.weight
 (640)" fillcolor=lightblue]
	2464849682480 -> 2464338786336
	2464338786336 [label=AccumulateGrad]
	2464338785568 -> 2464338785760
	2464849682000 [label="encoder.features.denseblock3.denselayer13.norm1.bias
 (640)" fillcolor=lightblue]
	2464849682000 -> 2464338785568
	2464338785568 [label=AccumulateGrad]
	2464338785136 -> 2464338784368
	2464849680240 [label="encoder.features.denseblock3.denselayer13.conv1.weight
 (128, 640, 1, 1)" fillcolor=lightblue]
	2464849680240 -> 2464338785136
	2464338785136 [label=AccumulateGrad]
	2464338784752 -> 2464338783072
	2464849862944 [label="encoder.features.denseblock3.denselayer13.norm2.weight
 (128)" fillcolor=lightblue]
	2464849862944 -> 2464338784752
	2464338784752 [label=AccumulateGrad]
	2464338783792 -> 2464338783072
	2464849863424 [label="encoder.features.denseblock3.denselayer13.norm2.bias
 (128)" fillcolor=lightblue]
	2464849863424 -> 2464338783792
	2464338783792 [label=AccumulateGrad]
	2464338782256 -> 2464339032528
	2464849863904 [label="encoder.features.denseblock3.denselayer13.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2464849863904 -> 2464338782256
	2464338782256 [label=AccumulateGrad]
	2464339027584 -> 2464339029984
	2464339027584 [label=ConvolutionBackward0]
	2464338784848 -> 2464339027584
	2464338784848 [label=ReluBackward0]
	2464338784896 -> 2464338784848
	2464338784896 [label=CudnnBatchNormBackward0]
	2464338786576 -> 2464338784896
	2464338786576 [label=ConvolutionBackward0]
	2464338787008 -> 2464338786576
	2464338787008 [label=ReluBackward0]
	2464338787632 -> 2464338787008
	2464338787632 [label=CudnnBatchNormBackward0]
	2464338787728 -> 2464338787632
	2464338787728 [label=CatBackward0]
	2464339029264 -> 2464338787728
	2464339033248 -> 2464338787728
	2464339027440 -> 2464338787728
	2464339026912 -> 2464338787728
	2464339033488 -> 2464338787728
	2464339018944 -> 2464338787728
	2464339030464 -> 2464338787728
	2464339022736 -> 2464338787728
	2464339017792 -> 2464338787728
	2464339032384 -> 2464338787728
	2464339027200 -> 2464338787728
	2464339030272 -> 2464338787728
	2464339030032 -> 2464338787728
	2464339032528 -> 2464338787728
	2464338787872 -> 2464338787632
	2464849863664 [label="encoder.features.denseblock3.denselayer14.norm1.weight
 (672)" fillcolor=lightblue]
	2464849863664 -> 2464338787872
	2464338787872 [label=AccumulateGrad]
	2464338787344 -> 2464338787632
	2464849863584 [label="encoder.features.denseblock3.denselayer14.norm1.bias
 (672)" fillcolor=lightblue]
	2464849863584 -> 2464338787344
	2464338787344 [label=AccumulateGrad]
	2464338787056 -> 2464338786576
	2464849864064 [label="encoder.features.denseblock3.denselayer14.conv1.weight
 (128, 672, 1, 1)" fillcolor=lightblue]
	2464849864064 -> 2464338787056
	2464338787056 [label=AccumulateGrad]
	2464338786672 -> 2464338784896
	2464849864224 [label="encoder.features.denseblock3.denselayer14.norm2.weight
 (128)" fillcolor=lightblue]
	2464849864224 -> 2464338786672
	2464338786672 [label=AccumulateGrad]
	2464338785904 -> 2464338784896
	2464849855264 [label="encoder.features.denseblock3.denselayer14.norm2.bias
 (128)" fillcolor=lightblue]
	2464849855264 -> 2464338785904
	2464338785904 [label=AccumulateGrad]
	2464338784320 -> 2464339027584
	2464849855744 [label="encoder.features.denseblock3.denselayer14.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2464849855744 -> 2464338784320
	2464338784320 [label=AccumulateGrad]
	2464339032912 -> 2464339029984
	2464339032912 [label=ConvolutionBackward0]
	2464338786720 -> 2464339032912
	2464338786720 [label=ReluBackward0]
	2464338786864 -> 2464338786720
	2464338786864 [label=CudnnBatchNormBackward0]
	2464338788112 -> 2464338786864
	2464338788112 [label=ConvolutionBackward0]
	2464338774192 -> 2464338788112
	2464338774192 [label=ReluBackward0]
	2464338772368 -> 2464338774192
	2464338772368 [label=CudnnBatchNormBackward0]
	2464338772416 -> 2464338772368
	2464338772416 [label=CatBackward0]
	2464339029264 -> 2464338772416
	2464339033248 -> 2464338772416
	2464339027440 -> 2464338772416
	2464339026912 -> 2464338772416
	2464339033488 -> 2464338772416
	2464339018944 -> 2464338772416
	2464339030464 -> 2464338772416
	2464339022736 -> 2464338772416
	2464339017792 -> 2464338772416
	2464339032384 -> 2464338772416
	2464339027200 -> 2464338772416
	2464339030272 -> 2464338772416
	2464339030032 -> 2464338772416
	2464339032528 -> 2464338772416
	2464339027584 -> 2464338772416
	2464338781152 -> 2464338772368
	2464849855504 [label="encoder.features.denseblock3.denselayer15.norm1.weight
 (704)" fillcolor=lightblue]
	2464849855504 -> 2464338781152
	2464338781152 [label=AccumulateGrad]
	2464338773424 -> 2464338772368
	2464849855344 [label="encoder.features.denseblock3.denselayer15.norm1.bias
 (704)" fillcolor=lightblue]
	2464849855344 -> 2464338773424
	2464338773424 [label=AccumulateGrad]
	2464338781920 -> 2464338788112
	2464849856384 [label="encoder.features.denseblock3.denselayer15.conv1.weight
 (128, 704, 1, 1)" fillcolor=lightblue]
	2464849856384 -> 2464338781920
	2464338781920 [label=AccumulateGrad]
	2464338781968 -> 2464338786864
	2464849857344 [label="encoder.features.denseblock3.denselayer15.norm2.weight
 (128)" fillcolor=lightblue]
	2464849857344 -> 2464338781968
	2464338781968 [label=AccumulateGrad]
	2464338787680 -> 2464338786864
	2464849857104 [label="encoder.features.denseblock3.denselayer15.norm2.bias
 (128)" fillcolor=lightblue]
	2464849857104 -> 2464338787680
	2464338787680 [label=AccumulateGrad]
	2464338786432 -> 2464339032912
	2464849857584 [label="encoder.features.denseblock3.denselayer15.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2464849857584 -> 2464338786432
	2464338786432 [label=AccumulateGrad]
	2464339022832 -> 2464339029984
	2464339022832 [label=ConvolutionBackward0]
	2464338786768 -> 2464339022832
	2464338786768 [label=ReluBackward0]
	2464338778800 -> 2464338786768
	2464338778800 [label=CudnnBatchNormBackward0]
	2464338785808 -> 2464338778800
	2464338785808 [label=ConvolutionBackward0]
	2464338780576 -> 2464338785808
	2464338780576 [label=ReluBackward0]
	2464338775728 -> 2464338780576
	2464338775728 [label=CudnnBatchNormBackward0]
	2464338773376 -> 2464338775728
	2464338773376 [label=CatBackward0]
	2464339029264 -> 2464338773376
	2464339033248 -> 2464338773376
	2464339027440 -> 2464338773376
	2464339026912 -> 2464338773376
	2464339033488 -> 2464338773376
	2464339018944 -> 2464338773376
	2464339030464 -> 2464338773376
	2464339022736 -> 2464338773376
	2464339017792 -> 2464338773376
	2464339032384 -> 2464338773376
	2464339027200 -> 2464338773376
	2464339030272 -> 2464338773376
	2464339030032 -> 2464338773376
	2464339032528 -> 2464338773376
	2464339027584 -> 2464338773376
	2464339032912 -> 2464338773376
	2464338772032 -> 2464338775728
	2464849857504 [label="encoder.features.denseblock3.denselayer16.norm1.weight
 (736)" fillcolor=lightblue]
	2464849857504 -> 2464338772032
	2464338772032 [label=AccumulateGrad]
	2464338777360 -> 2464338775728
	2464849857744 [label="encoder.features.denseblock3.denselayer16.norm1.bias
 (736)" fillcolor=lightblue]
	2464849857744 -> 2464338777360
	2464338777360 [label=AccumulateGrad]
	2464338778848 -> 2464338785808
	2464849859344 [label="encoder.features.denseblock3.denselayer16.conv1.weight
 (128, 736, 1, 1)" fillcolor=lightblue]
	2464849859344 -> 2464338778848
	2464338778848 [label=AccumulateGrad]
	2464338784704 -> 2464338778800
	2464849859184 [label="encoder.features.denseblock3.denselayer16.norm2.weight
 (128)" fillcolor=lightblue]
	2464849859184 -> 2464338784704
	2464338784704 [label=AccumulateGrad]
	2464338774960 -> 2464338778800
	2464849858944 [label="encoder.features.denseblock3.denselayer16.norm2.bias
 (128)" fillcolor=lightblue]
	2464849858944 -> 2464338774960
	2464338774960 [label=AccumulateGrad]
	2464338787920 -> 2464339022832
	2464849859424 [label="encoder.features.denseblock3.denselayer16.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2464849859424 -> 2464338787920
	2464338787920 [label=AccumulateGrad]
	2464339029552 -> 2464339029984
	2464339029552 [label=ConvolutionBackward0]
	2464338783120 -> 2464339029552
	2464338783120 [label=ReluBackward0]
	2464338781680 -> 2464338783120
	2464338781680 [label=CudnnBatchNormBackward0]
	2464338779424 -> 2464338781680
	2464338779424 [label=ConvolutionBackward0]
	2464338782304 -> 2464338779424
	2464338782304 [label=ReluBackward0]
	2464338774384 -> 2464338782304
	2464338774384 [label=CudnnBatchNormBackward0]
	2464338783216 -> 2464338774384
	2464338783216 [label=CatBackward0]
	2464339029264 -> 2464338783216
	2464339033248 -> 2464338783216
	2464339027440 -> 2464338783216
	2464339026912 -> 2464338783216
	2464339033488 -> 2464338783216
	2464339018944 -> 2464338783216
	2464339030464 -> 2464338783216
	2464339022736 -> 2464338783216
	2464339017792 -> 2464338783216
	2464339032384 -> 2464338783216
	2464339027200 -> 2464338783216
	2464339030272 -> 2464338783216
	2464339030032 -> 2464338783216
	2464339032528 -> 2464338783216
	2464339027584 -> 2464338783216
	2464339032912 -> 2464338783216
	2464339022832 -> 2464338783216
	2464338785184 -> 2464338774384
	2464849859664 [label="encoder.features.denseblock3.denselayer17.norm1.weight
 (768)" fillcolor=lightblue]
	2464849859664 -> 2464338785184
	2464338785184 [label=AccumulateGrad]
	2464338776112 -> 2464338774384
	2464849860704 [label="encoder.features.denseblock3.denselayer17.norm1.bias
 (768)" fillcolor=lightblue]
	2464849860704 -> 2464338776112
	2464338776112 [label=AccumulateGrad]
	2464338785664 -> 2464338779424
	2464849861184 [label="encoder.features.denseblock3.denselayer17.conv1.weight
 (128, 768, 1, 1)" fillcolor=lightblue]
	2464849861184 -> 2464338785664
	2464338785664 [label=AccumulateGrad]
	2464338783024 -> 2464338781680
	2464849860944 [label="encoder.features.denseblock3.denselayer17.norm2.weight
 (128)" fillcolor=lightblue]
	2464849860944 -> 2464338783024
	2464338783024 [label=AccumulateGrad]
	2464338774864 -> 2464338781680
	2464849860784 [label="encoder.features.denseblock3.denselayer17.norm2.bias
 (128)" fillcolor=lightblue]
	2464849860784 -> 2464338774864
	2464338774864 [label=AccumulateGrad]
	2464338787488 -> 2464339029552
	2464849861824 [label="encoder.features.denseblock3.denselayer17.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2464849861824 -> 2464338787488
	2464338787488 [label=AccumulateGrad]
	2464339021344 -> 2464339029984
	2464339021344 [label=ConvolutionBackward0]
	2464338782352 -> 2464339021344
	2464338782352 [label=ReluBackward0]
	2464338774000 -> 2464338782352
	2464338774000 [label=CudnnBatchNormBackward0]
	2464338788160 -> 2464338774000
	2464338788160 [label=ConvolutionBackward0]
	2464338773904 -> 2464338788160
	2464338773904 [label=ReluBackward0]
	2464338773232 -> 2464338773904
	2464338773232 [label=CudnnBatchNormBackward0]
	2464338773520 -> 2464338773232
	2464338773520 [label=CatBackward0]
	2464339029264 -> 2464338773520
	2464339033248 -> 2464338773520
	2464339027440 -> 2464338773520
	2464339026912 -> 2464338773520
	2464339033488 -> 2464338773520
	2464339018944 -> 2464338773520
	2464339030464 -> 2464338773520
	2464339022736 -> 2464338773520
	2464339017792 -> 2464338773520
	2464339032384 -> 2464338773520
	2464339027200 -> 2464338773520
	2464339030272 -> 2464338773520
	2464339030032 -> 2464338773520
	2464339032528 -> 2464338773520
	2464339027584 -> 2464338773520
	2464339032912 -> 2464338773520
	2464339022832 -> 2464338773520
	2464339029552 -> 2464338773520
	2464338773664 -> 2464338773232
	2464849862784 [label="encoder.features.denseblock3.denselayer18.norm1.weight
 (800)" fillcolor=lightblue]
	2464849862784 -> 2464338773664
	2464338773664 [label=AccumulateGrad]
	2464338780192 -> 2464338773232
	2464849862544 [label="encoder.features.denseblock3.denselayer18.norm1.bias
 (800)" fillcolor=lightblue]
	2464849862544 -> 2464338780192
	2464338780192 [label=AccumulateGrad]
	2464338776256 -> 2464338788160
	2464849864944 [label="encoder.features.denseblock3.denselayer18.conv1.weight
 (128, 800, 1, 1)" fillcolor=lightblue]
	2464849864944 -> 2464338776256
	2464338776256 [label=AccumulateGrad]
	2464338775920 -> 2464338774000
	2463245236288 [label="encoder.features.denseblock3.denselayer18.norm2.weight
 (128)" fillcolor=lightblue]
	2463245236288 -> 2464338775920
	2464338775920 [label=AccumulateGrad]
	2464338778464 -> 2464338774000
	2463245231168 [label="encoder.features.denseblock3.denselayer18.norm2.bias
 (128)" fillcolor=lightblue]
	2463245231168 -> 2464338778464
	2464338778464 [label=AccumulateGrad]
	2464338784608 -> 2464339021344
	2463245234768 [label="encoder.features.denseblock3.denselayer18.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2463245234768 -> 2464338784608
	2464338784608 [label=AccumulateGrad]
	2464339030512 -> 2464339029984
	2464339030512 [label=ConvolutionBackward0]
	2464338785424 -> 2464339030512
	2464338785424 [label=ReluBackward0]
	2464338778032 -> 2464338785424
	2464338778032 [label=CudnnBatchNormBackward0]
	2464338774288 -> 2464338778032
	2464338774288 [label=ConvolutionBackward0]
	2464338782736 -> 2464338774288
	2464338782736 [label=ReluBackward0]
	2464338780144 -> 2464338782736
	2464338780144 [label=CudnnBatchNormBackward0]
	2464338776592 -> 2464338780144
	2464338776592 [label=CatBackward0]
	2464339029264 -> 2464338776592
	2464339033248 -> 2464338776592
	2464339027440 -> 2464338776592
	2464339026912 -> 2464338776592
	2464339033488 -> 2464338776592
	2464339018944 -> 2464338776592
	2464339030464 -> 2464338776592
	2464339022736 -> 2464338776592
	2464339017792 -> 2464338776592
	2464339032384 -> 2464338776592
	2464339027200 -> 2464338776592
	2464339030272 -> 2464338776592
	2464339030032 -> 2464338776592
	2464339032528 -> 2464338776592
	2464339027584 -> 2464338776592
	2464339032912 -> 2464338776592
	2464339022832 -> 2464338776592
	2464339029552 -> 2464338776592
	2464339021344 -> 2464338776592
	2464338776832 -> 2464338780144
	2463245236608 [label="encoder.features.denseblock3.denselayer19.norm1.weight
 (832)" fillcolor=lightblue]
	2463245236608 -> 2464338776832
	2464338776832 [label=AccumulateGrad]
	2464338775776 -> 2464338780144
	2463245236928 [label="encoder.features.denseblock3.denselayer19.norm1.bias
 (832)" fillcolor=lightblue]
	2463245236928 -> 2464338775776
	2464338775776 [label=AccumulateGrad]
	2464338787152 -> 2464338774288
	2463245236208 [label="encoder.features.denseblock3.denselayer19.conv1.weight
 (128, 832, 1, 1)" fillcolor=lightblue]
	2463245236208 -> 2464338787152
	2464338787152 [label=AccumulateGrad]
	2464338772800 -> 2464338778032
	2463245235168 [label="encoder.features.denseblock3.denselayer19.norm2.weight
 (128)" fillcolor=lightblue]
	2463245235168 -> 2464338772800
	2464338772800 [label=AccumulateGrad]
	2464338773184 -> 2464338778032
	2463245231248 [label="encoder.features.denseblock3.denselayer19.norm2.bias
 (128)" fillcolor=lightblue]
	2463245231248 -> 2464338773184
	2464338773184 [label=AccumulateGrad]
	2464338781392 -> 2464339030512
	2463245224608 [label="encoder.features.denseblock3.denselayer19.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2463245224608 -> 2464338781392
	2464338781392 [label=AccumulateGrad]
	2464339031616 -> 2464339029984
	2464339031616 [label=ConvolutionBackward0]
	2464338774912 -> 2464339031616
	2464338774912 [label=ReluBackward0]
	2464338775200 -> 2464338774912
	2464338775200 [label=CudnnBatchNormBackward0]
	2464338777456 -> 2464338775200
	2464338777456 [label=ConvolutionBackward0]
	2464338778656 -> 2464338777456
	2464338778656 [label=ReluBackward0]
	2464338779376 -> 2464338778656
	2464338779376 [label=CudnnBatchNormBackward0]
	2464338779712 -> 2464338779376
	2464338779712 [label=CatBackward0]
	2464339029264 -> 2464338779712
	2464339033248 -> 2464338779712
	2464339027440 -> 2464338779712
	2464339026912 -> 2464338779712
	2464339033488 -> 2464338779712
	2464339018944 -> 2464338779712
	2464339030464 -> 2464338779712
	2464339022736 -> 2464338779712
	2464339017792 -> 2464338779712
	2464339032384 -> 2464338779712
	2464339027200 -> 2464338779712
	2464339030272 -> 2464338779712
	2464339030032 -> 2464338779712
	2464339032528 -> 2464338779712
	2464339027584 -> 2464338779712
	2464339032912 -> 2464338779712
	2464339022832 -> 2464338779712
	2464339029552 -> 2464338779712
	2464339021344 -> 2464338779712
	2464339030512 -> 2464338779712
	2464338782640 -> 2464338779376
	2463245234848 [label="encoder.features.denseblock3.denselayer20.norm1.weight
 (864)" fillcolor=lightblue]
	2463245234848 -> 2464338782640
	2464338782640 [label=AccumulateGrad]
	2464338779280 -> 2464338779376
	2463245224048 [label="encoder.features.denseblock3.denselayer20.norm1.bias
 (864)" fillcolor=lightblue]
	2463245224048 -> 2464338779280
	2464338779280 [label=AccumulateGrad]
	2464338778704 -> 2464338777456
	2463245230368 [label="encoder.features.denseblock3.denselayer20.conv1.weight
 (128, 864, 1, 1)" fillcolor=lightblue]
	2463245230368 -> 2464338778704
	2464338778704 [label=AccumulateGrad]
	2464338777744 -> 2464338775200
	2463245229968 [label="encoder.features.denseblock3.denselayer20.norm2.weight
 (128)" fillcolor=lightblue]
	2463245229968 -> 2464338777744
	2464338777744 [label=AccumulateGrad]
	2464338773280 -> 2464338775200
	2463245232608 [label="encoder.features.denseblock3.denselayer20.norm2.bias
 (128)" fillcolor=lightblue]
	2463245232608 -> 2464338773280
	2464338773280 [label=AccumulateGrad]
	2464338774096 -> 2464339031616
	2463245236848 [label="encoder.features.denseblock3.denselayer20.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2463245236848 -> 2464338774096
	2464338774096 [label=AccumulateGrad]
	2464339027728 -> 2464339029984
	2464339027728 [label=ConvolutionBackward0]
	2464338776064 -> 2464339027728
	2464338776064 [label=ReluBackward0]
	2464338776640 -> 2464338776064
	2464338776640 [label=CudnnBatchNormBackward0]
	2464338780816 -> 2464338776640
	2464338780816 [label=ConvolutionBackward0]
	2464338787392 -> 2464338780816
	2464338787392 [label=ReluBackward0]
	2464338778944 -> 2464338787392
	2464338778944 [label=CudnnBatchNormBackward0]
	2464338787200 -> 2464338778944
	2464338787200 [label=CatBackward0]
	2464339029264 -> 2464338787200
	2464339033248 -> 2464338787200
	2464339027440 -> 2464338787200
	2464339026912 -> 2464338787200
	2464339033488 -> 2464338787200
	2464339018944 -> 2464338787200
	2464339030464 -> 2464338787200
	2464339022736 -> 2464338787200
	2464339017792 -> 2464338787200
	2464339032384 -> 2464338787200
	2464339027200 -> 2464338787200
	2464339030272 -> 2464338787200
	2464339030032 -> 2464338787200
	2464339032528 -> 2464338787200
	2464339027584 -> 2464338787200
	2464339032912 -> 2464338787200
	2464339022832 -> 2464338787200
	2464339029552 -> 2464338787200
	2464339021344 -> 2464338787200
	2464339030512 -> 2464338787200
	2464339031616 -> 2464338787200
	2464338783696 -> 2464338778944
	2463245228448 [label="encoder.features.denseblock3.denselayer21.norm1.weight
 (896)" fillcolor=lightblue]
	2463245228448 -> 2464338783696
	2464338783696 [label=AccumulateGrad]
	2464338782544 -> 2464338778944
	2463245229568 [label="encoder.features.denseblock3.denselayer21.norm1.bias
 (896)" fillcolor=lightblue]
	2463245229568 -> 2464338782544
	2464338782544 [label=AccumulateGrad]
	2464338787776 -> 2464338780816
	2463245227408 [label="encoder.features.denseblock3.denselayer21.conv1.weight
 (128, 896, 1, 1)" fillcolor=lightblue]
	2463245227408 -> 2464338787776
	2464338787776 [label=AccumulateGrad]
	2464338784656 -> 2464338776640
	2463245235808 [label="encoder.features.denseblock3.denselayer21.norm2.weight
 (128)" fillcolor=lightblue]
	2463245235808 -> 2464338784656
	2464338784656 [label=AccumulateGrad]
	2464338780912 -> 2464338776640
	2463245231648 [label="encoder.features.denseblock3.denselayer21.norm2.bias
 (128)" fillcolor=lightblue]
	2463245231648 -> 2464338780912
	2464338780912 [label=AccumulateGrad]
	2464338775056 -> 2464339027728
	2463245224528 [label="encoder.features.denseblock3.denselayer21.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2463245224528 -> 2464338775056
	2464338775056 [label=AccumulateGrad]
	2464339028544 -> 2464339029984
	2464339028544 [label=ConvolutionBackward0]
	2464338781200 -> 2464339028544
	2464338781200 [label=ReluBackward0]
	2464338781536 -> 2464338781200
	2464338781536 [label=CudnnBatchNormBackward0]
	2464338775440 -> 2464338781536
	2464338775440 [label=ConvolutionBackward0]
	2464338785376 -> 2464338775440
	2464338785376 [label=ReluBackward0]
	2464338774672 -> 2464338785376
	2464338774672 [label=CudnnBatchNormBackward0]
	2464338773040 -> 2464338774672
	2464338773040 [label=CatBackward0]
	2464339029264 -> 2464338773040
	2464339033248 -> 2464338773040
	2464339027440 -> 2464338773040
	2464339026912 -> 2464338773040
	2464339033488 -> 2464338773040
	2464339018944 -> 2464338773040
	2464339030464 -> 2464338773040
	2464339022736 -> 2464338773040
	2464339017792 -> 2464338773040
	2464339032384 -> 2464338773040
	2464339027200 -> 2464338773040
	2464339030272 -> 2464338773040
	2464339030032 -> 2464338773040
	2464339032528 -> 2464338773040
	2464339027584 -> 2464338773040
	2464339032912 -> 2464338773040
	2464339022832 -> 2464338773040
	2464339029552 -> 2464338773040
	2464339021344 -> 2464338773040
	2464339030512 -> 2464338773040
	2464339031616 -> 2464338773040
	2464339027728 -> 2464338773040
	2464338786960 -> 2464338774672
	2463245230448 [label="encoder.features.denseblock3.denselayer22.norm1.weight
 (928)" fillcolor=lightblue]
	2463245230448 -> 2464338786960
	2464338786960 [label=AccumulateGrad]
	2464338786048 -> 2464338774672
	2463245230688 [label="encoder.features.denseblock3.denselayer22.norm1.bias
 (928)" fillcolor=lightblue]
	2463245230688 -> 2464338786048
	2464338786048 [label=AccumulateGrad]
	2464338779616 -> 2464338775440
	2463245234448 [label="encoder.features.denseblock3.denselayer22.conv1.weight
 (128, 928, 1, 1)" fillcolor=lightblue]
	2463245234448 -> 2464338779616
	2464338779616 [label=AccumulateGrad]
	2464338784560 -> 2464338781536
	2463245235968 [label="encoder.features.denseblock3.denselayer22.norm2.weight
 (128)" fillcolor=lightblue]
	2463245235968 -> 2464338784560
	2464338784560 [label=AccumulateGrad]
	2464338787536 -> 2464338781536
	2463245223168 [label="encoder.features.denseblock3.denselayer22.norm2.bias
 (128)" fillcolor=lightblue]
	2463245223168 -> 2464338787536
	2464338787536 [label=AccumulateGrad]
	2464338780528 -> 2464339028544
	2463245230288 [label="encoder.features.denseblock3.denselayer22.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2463245230288 -> 2464338780528
	2464338780528 [label=AccumulateGrad]
	2464339021632 -> 2464339029984
	2464339021632 [label=ConvolutionBackward0]
	2464338774624 -> 2464339021632
	2464338774624 [label=ReluBackward0]
	2464338772176 -> 2464338774624
	2464338772176 [label=CudnnBatchNormBackward0]
	2464338783744 -> 2464338772176
	2464338783744 [label=ConvolutionBackward0]
	2464338774480 -> 2464338783744
	2464338774480 [label=ReluBackward0]
	2464338787296 -> 2464338774480
	2464338787296 [label=CudnnBatchNormBackward0]
	2464338780000 -> 2464338787296
	2464338780000 [label=CatBackward0]
	2464339029264 -> 2464338780000
	2464339033248 -> 2464338780000
	2464339027440 -> 2464338780000
	2464339026912 -> 2464338780000
	2464339033488 -> 2464338780000
	2464339018944 -> 2464338780000
	2464339030464 -> 2464338780000
	2464339022736 -> 2464338780000
	2464339017792 -> 2464338780000
	2464339032384 -> 2464338780000
	2464339027200 -> 2464338780000
	2464339030272 -> 2464338780000
	2464339030032 -> 2464338780000
	2464339032528 -> 2464338780000
	2464339027584 -> 2464338780000
	2464339032912 -> 2464338780000
	2464339022832 -> 2464338780000
	2464339029552 -> 2464338780000
	2464339021344 -> 2464338780000
	2464339030512 -> 2464338780000
	2464339031616 -> 2464338780000
	2464339027728 -> 2464338780000
	2464339028544 -> 2464338780000
	2464338967184 -> 2464338787296
	2463245229088 [label="encoder.features.denseblock3.denselayer23.norm1.weight
 (960)" fillcolor=lightblue]
	2463245229088 -> 2464338967184
	2464338967184 [label=AccumulateGrad]
	2464338968240 -> 2464338787296
	2463245234048 [label="encoder.features.denseblock3.denselayer23.norm1.bias
 (960)" fillcolor=lightblue]
	2463245234048 -> 2464338968240
	2464338968240 [label=AccumulateGrad]
	2464338781344 -> 2464338783744
	2463245223088 [label="encoder.features.denseblock3.denselayer23.conv1.weight
 (128, 960, 1, 1)" fillcolor=lightblue]
	2463245223088 -> 2464338781344
	2464338781344 [label=AccumulateGrad]
	2464338782448 -> 2464338772176
	2463245227648 [label="encoder.features.denseblock3.denselayer23.norm2.weight
 (128)" fillcolor=lightblue]
	2463245227648 -> 2464338782448
	2464338782448 [label=AccumulateGrad]
	2464338786624 -> 2464338772176
	2463245227008 [label="encoder.features.denseblock3.denselayer23.norm2.bias
 (128)" fillcolor=lightblue]
	2463245227008 -> 2464338786624
	2464338786624 [label=AccumulateGrad]
	2464338783840 -> 2464339021632
	2463245234688 [label="encoder.features.denseblock3.denselayer23.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2463245234688 -> 2464338783840
	2464338783840 [label=AccumulateGrad]
	2464339023936 -> 2464339029984
	2464339023936 [label=ConvolutionBackward0]
	2464338784272 -> 2464339023936
	2464338784272 [label=ReluBackward0]
	2464338783648 -> 2464338784272
	2464338783648 [label=CudnnBatchNormBackward0]
	2464338962048 -> 2464338783648
	2464338962048 [label=ConvolutionBackward0]
	2464338964064 -> 2464338962048
	2464338964064 [label=ReluBackward0]
	2464338953744 -> 2464338964064
	2464338953744 [label=CudnnBatchNormBackward0]
	2464338960080 -> 2464338953744
	2464338960080 [label=CatBackward0]
	2464339029264 -> 2464338960080
	2464339033248 -> 2464338960080
	2464339027440 -> 2464338960080
	2464339026912 -> 2464338960080
	2464339033488 -> 2464338960080
	2464339018944 -> 2464338960080
	2464339030464 -> 2464338960080
	2464339022736 -> 2464338960080
	2464339017792 -> 2464338960080
	2464339032384 -> 2464338960080
	2464339027200 -> 2464338960080
	2464339030272 -> 2464338960080
	2464339030032 -> 2464338960080
	2464339032528 -> 2464338960080
	2464339027584 -> 2464338960080
	2464339032912 -> 2464338960080
	2464339022832 -> 2464338960080
	2464339029552 -> 2464338960080
	2464339021344 -> 2464338960080
	2464339030512 -> 2464338960080
	2464339031616 -> 2464338960080
	2464339027728 -> 2464338960080
	2464339028544 -> 2464338960080
	2464339021632 -> 2464338960080
	2464338956000 -> 2464338953744
	2463245237248 [label="encoder.features.denseblock3.denselayer24.norm1.weight
 (992)" fillcolor=lightblue]
	2463245237248 -> 2464338956000
	2464338956000 [label=AccumulateGrad]
	2464338957056 -> 2464338953744
	2463245227248 [label="encoder.features.denseblock3.denselayer24.norm1.bias
 (992)" fillcolor=lightblue]
	2463245227248 -> 2464338957056
	2464338957056 [label=AccumulateGrad]
	2464338964592 -> 2464338962048
	2463245231568 [label="encoder.features.denseblock3.denselayer24.conv1.weight
 (128, 992, 1, 1)" fillcolor=lightblue]
	2463245231568 -> 2464338964592
	2464338964592 [label=AccumulateGrad]
	2464338956624 -> 2464338783648
	2463245233168 [label="encoder.features.denseblock3.denselayer24.norm2.weight
 (128)" fillcolor=lightblue]
	2463245233168 -> 2464338956624
	2464338956624 [label=AccumulateGrad]
	2464338952352 -> 2464338783648
	2463245227728 [label="encoder.features.denseblock3.denselayer24.norm2.bias
 (128)" fillcolor=lightblue]
	2463245227728 -> 2464338952352
	2464338952352 [label=AccumulateGrad]
	2464338787968 -> 2464339023936
	2463245236048 [label="encoder.features.denseblock3.denselayer24.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2463245236048 -> 2464338787968
	2464338787968 [label=AccumulateGrad]
	2464339018512 -> 2464339023984
	2463245232528 [label="encoder.features.transition3.norm.weight
 (1024)" fillcolor=lightblue]
	2463245232528 -> 2464339018512
	2464339018512 [label=AccumulateGrad]
	2464339018464 -> 2464339023984
	2463245233568 [label="encoder.features.transition3.norm.bias
 (1024)" fillcolor=lightblue]
	2463245233568 -> 2464339018464
	2464339018464 [label=AccumulateGrad]
	2464339021248 -> 2464339020480
	2463245233248 [label="encoder.features.transition3.conv.weight
 (512, 1024, 1, 1)" fillcolor=lightblue]
	2463245233248 -> 2464339021248
	2464339021248 [label=AccumulateGrad]
	2464339027872 -> 2464339027296
	2464339027872 [label=ConvolutionBackward0]
	2464339027680 -> 2464339027872
	2464339027680 [label=ReluBackward0]
	2464339019280 -> 2464339027680
	2464339019280 [label=CudnnBatchNormBackward0]
	2464338775872 -> 2464339019280
	2464338775872 [label=ConvolutionBackward0]
	2464338953168 -> 2464338775872
	2464338953168 [label=ReluBackward0]
	2464338955136 -> 2464338953168
	2464338955136 [label=CudnnBatchNormBackward0]
	2464338960128 -> 2464338955136
	2464338960128 [label=CatBackward0]
	2464339031184 -> 2464338960128
	2464338960416 -> 2464338955136
	2463245222128 [label="encoder.features.denseblock4.denselayer1.norm1.weight
 (512)" fillcolor=lightblue]
	2463245222128 -> 2464338960416
	2464338960416 [label=AccumulateGrad]
	2464338955328 -> 2464338955136
	2463245236128 [label="encoder.features.denseblock4.denselayer1.norm1.bias
 (512)" fillcolor=lightblue]
	2463245236128 -> 2464338955328
	2464338955328 [label=AccumulateGrad]
	2464338954128 -> 2464338775872
	2463245231888 [label="encoder.features.denseblock4.denselayer1.conv1.weight
 (128, 512, 1, 1)" fillcolor=lightblue]
	2463245231888 -> 2464338954128
	2464338954128 [label=AccumulateGrad]
	2464338775392 -> 2464339019280
	2463245229888 [label="encoder.features.denseblock4.denselayer1.norm2.weight
 (128)" fillcolor=lightblue]
	2463245229888 -> 2464338775392
	2464338775392 [label=AccumulateGrad]
	2464338961616 -> 2464339019280
	2463245237168 [label="encoder.features.denseblock4.denselayer1.norm2.bias
 (128)" fillcolor=lightblue]
	2463245237168 -> 2464338961616
	2464338961616 [label=AccumulateGrad]
	2464339028064 -> 2464339027872
	2463245235008 [label="encoder.features.denseblock4.denselayer1.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2463245235008 -> 2464339028064
	2464339028064 [label=AccumulateGrad]
	2464339030368 -> 2464339027296
	2464339030368 [label=ConvolutionBackward0]
	2464339024128 -> 2464339030368
	2464339024128 [label=ReluBackward0]
	2464338964640 -> 2464339024128
	2464338964640 [label=CudnnBatchNormBackward0]
	2464338960608 -> 2464338964640
	2464338960608 [label=ConvolutionBackward0]
	2464338961280 -> 2464338960608
	2464338961280 [label=ReluBackward0]
	2464338961376 -> 2464338961280
	2464338961376 [label=CudnnBatchNormBackward0]
	2464338967760 -> 2464338961376
	2464338967760 [label=CatBackward0]
	2464339031184 -> 2464338967760
	2464339027872 -> 2464338967760
	2464338957728 -> 2464338961376
	2463245234208 [label="encoder.features.denseblock4.denselayer2.norm1.weight
 (544)" fillcolor=lightblue]
	2463245234208 -> 2464338957728
	2464338957728 [label=AccumulateGrad]
	2464338956576 -> 2464338961376
	2463245232448 [label="encoder.features.denseblock4.denselayer2.norm1.bias
 (544)" fillcolor=lightblue]
	2463245232448 -> 2464338956576
	2464338956576 [label=AccumulateGrad]
	2464338954080 -> 2464338960608
	2463245237408 [label="encoder.features.denseblock4.denselayer2.conv1.weight
 (128, 544, 1, 1)" fillcolor=lightblue]
	2463245237408 -> 2464338954080
	2464338954080 [label=AccumulateGrad]
	2464338960896 -> 2464338964640
	2463245236768 [label="encoder.features.denseblock4.denselayer2.norm2.weight
 (128)" fillcolor=lightblue]
	2463245236768 -> 2464338960896
	2464338960896 [label=AccumulateGrad]
	2464338952736 -> 2464338964640
	2463245233328 [label="encoder.features.denseblock4.denselayer2.norm2.bias
 (128)" fillcolor=lightblue]
	2463245233328 -> 2464338952736
	2464338952736 [label=AccumulateGrad]
	2464339021824 -> 2464339030368
	2463245234528 [label="encoder.features.denseblock4.denselayer2.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2463245234528 -> 2464339021824
	2464339021824 [label=AccumulateGrad]
	2464339029408 -> 2464339027296
	2464339029408 [label=ConvolutionBackward0]
	2464338959072 -> 2464339029408
	2464338959072 [label=ReluBackward0]
	2464338955904 -> 2464338959072
	2464338955904 [label=CudnnBatchNormBackward0]
	2464338954176 -> 2464338955904
	2464338954176 [label=ConvolutionBackward0]
	2464338955088 -> 2464338954176
	2464338955088 [label=ReluBackward0]
	2464338955424 -> 2464338955088
	2464338955424 [label=CudnnBatchNormBackward0]
	2464338955280 -> 2464338955424
	2464338955280 [label=CatBackward0]
	2464339031184 -> 2464338955280
	2464339027872 -> 2464338955280
	2464339030368 -> 2464338955280
	2464338962576 -> 2464338955424
	2463245225088 [label="encoder.features.denseblock4.denselayer3.norm1.weight
 (576)" fillcolor=lightblue]
	2463245225088 -> 2464338962576
	2464338962576 [label=AccumulateGrad]
	2464338956864 -> 2464338955424
	2463245234288 [label="encoder.features.denseblock4.denselayer3.norm1.bias
 (576)" fillcolor=lightblue]
	2463245234288 -> 2464338956864
	2464338956864 [label=AccumulateGrad]
	2464338954224 -> 2464338954176
	2463245225648 [label="encoder.features.denseblock4.denselayer3.conv1.weight
 (128, 576, 1, 1)" fillcolor=lightblue]
	2463245225648 -> 2464338954224
	2464338954224 [label=AccumulateGrad]
	2464338963536 -> 2464338955904
	2463245236448 [label="encoder.features.denseblock4.denselayer3.norm2.weight
 (128)" fillcolor=lightblue]
	2463245236448 -> 2464338963536
	2464338963536 [label=AccumulateGrad]
	2464338958496 -> 2464338955904
	2463245227328 [label="encoder.features.denseblock4.denselayer3.norm2.bias
 (128)" fillcolor=lightblue]
	2463245227328 -> 2464338958496
	2464338958496 [label=AccumulateGrad]
	2464338960704 -> 2464339029408
	2463245223248 [label="encoder.features.denseblock4.denselayer3.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2463245223248 -> 2464338960704
	2464338960704 [label=AccumulateGrad]
	2464339023072 -> 2464339027296
	2464339023072 [label=ConvolutionBackward0]
	2464338961904 -> 2464339023072
	2464338961904 [label=ReluBackward0]
	2464338952496 -> 2464338961904
	2464338952496 [label=CudnnBatchNormBackward0]
	2464338960992 -> 2464338952496
	2464338960992 [label=ConvolutionBackward0]
	2464338959600 -> 2464338960992
	2464338959600 [label=ReluBackward0]
	2464338957200 -> 2464338959600
	2464338957200 [label=CudnnBatchNormBackward0]
	2464338966992 -> 2464338957200
	2464338966992 [label=CatBackward0]
	2464339031184 -> 2464338966992
	2464339027872 -> 2464338966992
	2464339030368 -> 2464338966992
	2464339029408 -> 2464338966992
	2464338959552 -> 2464338957200
	2463245235088 [label="encoder.features.denseblock4.denselayer4.norm1.weight
 (608)" fillcolor=lightblue]
	2463245235088 -> 2464338959552
	2464338959552 [label=AccumulateGrad]
	2464338956336 -> 2464338957200
	2463245222208 [label="encoder.features.denseblock4.denselayer4.norm1.bias
 (608)" fillcolor=lightblue]
	2463245222208 -> 2464338956336
	2464338956336 [label=AccumulateGrad]
	2464338968336 -> 2464338960992
	2463245225808 [label="encoder.features.denseblock4.denselayer4.conv1.weight
 (128, 608, 1, 1)" fillcolor=lightblue]
	2463245225808 -> 2464338968336
	2464338968336 [label=AccumulateGrad]
	2464338965072 -> 2464338952496
	2463245223008 [label="encoder.features.denseblock4.denselayer4.norm2.weight
 (128)" fillcolor=lightblue]
	2463245223008 -> 2464338965072
	2464338965072 [label=AccumulateGrad]
	2464338962720 -> 2464338952496
	2463245230768 [label="encoder.features.denseblock4.denselayer4.norm2.bias
 (128)" fillcolor=lightblue]
	2463245230768 -> 2464338962720
	2464338962720 [label=AccumulateGrad]
	2464338960176 -> 2464339023072
	2463245231328 [label="encoder.features.denseblock4.denselayer4.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2463245231328 -> 2464338960176
	2464338960176 [label=AccumulateGrad]
	2464339029696 -> 2464339027296
	2464339029696 [label=ConvolutionBackward0]
	2464338967808 -> 2464339029696
	2464338967808 [label=ReluBackward0]
	2464338963728 -> 2464338967808
	2464338963728 [label=CudnnBatchNormBackward0]
	2464338955616 -> 2464338963728
	2464338955616 [label=ConvolutionBackward0]
	2464338954032 -> 2464338955616
	2464338954032 [label=ReluBackward0]
	2464338965936 -> 2464338954032
	2464338965936 [label=CudnnBatchNormBackward0]
	2464338963776 -> 2464338965936
	2464338963776 [label=CatBackward0]
	2464339031184 -> 2464338963776
	2464339027872 -> 2464338963776
	2464339030368 -> 2464338963776
	2464339029408 -> 2464338963776
	2464339023072 -> 2464338963776
	2464338962864 -> 2464338965936
	2463245226528 [label="encoder.features.denseblock4.denselayer5.norm1.weight
 (640)" fillcolor=lightblue]
	2463245226528 -> 2464338962864
	2464338962864 [label=AccumulateGrad]
	2464338967136 -> 2464338965936
	2463245226128 [label="encoder.features.denseblock4.denselayer5.norm1.bias
 (640)" fillcolor=lightblue]
	2463245226128 -> 2464338967136
	2464338967136 [label=AccumulateGrad]
	2464338968144 -> 2464338955616
	2463245230528 [label="encoder.features.denseblock4.denselayer5.conv1.weight
 (128, 640, 1, 1)" fillcolor=lightblue]
	2463245230528 -> 2464338968144
	2464338968144 [label=AccumulateGrad]
	2464338954752 -> 2464338963728
	2463245237568 [label="encoder.features.denseblock4.denselayer5.norm2.weight
 (128)" fillcolor=lightblue]
	2463245237568 -> 2464338954752
	2464338954752 [label=AccumulateGrad]
	2464338953984 -> 2464338963728
	2463245228768 [label="encoder.features.denseblock4.denselayer5.norm2.bias
 (128)" fillcolor=lightblue]
	2463245228768 -> 2464338953984
	2464338953984 [label=AccumulateGrad]
	2464338953072 -> 2464339029696
	2463245229168 [label="encoder.features.denseblock4.denselayer5.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2463245229168 -> 2464338953072
	2464338953072 [label=AccumulateGrad]
	2464339022448 -> 2464339027296
	2464339022448 [label=ConvolutionBackward0]
	2464338963152 -> 2464339022448
	2464338963152 [label=ReluBackward0]
	2464338954608 -> 2464338963152
	2464338954608 [label=CudnnBatchNormBackward0]
	2464338961472 -> 2464338954608
	2464338961472 [label=ConvolutionBackward0]
	2464338958304 -> 2464338961472
	2464338958304 [label=ReluBackward0]
	2464338957104 -> 2464338958304
	2464338957104 [label=CudnnBatchNormBackward0]
	2464338953792 -> 2464338957104
	2464338953792 [label=CatBackward0]
	2464339031184 -> 2464338953792
	2464339027872 -> 2464338953792
	2464339030368 -> 2464338953792
	2464339029408 -> 2464338953792
	2464339023072 -> 2464338953792
	2464339029696 -> 2464338953792
	2464338952832 -> 2464338957104
	2463245236528 [label="encoder.features.denseblock4.denselayer6.norm1.weight
 (672)" fillcolor=lightblue]
	2463245236528 -> 2464338952832
	2464338952832 [label=AccumulateGrad]
	2464338957632 -> 2464338957104
	2463245235888 [label="encoder.features.denseblock4.denselayer6.norm1.bias
 (672)" fillcolor=lightblue]
	2463245235888 -> 2464338957632
	2464338957632 [label=AccumulateGrad]
	2464338957968 -> 2464338961472
	2463245233888 [label="encoder.features.denseblock4.denselayer6.conv1.weight
 (128, 672, 1, 1)" fillcolor=lightblue]
	2463245233888 -> 2464338957968
	2464338957968 [label=AccumulateGrad]
	2464338960944 -> 2464338954608
	2463245224448 [label="encoder.features.denseblock4.denselayer6.norm2.weight
 (128)" fillcolor=lightblue]
	2463245224448 -> 2464338960944
	2464338960944 [label=AccumulateGrad]
	2464338958400 -> 2464338954608
	2463245234608 [label="encoder.features.denseblock4.denselayer6.norm2.bias
 (128)" fillcolor=lightblue]
	2463245234608 -> 2464338958400
	2464338958400 [label=AccumulateGrad]
	2464338965168 -> 2464339022448
	2463245188736 [label="encoder.features.denseblock4.denselayer6.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2463245188736 -> 2464338965168
	2464338965168 [label=AccumulateGrad]
	2464339024896 -> 2464339027296
	2464339024896 [label=ConvolutionBackward0]
	2464338959984 -> 2464339024896
	2464338959984 [label=ReluBackward0]
	2464338966800 -> 2464338959984
	2464338966800 [label=CudnnBatchNormBackward0]
	2464338959792 -> 2464338966800
	2464338959792 [label=ConvolutionBackward0]
	2464338963440 -> 2464338959792
	2464338963440 [label=ReluBackward0]
	2464338959504 -> 2464338963440
	2464338959504 [label=CudnnBatchNormBackward0]
	2464338952256 -> 2464338959504
	2464338952256 [label=CatBackward0]
	2464339031184 -> 2464338952256
	2464339027872 -> 2464338952256
	2464339030368 -> 2464338952256
	2464339029408 -> 2464338952256
	2464339023072 -> 2464338952256
	2464339029696 -> 2464338952256
	2464339022448 -> 2464338952256
	2464338957152 -> 2464338959504
	2463245187136 [label="encoder.features.denseblock4.denselayer7.norm1.weight
 (704)" fillcolor=lightblue]
	2463245187136 -> 2464338957152
	2464338957152 [label=AccumulateGrad]
	2464338957296 -> 2464338959504
	2463245183216 [label="encoder.features.denseblock4.denselayer7.norm1.bias
 (704)" fillcolor=lightblue]
	2463245183216 -> 2464338957296
	2464338957296 [label=AccumulateGrad]
	2464338953840 -> 2464338959792
	2463245181296 [label="encoder.features.denseblock4.denselayer7.conv1.weight
 (128, 704, 1, 1)" fillcolor=lightblue]
	2463245181296 -> 2464338953840
	2464338953840 [label=AccumulateGrad]
	2464338961136 -> 2464338966800
	2463245181136 [label="encoder.features.denseblock4.denselayer7.norm2.weight
 (128)" fillcolor=lightblue]
	2463245181136 -> 2464338961136
	2464338961136 [label=AccumulateGrad]
	2464338955760 -> 2464338966800
	2463245187056 [label="encoder.features.denseblock4.denselayer7.norm2.bias
 (128)" fillcolor=lightblue]
	2463245187056 -> 2464338955760
	2464338955760 [label=AccumulateGrad]
	2464338961808 -> 2464339024896
	2463245184496 [label="encoder.features.denseblock4.denselayer7.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2463245184496 -> 2464338961808
	2464338961808 [label=AccumulateGrad]
	2464339030080 -> 2464339027296
	2464339030080 [label=ConvolutionBackward0]
	2464338967568 -> 2464339030080
	2464338967568 [label=ReluBackward0]
	2464338965744 -> 2464338967568
	2464338965744 [label=CudnnBatchNormBackward0]
	2464338966704 -> 2464338965744
	2464338966704 [label=ConvolutionBackward0]
	2464338953504 -> 2464338966704
	2464338953504 [label=ReluBackward0]
	2464338955520 -> 2464338953504
	2464338955520 [label=CudnnBatchNormBackward0]
	2464338958928 -> 2464338955520
	2464338958928 [label=CatBackward0]
	2464339031184 -> 2464338958928
	2464339027872 -> 2464338958928
	2464339030368 -> 2464338958928
	2464339029408 -> 2464338958928
	2464339023072 -> 2464338958928
	2464339029696 -> 2464338958928
	2464339022448 -> 2464338958928
	2464339024896 -> 2464338958928
	2464338953360 -> 2464338955520
	2463245182416 [label="encoder.features.denseblock4.denselayer8.norm1.weight
 (736)" fillcolor=lightblue]
	2463245182416 -> 2464338953360
	2464338953360 [label=AccumulateGrad]
	2464338953408 -> 2464338955520
	2463245185296 [label="encoder.features.denseblock4.denselayer8.norm1.bias
 (736)" fillcolor=lightblue]
	2463245185296 -> 2464338953408
	2464338953408 [label=AccumulateGrad]
	2464338956816 -> 2464338966704
	2463245182256 [label="encoder.features.denseblock4.denselayer8.conv1.weight
 (128, 736, 1, 1)" fillcolor=lightblue]
	2463245182256 -> 2464338956816
	2464338956816 [label=AccumulateGrad]
	2464338952448 -> 2464338965744
	2463245187536 [label="encoder.features.denseblock4.denselayer8.norm2.weight
 (128)" fillcolor=lightblue]
	2463245187536 -> 2464338952448
	2464338952448 [label=AccumulateGrad]
	2464338954800 -> 2464338965744
	2463245184416 [label="encoder.features.denseblock4.denselayer8.norm2.bias
 (128)" fillcolor=lightblue]
	2463245184416 -> 2464338954800
	2464338954800 [label=AccumulateGrad]
	2464338961040 -> 2464339030080
	2463245183856 [label="encoder.features.denseblock4.denselayer8.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2463245183856 -> 2464338961040
	2464338961040 [label=AccumulateGrad]
	2464339031856 -> 2464339027296
	2464339031856 [label=ConvolutionBackward0]
	2464338956912 -> 2464339031856
	2464338956912 [label=ReluBackward0]
	2464338964208 -> 2464338956912
	2464338964208 [label=CudnnBatchNormBackward0]
	2464338960512 -> 2464338964208
	2464338960512 [label=ConvolutionBackward0]
	2464338962000 -> 2464338960512
	2464338962000 [label=ReluBackward0]
	2464338958112 -> 2464338962000
	2464338958112 [label=CudnnBatchNormBackward0]
	2464338962528 -> 2464338958112
	2464338962528 [label=CatBackward0]
	2464339031184 -> 2464338962528
	2464339027872 -> 2464338962528
	2464339030368 -> 2464338962528
	2464339029408 -> 2464338962528
	2464339023072 -> 2464338962528
	2464339029696 -> 2464338962528
	2464339022448 -> 2464338962528
	2464339024896 -> 2464338962528
	2464339030080 -> 2464338962528
	2464338966368 -> 2464338958112
	2463245175776 [label="encoder.features.denseblock4.denselayer9.norm1.weight
 (768)" fillcolor=lightblue]
	2463245175776 -> 2464338966368
	2464338966368 [label=AccumulateGrad]
	2464338952592 -> 2464338958112
	2463245187296 [label="encoder.features.denseblock4.denselayer9.norm1.bias
 (768)" fillcolor=lightblue]
	2463245187296 -> 2464338952592
	2464338952592 [label=AccumulateGrad]
	2464338959696 -> 2464338960512
	2463245182816 [label="encoder.features.denseblock4.denselayer9.conv1.weight
 (128, 768, 1, 1)" fillcolor=lightblue]
	2463245182816 -> 2464338959696
	2464338959696 [label=AccumulateGrad]
	2464338964352 -> 2464338964208
	2463245184256 [label="encoder.features.denseblock4.denselayer9.norm2.weight
 (128)" fillcolor=lightblue]
	2463245184256 -> 2464338964352
	2464338964352 [label=AccumulateGrad]
	2464338959648 -> 2464338964208
	2463245182656 [label="encoder.features.denseblock4.denselayer9.norm2.bias
 (128)" fillcolor=lightblue]
	2463245182656 -> 2464338959648
	2464338959648 [label=AccumulateGrad]
	2464338960848 -> 2464339031856
	2463245184336 [label="encoder.features.denseblock4.denselayer9.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2463245184336 -> 2464338960848
	2464338960848 [label=AccumulateGrad]
	2464339032960 -> 2464339027296
	2464339032960 [label=ConvolutionBackward0]
	2464338964448 -> 2464339032960
	2464338964448 [label=ReluBackward0]
	2464338959120 -> 2464338964448
	2464338959120 [label=CudnnBatchNormBackward0]
	2464338959312 -> 2464338959120
	2464338959312 [label=ConvolutionBackward0]
	2464338967424 -> 2464338959312
	2464338967424 [label=ReluBackward0]
	2464338955856 -> 2464338967424
	2464338955856 [label=CudnnBatchNormBackward0]
	2464338952400 -> 2464338955856
	2464338952400 [label=CatBackward0]
	2464339031184 -> 2464338952400
	2464339027872 -> 2464338952400
	2464339030368 -> 2464338952400
	2464339029408 -> 2464338952400
	2464339023072 -> 2464338952400
	2464339029696 -> 2464338952400
	2464339022448 -> 2464338952400
	2464339024896 -> 2464338952400
	2464339030080 -> 2464338952400
	2464339031856 -> 2464338952400
	2464338952640 -> 2464338955856
	2463245183296 [label="encoder.features.denseblock4.denselayer10.norm1.weight
 (800)" fillcolor=lightblue]
	2463245183296 -> 2464338952640
	2464338952640 [label=AccumulateGrad]
	2464338952784 -> 2464338955856
	2463245185696 [label="encoder.features.denseblock4.denselayer10.norm1.bias
 (800)" fillcolor=lightblue]
	2463245185696 -> 2464338952784
	2464338952784 [label=AccumulateGrad]
	2464338966464 -> 2464338959312
	2463245184096 [label="encoder.features.denseblock4.denselayer10.conv1.weight
 (128, 800, 1, 1)" fillcolor=lightblue]
	2463245184096 -> 2464338966464
	2464338966464 [label=AccumulateGrad]
	2464338963344 -> 2464338959120
	2463245187776 [label="encoder.features.denseblock4.denselayer10.norm2.weight
 (128)" fillcolor=lightblue]
	2463245187776 -> 2464338963344
	2464338963344 [label=AccumulateGrad]
	2464338965648 -> 2464338959120
	2463245180976 [label="encoder.features.denseblock4.denselayer10.norm2.bias
 (128)" fillcolor=lightblue]
	2463245180976 -> 2464338965648
	2464338965648 [label=AccumulateGrad]
	2464338959264 -> 2464339032960
	2463245188016 [label="encoder.features.denseblock4.denselayer10.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2463245188016 -> 2464338959264
	2464338959264 [label=AccumulateGrad]
	2464339033008 -> 2464339027296
	2464339033008 [label=ConvolutionBackward0]
	2464338963392 -> 2464339033008
	2464338963392 [label=ReluBackward0]
	2464338965792 -> 2464338963392
	2464338965792 [label=CudnnBatchNormBackward0]
	2464338952976 -> 2464338965792
	2464338952976 [label=ConvolutionBackward0]
	2464338954416 -> 2464338952976
	2464338954416 [label=ReluBackward0]
	2464338954896 -> 2464338954416
	2464338954896 [label=CudnnBatchNormBackward0]
	2464338956144 -> 2464338954896
	2464338956144 [label=CatBackward0]
	2464339031184 -> 2464338956144
	2464339027872 -> 2464338956144
	2464339030368 -> 2464338956144
	2464339029408 -> 2464338956144
	2464339023072 -> 2464338956144
	2464339029696 -> 2464338956144
	2464339022448 -> 2464338956144
	2464339024896 -> 2464338956144
	2464339030080 -> 2464338956144
	2464339031856 -> 2464338956144
	2464339032960 -> 2464338956144
	2464338956192 -> 2464338954896
	2463245186816 [label="encoder.features.denseblock4.denselayer11.norm1.weight
 (832)" fillcolor=lightblue]
	2463245186816 -> 2464338956192
	2464338956192 [label=AccumulateGrad]
	2464338954704 -> 2464338954896
	2463245186256 [label="encoder.features.denseblock4.denselayer11.norm1.bias
 (832)" fillcolor=lightblue]
	2463245186256 -> 2464338954704
	2464338954704 [label=AccumulateGrad]
	2464338954656 -> 2464338952976
	2463245185056 [label="encoder.features.denseblock4.denselayer11.conv1.weight
 (128, 832, 1, 1)" fillcolor=lightblue]
	2463245185056 -> 2464338954656
	2464338954656 [label=AccumulateGrad]
	2464338953024 -> 2464338965792
	2463245182736 [label="encoder.features.denseblock4.denselayer11.norm2.weight
 (128)" fillcolor=lightblue]
	2463245182736 -> 2464338953024
	2464338953024 [label=AccumulateGrad]
	2464338952304 -> 2464338965792
	2463245188656 [label="encoder.features.denseblock4.denselayer11.norm2.bias
 (128)" fillcolor=lightblue]
	2463245188656 -> 2464338952304
	2464338952304 [label=AccumulateGrad]
	2464338962432 -> 2464339033008
	2463245184016 [label="encoder.features.denseblock4.denselayer11.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2463245184016 -> 2464338962432
	2464338962432 [label=AccumulateGrad]
	2464339028496 -> 2464339027296
	2464339028496 [label=ConvolutionBackward0]
	2464338953600 -> 2464339028496
	2464338953600 [label=ReluBackward0]
	2464338953696 -> 2464338953600
	2464338953696 [label=CudnnBatchNormBackward0]
	2464338956720 -> 2464338953696
	2464338956720 [label=ConvolutionBackward0]
	2464338957680 -> 2464338956720
	2464338957680 [label=ReluBackward0]
	2464338958640 -> 2464338957680
	2464338958640 [label=CudnnBatchNormBackward0]
	2464338959744 -> 2464338958640
	2464338959744 [label=CatBackward0]
	2464339031184 -> 2464338959744
	2464339027872 -> 2464338959744
	2464339030368 -> 2464338959744
	2464339029408 -> 2464338959744
	2464339023072 -> 2464338959744
	2464339029696 -> 2464338959744
	2464339022448 -> 2464338959744
	2464339024896 -> 2464338959744
	2464339030080 -> 2464338959744
	2464339031856 -> 2464338959744
	2464339032960 -> 2464338959744
	2464339033008 -> 2464338959744
	2464338960224 -> 2464338958640
	2463245182016 [label="encoder.features.denseblock4.denselayer12.norm1.weight
 (864)" fillcolor=lightblue]
	2463245182016 -> 2464338960224
	2464338960224 [label=AccumulateGrad]
	2464338958544 -> 2464338958640
	2463245184976 [label="encoder.features.denseblock4.denselayer12.norm1.bias
 (864)" fillcolor=lightblue]
	2463245184976 -> 2464338958544
	2464338958544 [label=AccumulateGrad]
	2464338957824 -> 2464338956720
	2463245186416 [label="encoder.features.denseblock4.denselayer12.conv1.weight
 (128, 864, 1, 1)" fillcolor=lightblue]
	2463245186416 -> 2464338957824
	2464338957824 [label=AccumulateGrad]
	2464338957344 -> 2464338953696
	2463245180496 [label="encoder.features.denseblock4.denselayer12.norm2.weight
 (128)" fillcolor=lightblue]
	2463245180496 -> 2464338957344
	2464338957344 [label=AccumulateGrad]
	2464338955664 -> 2464338953696
	2463245180176 [label="encoder.features.denseblock4.denselayer12.norm2.bias
 (128)" fillcolor=lightblue]
	2463245180176 -> 2464338955664
	2464338955664 [label=AccumulateGrad]
	2464338952880 -> 2464339028496
	2463245180576 [label="encoder.features.denseblock4.denselayer12.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2463245180576 -> 2464338952880
	2464338952880 [label=AccumulateGrad]
	2464339019712 -> 2464339027296
	2464339019712 [label=ConvolutionBackward0]
	2464338957440 -> 2464339019712
	2464338957440 [label=ReluBackward0]
	2464338957584 -> 2464338957440
	2464338957584 [label=CudnnBatchNormBackward0]
	2464338960800 -> 2464338957584
	2464338960800 [label=ConvolutionBackward0]
	2464338962624 -> 2464338960800
	2464338962624 [label=ReluBackward0]
	2464338963056 -> 2464338962624
	2464338963056 [label=CudnnBatchNormBackward0]
	2464338963920 -> 2464338963056
	2464338963920 [label=CatBackward0]
	2464339031184 -> 2464338963920
	2464339027872 -> 2464338963920
	2464339030368 -> 2464338963920
	2464339029408 -> 2464338963920
	2464339023072 -> 2464338963920
	2464339029696 -> 2464338963920
	2464339022448 -> 2464338963920
	2464339024896 -> 2464338963920
	2464339030080 -> 2464338963920
	2464339031856 -> 2464338963920
	2464339032960 -> 2464338963920
	2464339033008 -> 2464338963920
	2464339028496 -> 2464338963920
	2464338964304 -> 2464338963056
	2463245186736 [label="encoder.features.denseblock4.denselayer13.norm1.weight
 (896)" fillcolor=lightblue]
	2463245186736 -> 2464338964304
	2464338964304 [label=AccumulateGrad]
	2464338962960 -> 2464338963056
	2463245187376 [label="encoder.features.denseblock4.denselayer13.norm1.bias
 (896)" fillcolor=lightblue]
	2463245187376 -> 2464338962960
	2464338962960 [label=AccumulateGrad]
	2464338962816 -> 2464338960800
	2463245180816 [label="encoder.features.denseblock4.denselayer13.conv1.weight
 (128, 896, 1, 1)" fillcolor=lightblue]
	2463245180816 -> 2464338962816
	2464338962816 [label=AccumulateGrad]
	2464338961520 -> 2464338957584
	2463245188816 [label="encoder.features.denseblock4.denselayer13.norm2.weight
 (128)" fillcolor=lightblue]
	2463245188816 -> 2464338961520
	2464338961520 [label=AccumulateGrad]
	2464338959168 -> 2464338957584
	2463245180096 [label="encoder.features.denseblock4.denselayer13.norm2.bias
 (128)" fillcolor=lightblue]
	2463245180096 -> 2464338959168
	2464338959168 [label=AccumulateGrad]
	2464338956288 -> 2464339019712
	2463245186016 [label="encoder.features.denseblock4.denselayer13.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2463245186016 -> 2464338956288
	2464338956288 [label=AccumulateGrad]
	2464339021968 -> 2464339027296
	2464339021968 [label=ConvolutionBackward0]
	2464338962144 -> 2464339021968
	2464338962144 [label=ReluBackward0]
	2464338962480 -> 2464338962144
	2464338962480 [label=CudnnBatchNormBackward0]
	2464338964544 -> 2464338962480
	2464338964544 [label=ConvolutionBackward0]
	2464338965360 -> 2464338964544
	2464338965360 [label=ReluBackward0]
	2464338966176 -> 2464338965360
	2464338966176 [label=CudnnBatchNormBackward0]
	2464338966752 -> 2464338966176
	2464338966752 [label=CatBackward0]
	2464339031184 -> 2464338966752
	2464339027872 -> 2464338966752
	2464339030368 -> 2464338966752
	2464339029408 -> 2464338966752
	2464339023072 -> 2464338966752
	2464339029696 -> 2464338966752
	2464339022448 -> 2464338966752
	2464339024896 -> 2464338966752
	2464339030080 -> 2464338966752
	2464339031856 -> 2464338966752
	2464339032960 -> 2464338966752
	2464339033008 -> 2464338966752
	2464339028496 -> 2464338966752
	2464339019712 -> 2464338966752
	2464338967088 -> 2464338966176
	2463245187616 [label="encoder.features.denseblock4.denselayer14.norm1.weight
 (928)" fillcolor=lightblue]
	2463245187616 -> 2464338967088
	2464338967088 [label=AccumulateGrad]
	2464338965600 -> 2464338966176
	2463245185456 [label="encoder.features.denseblock4.denselayer14.norm1.bias
 (928)" fillcolor=lightblue]
	2463245185456 -> 2464338965600
	2464338965600 [label=AccumulateGrad]
	2464338965456 -> 2464338964544
	2464338320896 [label="encoder.features.denseblock4.denselayer14.conv1.weight
 (128, 928, 1, 1)" fillcolor=lightblue]
	2464338320896 -> 2464338965456
	2464338965456 [label=AccumulateGrad]
	2464338965120 -> 2464338962480
	2464338320736 [label="encoder.features.denseblock4.denselayer14.norm2.weight
 (128)" fillcolor=lightblue]
	2464338320736 -> 2464338965120
	2464338965120 [label=AccumulateGrad]
	2464338963248 -> 2464338962480
	2464338320336 [label="encoder.features.denseblock4.denselayer14.norm2.bias
 (128)" fillcolor=lightblue]
	2464338320336 -> 2464338963248
	2464338963248 [label=AccumulateGrad]
	2464338960320 -> 2464339021968
	2464338321216 [label="encoder.features.denseblock4.denselayer14.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2464338321216 -> 2464338960320
	2464338960320 [label=AccumulateGrad]
	2464339029792 -> 2464339027296
	2464339029792 [label=ConvolutionBackward0]
	2464338965216 -> 2464339029792
	2464338965216 [label=ReluBackward0]
	2464338965264 -> 2464338965216
	2464338965264 [label=CudnnBatchNormBackward0]
	2464338967616 -> 2464338965264
	2464338967616 [label=ConvolutionBackward0]
	2464338968528 -> 2464338967616
	2464338968528 [label=ReluBackward0]
	2464338962672 -> 2464338968528
	2464338962672 [label=CudnnBatchNormBackward0]
	2464338953120 -> 2464338962672
	2464338953120 [label=CatBackward0]
	2464339031184 -> 2464338953120
	2464339027872 -> 2464338953120
	2464339030368 -> 2464338953120
	2464339029408 -> 2464338953120
	2464339023072 -> 2464338953120
	2464339029696 -> 2464338953120
	2464339022448 -> 2464338953120
	2464339024896 -> 2464338953120
	2464339030080 -> 2464338953120
	2464339031856 -> 2464338953120
	2464339032960 -> 2464338953120
	2464339033008 -> 2464338953120
	2464339028496 -> 2464338953120
	2464339019712 -> 2464338953120
	2464339021968 -> 2464338953120
	2464338964160 -> 2464338962672
	2464338322256 [label="encoder.features.denseblock4.denselayer15.norm1.weight
 (960)" fillcolor=lightblue]
	2464338322256 -> 2464338964160
	2464338964160 [label=AccumulateGrad]
	2464338958832 -> 2464338962672
	2464338322096 [label="encoder.features.denseblock4.denselayer15.norm1.bias
 (960)" fillcolor=lightblue]
	2464338322096 -> 2464338958832
	2464338958832 [label=AccumulateGrad]
	2464338953552 -> 2464338967616
	2464338322496 [label="encoder.features.denseblock4.denselayer15.conv1.weight
 (128, 960, 1, 1)" fillcolor=lightblue]
	2464338322496 -> 2464338953552
	2464338953552 [label=AccumulateGrad]
	2464338967664 -> 2464338965264
	2464338322336 [label="encoder.features.denseblock4.denselayer15.norm2.weight
 (128)" fillcolor=lightblue]
	2464338322336 -> 2464338967664
	2464338967664 [label=AccumulateGrad]
	2464338966416 -> 2464338965264
	2464338322576 [label="encoder.features.denseblock4.denselayer15.norm2.bias
 (128)" fillcolor=lightblue]
	2464338322576 -> 2464338966416
	2464338966416 [label=AccumulateGrad]
	2464338964400 -> 2464339029792
	2464338324096 [label="encoder.features.denseblock4.denselayer15.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2464338324096 -> 2464338964400
	2464338964400 [label=AccumulateGrad]
	2464339019136 -> 2464339027296
	2464339019136 [label=ConvolutionBackward0]
	2464338967904 -> 2464339019136
	2464338967904 [label=ReluBackward0]
	2464338968288 -> 2464338967904
	2464338968288 [label=CudnnBatchNormBackward0]
	2464338963968 -> 2464338968288
	2464338963968 [label=ConvolutionBackward0]
	2464338955376 -> 2464338963968
	2464338955376 [label=ReluBackward0]
	2464338955712 -> 2464338955376
	2464338955712 [label=CudnnBatchNormBackward0]
	2464338955952 -> 2464338955712
	2464338955952 [label=CatBackward0]
	2464339031184 -> 2464338955952
	2464339027872 -> 2464338955952
	2464339030368 -> 2464338955952
	2464339029408 -> 2464338955952
	2464339023072 -> 2464338955952
	2464339029696 -> 2464338955952
	2464339022448 -> 2464338955952
	2464339024896 -> 2464338955952
	2464339030080 -> 2464338955952
	2464339031856 -> 2464338955952
	2464339032960 -> 2464338955952
	2464339033008 -> 2464338955952
	2464339028496 -> 2464338955952
	2464339019712 -> 2464338955952
	2464339021968 -> 2464338955952
	2464339029792 -> 2464338955952
	2464338956048 -> 2464338955712
	2464338323936 [label="encoder.features.denseblock4.denselayer16.norm1.weight
 (992)" fillcolor=lightblue]
	2464338323936 -> 2464338956048
	2464338956048 [label=AccumulateGrad]
	2464338955472 -> 2464338955712
	2464338323696 [label="encoder.features.denseblock4.denselayer16.norm1.bias
 (992)" fillcolor=lightblue]
	2464338323696 -> 2464338955472
	2464338955472 [label=AccumulateGrad]
	2464338956096 -> 2464338963968
	2464338324416 [label="encoder.features.denseblock4.denselayer16.conv1.weight
 (128, 992, 1, 1)" fillcolor=lightblue]
	2464338324416 -> 2464338956096
	2464338956096 [label=AccumulateGrad]
	2464338954464 -> 2464338968288
	2464338313536 [label="encoder.features.denseblock4.denselayer16.norm2.weight
 (128)" fillcolor=lightblue]
	2464338313536 -> 2464338954464
	2464338954464 [label=AccumulateGrad]
	2464338967328 -> 2464338968288
	2464338313696 [label="encoder.features.denseblock4.denselayer16.norm2.bias
 (128)" fillcolor=lightblue]
	2464338313696 -> 2464338967328
	2464338967328 [label=AccumulateGrad]
	2464338967280 -> 2464339019136
	2464338327296 [label="encoder.features.denseblock4.denselayer16.conv2.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2464338327296 -> 2464338967280
	2464338967280 [label=AccumulateGrad]
	2464339019088 -> 2464339022304
	2464338327536 [label="encoder.features.norm5.weight
 (1024)" fillcolor=lightblue]
	2464338327536 -> 2464339019088
	2464339019088 [label=AccumulateGrad]
	2464339027008 -> 2464339022304
	2464338327696 [label="encoder.features.norm5.bias
 (1024)" fillcolor=lightblue]
	2464338327696 -> 2464339027008
	2464339027008 [label=AccumulateGrad]
	2464339022208 -> 2464339023840
	2464339023456 -> 2464339025088
	2465073168240 [label="decoder.blocks.0.conv1.0.weight
 (256, 2048, 3, 3)" fillcolor=lightblue]
	2465073168240 -> 2464339023456
	2464339023456 [label=AccumulateGrad]
	2464339024992 -> 2464339026240
	2465073168160 [label="decoder.blocks.0.conv1.1.weight
 (256)" fillcolor=lightblue]
	2465073168160 -> 2464339024992
	2464339024992 [label=AccumulateGrad]
	2464339026336 -> 2464339026240
	2465073168080 [label="decoder.blocks.0.conv1.1.bias
 (256)" fillcolor=lightblue]
	2465073168080 -> 2464339026336
	2464339026336 [label=AccumulateGrad]
	2464339025760 -> 2464339023792
	2465073167600 [label="decoder.blocks.0.conv2.0.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2465073167600 -> 2464339025760
	2464339025760 [label=AccumulateGrad]
	2464339023744 -> 2464339024272
	2465073167520 [label="decoder.blocks.0.conv2.1.weight
 (256)" fillcolor=lightblue]
	2465073167520 -> 2464339023744
	2464339023744 [label=AccumulateGrad]
	2464339025040 -> 2464339024272
	2465073167440 [label="decoder.blocks.0.conv2.1.bias
 (256)" fillcolor=lightblue]
	2465073167440 -> 2464339025040
	2464339025040 [label=AccumulateGrad]
	2464339025136 -> 2464339026192
	2464339025712 -> 2464339019568
	2465073166960 [label="decoder.blocks.1.conv1.0.weight
 (128, 768, 3, 3)" fillcolor=lightblue]
	2465073166960 -> 2464339025712
	2464339025712 [label=AccumulateGrad]
	2464339018368 -> 2464339019616
	2465073166880 [label="decoder.blocks.1.conv1.1.weight
 (128)" fillcolor=lightblue]
	2465073166880 -> 2464339018368
	2464339018368 [label=AccumulateGrad]
	2464339019808 -> 2464339019616
	2465073166800 [label="decoder.blocks.1.conv1.1.bias
 (128)" fillcolor=lightblue]
	2465073166800 -> 2464339019808
	2464339019808 [label=AccumulateGrad]
	2464339020528 -> 2464338871344
	2465073166320 [label="decoder.blocks.1.conv2.0.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2465073166320 -> 2464339020528
	2464339020528 [label=AccumulateGrad]
	2464338882336 -> 2464338871968
	2465073166240 [label="decoder.blocks.1.conv2.1.weight
 (128)" fillcolor=lightblue]
	2465073166240 -> 2464338882336
	2464338882336 [label=AccumulateGrad]
	2464338870960 -> 2464338871968
	2465073166160 [label="decoder.blocks.1.conv2.1.bias
 (128)" fillcolor=lightblue]
	2465073166160 -> 2464338870960
	2464338870960 [label=AccumulateGrad]
	2464338876384 -> 2464338875040
	2464338872352 -> 2464338870576
	2465073165680 [label="decoder.blocks.2.conv1.0.weight
 (64, 384, 3, 3)" fillcolor=lightblue]
	2465073165680 -> 2464338872352
	2464338872352 [label=AccumulateGrad]
	2464338879696 -> 2464338873360
	2465073165600 [label="decoder.blocks.2.conv1.1.weight
 (64)" fillcolor=lightblue]
	2465073165600 -> 2464338879696
	2464338879696 [label=AccumulateGrad]
	2464338879024 -> 2464338873360
	2465073165520 [label="decoder.blocks.2.conv1.1.bias
 (64)" fillcolor=lightblue]
	2465073165520 -> 2464338879024
	2464338879024 [label=AccumulateGrad]
	2464338879264 -> 2464338880896
	2465073165120 [label="decoder.blocks.2.conv2.0.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2465073165120 -> 2464338879264
	2464338879264 [label=AccumulateGrad]
	2464338876000 -> 2464338885408
	2465073165040 [label="decoder.blocks.2.conv2.1.weight
 (64)" fillcolor=lightblue]
	2465073165040 -> 2464338876000
	2464338876000 [label=AccumulateGrad]
	2464338885216 -> 2464338885408
	2465073164960 [label="decoder.blocks.2.conv2.1.bias
 (64)" fillcolor=lightblue]
	2465073164960 -> 2464338885216
	2464338885216 [label=AccumulateGrad]
	2464338870864 -> 2464338876096
	2464338886080 -> 2464338871200
	2465073164480 [label="decoder.blocks.3.conv1.0.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2465073164480 -> 2464338886080
	2464338886080 [label=AccumulateGrad]
	2464338877392 -> 2464338873984
	2465073164400 [label="decoder.blocks.3.conv1.1.weight
 (32)" fillcolor=lightblue]
	2465073164400 -> 2464338877392
	2464338877392 [label=AccumulateGrad]
	2464338876528 -> 2464338873984
	2465073164320 [label="decoder.blocks.3.conv1.1.bias
 (32)" fillcolor=lightblue]
	2465073164320 -> 2464338876528
	2464338876528 [label=AccumulateGrad]
	2464338874944 -> 2464338883392
	2465073163840 [label="decoder.blocks.3.conv2.0.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	2465073163840 -> 2464338874944
	2464338874944 [label=AccumulateGrad]
	2464338875328 -> 2464338884688
	2465073163760 [label="decoder.blocks.3.conv2.1.weight
 (32)" fillcolor=lightblue]
	2465073163760 -> 2464338875328
	2464338875328 [label=AccumulateGrad]
	2464338876720 -> 2464338884688
	2465073163680 [label="decoder.blocks.3.conv2.1.bias
 (32)" fillcolor=lightblue]
	2465073163680 -> 2464338876720
	2464338876720 [label=AccumulateGrad]
	2464338879408 -> 2464372886160
	2465073160320 [label="decoder.blocks.4.conv1.0.weight
 (16, 32, 3, 3)" fillcolor=lightblue]
	2465073160320 -> 2464338879408
	2464338879408 [label=AccumulateGrad]
	2464338874752 -> 2464213206832
	2464373811040 [label="decoder.blocks.4.conv1.1.weight
 (16)" fillcolor=lightblue]
	2464373811040 -> 2464338874752
	2464338874752 [label=AccumulateGrad]
	2464338877008 -> 2464213206832
	2464373316160 [label="decoder.blocks.4.conv1.1.bias
 (16)" fillcolor=lightblue]
	2464373316160 -> 2464338877008
	2464338877008 [label=AccumulateGrad]
	2464596927840 -> 2464213438608
	2464849430640 [label="decoder.blocks.4.conv2.0.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	2464849430640 -> 2464596927840
	2464596927840 [label=AccumulateGrad]
	2464213446864 -> 2464339166832
	2464849443120 [label="decoder.blocks.4.conv2.1.weight
 (16)" fillcolor=lightblue]
	2464849443120 -> 2464213446864
	2464213446864 [label=AccumulateGrad]
	2464502003552 -> 2464339166832
	2464849443760 [label="decoder.blocks.4.conv2.1.bias
 (16)" fillcolor=lightblue]
	2464849443760 -> 2464502003552
	2464502003552 [label=AccumulateGrad]
	2464338710624 -> 2464465887600
	2464849440000 [label="segmentation_head.0.weight
 (5, 16, 3, 3)" fillcolor=lightblue]
	2464849440000 -> 2464338710624
	2464338710624 [label=AccumulateGrad]
	2464501779328 -> 2464465887600
	2464463569936 [label="segmentation_head.0.bias
 (5)" fillcolor=lightblue]
	2464463569936 -> 2464501779328
	2464501779328 [label=AccumulateGrad]
	2464465887600 -> 2463245183616
}
